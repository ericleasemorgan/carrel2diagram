<html>
<head>
<title>Distant Reader - Study carrel</title>
<style>
	body       { margin: 7% }
	.verbose   { margin-bottom: 1em }
	.signature { text-align: right }
	#inventory { display: none }
	#howtouse  { display: none }
</style>
<script type="text/javascript">
	<!--
    function showandhide(id) {
       var e = document.getElementById(id);
       if(e.style.display == 'block')
          e.style.display = 'none';
       else
          e.style.display = 'block';
    }
	//-->
</script>
</head>

<body>

<h1>Distant Reader - Study carrel</h1>

<p>This is a Distant Reader "study carrel" - a collection of documents &amp; indexes brought together for the purpose of using & understanding (call it "reading") a corpus.</p>

<h2>Inventory</h2>

<p>The carrel is made up of a number of parts, beginning with: <a href="#" onclick="showandhide('inventory');">(toggle more or less)</a></p>

<div id='inventory'>

	<ul>

		<li>a <a href="./cache/">cache</a> of your requested documents brought together for reading &amp; analysis -- your corpus</li>

		<li>those same documents but transformed into <a href="./txt/">plain text files</a> so analysis can be done against them</li>

	</ul>

	<p>Next there are lists (tab-delimited text files) of data &amp; information extracted from your corpus:</p>

	<ul>

		<li class='verbose'><a href="./bib/">bibliographics</a> - file names (local identifiers), computed summaries, readability scores, lengths in sentences, and lengths in words of each item in the corpus; useful for filtering results based on size of document, whence it originated, and comprehensibility</li>

		<li class='verbose'><a href="./pos/">parts-of-speech</a> - each word in each document annotated with the file whence it came, the sentence whence it came, its position in the sentence, its part-of-speech (noun, verb, adjective, etc.), and its lemma ("root" or "stem" word); useful for counting &amp; tabulating all sorts of frequencies, and answering questions such as "What is mentioned in this corpus, what action takes place in this corpus, and how are things described."</li>

		<li class='verbose'><a href="./ent/">named entities</a> - specific types of nouns (names of people, places, organizations, dates, times, money amounts, works of art, etc.) annotated with the file whence it came, the sentences whence it came, and the type of named entity; useful for answering questions such as "Who is mentioned in the corpus, when &amp; where do things take place, and to what are things referred?"</li>

		<li class='verbose'><a href="./wrd/">keywords</a> - statistically significant words associated with the file whence they came; useful for articulating the "aboutness" of a document</li>

		<li class='verbose'><a href="./urls/">URLs</a> - each of the hyperlinks found in a document associated with the file whence they came and their root domain; useful for articulating whence documents originated, to what they refer, and the general milieu of the corpus; also useful for addressing the issue of "finding more like this one"</li>

		<li class='verbose'><a href="./adr/">email addresses</a> - "Who are you gonna call?"</li>

	</ul>

	<p>Finally, there are a few "reports", such as:</p>

	<ul>

		<li>a <a href="./etc/report.txt">summary</a> of the information extracted from the corpus including frequency lists (parts-of-speech, keywords, URLs, etc), narrative summaries of each item, and tiny "sentences" connoting meaning</li>

		<li>an <a href="./etc/reader.db">SQLite database file</a> containing all the data from the tab-delimited text files, and the availability of this "index" enables you to ask your own questions against the corpus</li>

		<li>the <a href="./etc/reader.zip">whole of the study carrel</a> compressed into a single .zip file which gives you everthing outlined above but intended for offline analysis</li>

	</ul>

</div>

<h2>How to use the study carrel</h2>

<p>To transform the study carrel's data &amp; information into knowledge &amp; wisdom, consider going through the following process: <a href="#" onclick="showandhide('howtouse');">(toggle more or less)</a></p>

<div id='howtouse'>

	<ol>

		<li class='verbose'><a href="./cache/">Peruse the content of the cache</a>, and ask yourself, "How many documents did I expected to be in my corpus, and how many documents are here?" The answer will help you determine the completness of your corpus. Remember, the Distant Reader knows nothing about username/password combinations, and consequently it may not have access to some content.</li>

		<li class='verbose'>Skim through some (or all) of the items in your corpus thus giving yourself another sort of corpus reality check. Remember, many links to articles are really links to "splash pages" describing articles, and since the Distant Reader does not do deep crawling, some of the desired content may not have been cached.</li>

		<li class='verbose'>If you identify an item of particular interest, seriously consider printing it. Since every effort has been made to save each cached item as a stand-alone document, printing them ought to work more often than not. Once printed, read/peruse the document with a pencil in hand; actively writing on the things you read improves comprehension.</li>

		<li class='verbose'><a href="./txt/">Peruse the directory of transformed plain text files</a>. Compare the number of documents in this directory with the number of documents in the cache. If the numbers are similar, then the transformation process was successful. If not, then call Eric. Take note of the content of the plain text files. Notice how all formatting has been removed. If all the extraneous spaces &amp; carriage returns were removed from a given text file, and if the plain text file were printed, and if the result is (more or less) readable, then the subsequent computer analysis will be (more or less) successful.</li>

		<li class='verbose'><a href="./etc/report.txt">Read the summary report.</a> It contains a myriad of counts &amp; tabulations extracted from the corpus. By reading this document you ought to be able to get an overall understanding of the corpus.</li>

		<li class='verbose'>Peruse the lists of <a href="./bib/">bibliographics</a>, <a href="./pos/">parts-of-speech</a>, <a href="./ent/">named entities</a>, <a href="./adr/">addresses</a>, <a href="./urls/">URLs</a>, and <a href="./wrd/">keywords</a>. Doing so will provide context to much of the data/information you have already seen. Maybe you identified items of particular interest in Step #3? If so, then open their corresponding tab-delimited data file(s) in order to highlight, emphasize, or review the data/information extracted by the Distant Reader.</li>

		<li class='verbose'><a href="./etc/reader.zip">Download the whole corpus</a>, and repeat Steps #1 - #6 one more time. It is quite likely you will have missed something the first time around.</li>

		<li class='verbose'>Download and install some free, operating system independent software, listed here in priority order:

			<ol>

				<li><a href="http://www.laurenceanthony.net/software/antconc/">AntConc</a> - an very functional concordance application, especially since it allows one to import multiple files</li>

				<li><a href="https://github.com/senderle/topic-modeling-tool">Topic Modeling Tool</a> - outputs "topic models" thus grouping documents into sub-collections or "themes"</li>

				<li><a href="http://openrefine.org/">OpenRefine</a> - sorts, tabulates, and reports on the contents of tab-delimited files; runs circles around spreadsheet applications</li>

				<li><a href="https://public.tableau.com/">Tableau Public</a> - with practice, this application can read tab-delimited files and output informative &amp; interactive charts &amp; graphs</li>

				<li><a href="https://www.sqlite.org/">SQLite</a> - can read and report on the content of a study carrel database; this is a command-line driven applcation and requires a knowledge of SQL</li>

			</ol>

		</li>

		<li class='verbose'>Use AntConc to "read" your corpus. More specifically, use AntConc's File/Open Dir... menu option to import all the content of the carrel's txt directory, and then use the balance of AntConc's functionality to search &amp; browse the whole. For example, search for words identified in the summary report.</li>

		<li class='verbose'>Use Topic Modeling Tool to subdivide the text files into sets of themes, and use words of interest found in the themes as input for AntConc.</li>

		<li class='verbose'>Use OpenRefine to read &amp; report on the one or more of the tab-delimited data files. Try to discover what occurs both frequently as well as infrequently. Use the results of this process as input back into AntConc.</li>

		<li class='verbose'>Use Tableau Public to import one or more tab-delimited data files, and then create an interactive "word cloud" or color-coded geographic map illustrating the places mentioned in one or more of corpus items.</li>

		<li>Use SQLite to query the <a href="./etc/reader.db">study carrel database</a>. Using SQLite it is possible to implement just about all of the functionality of OpenRefine, but at the expense of a command-line interface. On the other hand, the SQLite approach allows you to query the database with "grammers". In other words, using SQLite you can answer questions such as "What sentences contain the pattern adjective-king, noun-verb-noun, or adjective-and-adjective?" You can them print out print out the matching sentences or just the patterns in their original word forms. This is a complicated process, and examples can be found in the <a href="./etc/queries.sql">queries file</a>.</li>

	</ol>

</div>

<h2>Summary</h2>

<p>In summary, there are a few more things to note. First, "software is never done", the Distant Reader is software, and therefore, the Distant Reader is never done. There are and will always be ways the Distant Reader can be improved. When you think of such things, then please don't hesitate to pass them along.</p>

<p>Second, the Distant Reader is tool akin to a book's table-of-contents or back-of-the-book index. Reading and perusing the output of the Distant Reader is not a replacement for the traditional reading process, but given the amount of content one is increasingly expected to digest, the Distant Reader can bring to light many details that would quite likely be missed through the traditional reading process. This is true if the Distant Reader were given sets of newly published scholarly articles or classic texts such as <a href="http://cds.crc.nd.edu/reader/collections/iliad/">Homer's <cite>Iliad</cite></a>, <a href="http://cds.crc.nd.edu/reader/collections/republic/">Plato's <cite>Republic</cite></a>, <a href="http://cds.crc.nd.edu/reader/collections/confessions/">Augustine's <cite>Confessions</cite></a>, <a href="http://cds.crc.nd.edu/reader/collections/divine/">Dante's <cite>Divine Comedy</cite></a>, <a href="http://cds.crc.nd.edu/reader/collections/hamlet/">Shakespear's <cite>Hamlet</cite></a>, <a href="http://cds.crc.nd.edu/reader/collections/cities/">Dicken's <cite>Tale of Two Cities</cite></a>, or <a href="http://cds.crc.nd.edu/reader/collections/walden/">Thoreau's <cite>Walden</cite></a>.</p>

<p>The use of computer technology to "read" a corpus requires practice. The software itself is fledgling. You -- the reader -- are new to the process. "Fledgling" multiplied by "new" equals a lot of trepidation and unknowns. But think of how many trepidations and unknowns were generated when oral traditions evolved into written traditions, when scrolls evolved into codexes (books), when books became mass-produced, and now, when books can be digitized and "read" at a scales never-before imagined. We are all new to this process, but at the same time, we are simply continuing a dialog that has been going on for milenium. We live in an "interesting" time.</p>

<hr />

<p class='signature'>
Eric Lease Morgan &lt;<a href="mailto:emorgan@nd.edu">emorgan@nd.edu</a>&gt;<br />
July 26, 2018
</p>
</body>
</html>