













































A Toolkit to Effectively Manage your Website Practical Advice for Content Strategy


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










A Toolkit to Effectively Manage your Website Practical Advice for Content Strategy




Sherry Buchanan

PORTLAND STATE UNIVERSITY



Skip other details including permanent urls DOI citation information
Volume 1 Issue 6 2017



DOI httpdxdoiorg103998weave125356420001604



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













Managing an effective website is cyclical and taskoriented but straightforward once you have a set of tools in place This article provides the tools to manage your website to bring stakeholders into the process and ease the cognitive load of users by offering them the best possible user experience 

I am the content strategist for the Portland State University Library website The PSU Library website receives more than 18 million visits per year almost double the librarys annual walkin traffic The primary audience is twentynine thousand students and seven thousand faculty and staff The secondary audience is community alumni and donors 

In 2014 PSU Library launched its new website after a card sort and numerous usability tests to reinforce the utility of our information architecture and content strategy The new website was a welcome change and its redesign was a great accomplishment but launching the site was just the beginning of a more rigorous ongoing maintenance and evaluation process The site is now meticulously maintained but this was not always the case In 2012 the PSU Library website contained close to 400 pages From 2013 to 2016 we removed more than 250 pages reducing the footprint by 67 percent and substantially boiling down remaining content We are able to declutter and upkeep the website because we use a calendarbased toolkit shared below

Our Toolkit Starts From Core Goals and Yours Will Too

Setting out to design our toolkit for ongoing content governance we started from some goals for keeping our website fresh and usable over time These are broad and likely applicable to your website and library too but worth thinking through before you borrow these tools

First most people do not actually read web pages users skim for content and web pages need to reflect this principle The importance of brevity and styling for readability cannot be overemphasized frontload links at the beginning of sentences use bullets avoid walls of text Having a style guide and encouraging compliance is critical because writing for usability isnt always intuitive even to good writers and sometimes it is important to err on the side of consistency even when there are content decisions that could reasonably be made in other ways In addition to an editing and style guide we provide monthly reports to library staff to keep our processes transparent and to invite input within a structured system and we have methods to handle new content and ensure we dont have stale content We have one primary editor me and two blog editors We take the time to understand our audience We cyclically identify the most salient content and remove everything else We have clearly established workflows for introducing new pages deleting pages and updating content We have welldefined goals priorities and design principles Our annual calendar focuses our activities We do regular usability testing and we make datadriven decisions 

A big part of our approach to managing our website contentthe writinglayoutis posited in the notion of psychological safety Creativity and success happen when editors are comfortable expressing their ideas are free to take risks and explore solutions and find their own ways to keep our usercentered datadriven approach to content at the heart of their efforts Great solutions can only be found when there is room to explore It is critical that the people making websites are given a certain amount of creative license to investigate other websites to seek better models to find comparator sites and specific pages to emulate to explore solutions immerse in brainstorming and engage with ideas to identify new approaches to content Investigating and testing multiple layouts and information architecture strategies to see which layout meshes with user needs and provides the best readability is key


A great way to find comparable academic library web pages is to perform a Google search with siteedu and use keywords that represent your content It is important to have your own test environment multiple test environments ideally to draft options and try out new ideas In addition to this free space a set of rules to keep content within guidelines is critical I cant emphasize enough the value of creative license freedom to explore multiple models and be in a playful mode to stay open to the best solutions Google itself invests in this theory see this related New York Times article Its worth pondering this idea and sharing it with administrators I did 



At the core of making and managing a good website is understanding who uses the website Also we need to be aware that reducing the cognitive load for all users is paramount Cut two of every ten words Get into the personas of the users and think like them imagine their needs and desires and build a user experience that exceeds expectations Be in the user perspective

Here is a before and after snapshot of our content mindset shift

	Before	After
	Distributed editors	Centralized editing
	Anything goes	Vetted for quality control
	Youre on your own	How can we help
	Intuitive content creation	Datadriven content
	Slow revision process	24hour turnaround
	Inconsistent voice	Consistent voice 
	Stale content	Current content
	Sprawling	Pared down


Our Toolkit

Website Goals Priorities  Design Principles Template

All websites should have clear goals This is like your websites mission statement and these goals need to be in writing to ensure adherence Along with clear goals it is helpful to have agreed upon priorities and design principles We designed with these ideas in mind responsiveness mobilefirst universal access Even though only ten percent of our users access the PSU Library website via mobile devices we still went forward with mobile first design principle to provide the best functionality possible to all our users because we have about thirteen thousand visits per month from mobile devices and we anticipate increased mobile usage Start with the most simple structure and pages 

Universal access refers to accessibility and we have made efforts to ensure that all users can access our website content Users who do not use a mouse need headings for screen readers so they can jump to the content they seek Screenshots are only used as supplements and instructions should be written well so that screenshots are not needed to do tasks We have had blind users perform tasks on our site and we have made changes to help them A number of users have reading disabilities and if we design for themclear and concise contentwe are helping all readers 

Editing  Style Guide

The Editing  Style Guide is critical to our effectiveness It includes information on web page creation deletion and editing workflow WordPress Howto style elements writing guidelines common terms and usage and supporting references such as the University style guidelines and identity standards and other inspiring sources

Annual Website Calendar

Website management is cyclical We have a usercentered annual calendar In the fall we keep it light Every term except summer we do one week of focused analytics in the fourth week of the term to capture what users are doing from our home page In the winter we do usability testing We start preparing in January devising the particular things we want to learn and how to test the site or search interface or study room booking systemwhatever it is we are testing based on our goals In spring we make decisions and implement changes on the development server get feedback from stakeholders and fine tune changes using an iterative process In summer we update our public website Each month a website report is written and shared with the entire library highlighting industry trends notable websites and our website traffic analytics and search data in comparison We have an editing hiatus for a few days during the second week of each month to perform WordPress core and plugin updates and launch or remove plugins 

Google Analytics Template

Website managers use Google Analytics to make informed content decisions Creating an Analytics Dashboard is simple and allows you to focus on the data that matters to you and that you want to track over time Once you have an account for your properties you can use our shared monthly report template It includes the aforementioned charts and graphs that comprise our monthly report

Monthly Website Reports Full Archive


Part of the lure of writing a monthly report about our website is the process of looking at other websites searching for new design ideas reconsidering our layouts hierarchy and content examining what trends are on the horizon and thinking critically to ensure we are exceeding user expectations whenever possible Ive talked to several website content editors at other institutions and most of them were somehow elected to their position or fell into the role of writing web content Even if you have no experience at all and you find yourself in a position to make or maintain your website you just need to come up with a system and focus on effective collaboration Be thorough accurate professional and courteous and always lend a consistent voice to content 



The monthly website report starts out each month with a Looking to the Horizon section intended to frame our work in a larger context by showcasing articles on usability and emerging technology as well as notable library websites The reports highlight statistics from Google Analytics and include a Special Focus section to share unique information with colleagues We include a percentage of change chart to demonstrate usage increases or decreases to our websites our WordPress site is one of several Google Analytics properties When sharing traffic data we include graphs and compare the current month with the same month of the prior year Additionally we highlight our top ten web pages and provide the following charts traffic types browsers desktopmobile unique pageviews new  returning visitors bounce rate and session duration graphs with definitions as the end of the report Valuable information is gained from this report and the information feeds datadriven decisions We share this report with library staff and we ask for feedback 

UsabilityTechnology Articles  Notable Websites Archive

This is a bulleted list of excellent usability articles emerging technology reports and notable library websites excerpted from PSU Library monthly website reports 

Collected Usability Testing Questions

This is a collection of PSU and other library usability testing questions resulting from a literature review and environmental scan Each tab offers questions used for specific usability tests we have done and also tests performed by other universities The first tab contains a draft of our usability testing questions for the new catalog interface we plan to roll out in 2017 The annual calendar lays out our plan February testing April soft launch June cutover This is the first time we are solely focusing annual usability testing on our search interface Our most recent change was to introduce the primary website navigation aka mega menu into the search interface Over the years we have thoroughly tested the main websites information architecture and worked diligently to meet our goals and now we are focusing our energy on the new ExLibris Primo catalog interface

Quick Usability Testing Howto	Recruit three to five users from different disciplines and varying skill levels
	Use the think out loud protocol see Steve Krug and free WebEx software
	Identify your top problems and implement changes an executive summary helps




Quarterly Homepage Analytics

Homepage analytics are performed the fourth week of each quarter except summer We have heat maps over our homepage and mega menu showing inpage analytics of every time links are clicked from the homepage and a pie chart with the most visited links The reports are evolving We plan to have a better pie chart in place to reflect the content labels rather than the URLs

Pages by Last Modified Date

This is essentially a sitemap that we call our Stale Pages Report If a page hasnt been modified in a long time thats one indicator that it might need updating or be a candidate for deletion We added the primary contact person for each page into a custom field in WordPress and created a report to export all the pages the person responsible for content the URL and the last modified date We commit to making sure every page is reviewed annually

Acknowledgments

Special thanks to everyone who makes PSUs library website great administrators supporting our work the Website Advisory Committee the Library Technologies team staff who give input and all our users whose goals we hope to meet

After writing this the author converted the monthly website report to the new Google Data Studio format Check out the March 2017 PSU Monthly Website Report




Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS
























































Things That Squeak and Make You Feel Bad Building Scalable User Experience Programs for Space Assessment


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










Things That Squeak and Make You Feel Bad Building Scalable User Experience Programs for Space Assessment




Rebecca Kuglitsch and Juliann Couture

UNIVERSITY OF COLORADO BOULDER



Skip other details including permanent urls DOI citation information
Volume 1 Issue 8 2018



DOI httpdxdoiorg103998weave125356420001801



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













This paper was refereed by Weaves peer reviewers


Abstract


This article suggests a process for creating a user experience UX assessment of space program that requires limited resources and minimal prior UX experience By beginning with small scale methods like comment boxes and easel prompts librarians can overturn false assumptions about user behaviors ground deeper investigations such as focus groups and generate momentum At the same time these methods should feed into larger efforts to build trust and interest with peers and administration laying the groundwork for more indepth space UX assessment and more significant changes The process and approach we suggest can be scaled for use in both large and small library systems 


Developing a user experience space assessment program can seem overwhelming especially without a dedicated user experience librarian or department but does not have to be In this piece we explore how to scale and sequence small UX projects communicate UX practices and results to stakeholders and build support in order to develop an intentional but still manageable space assessment program Our approach takes advantage of our institutional contexta large academic library system with several branch locations allowing us to pilot projects at different scales We were able to coordinate across a complex multisite system as well as in branch libraries with a staffing model analogous to libraries at smaller institutions This gives us confidence that our methods can be applied at libraries of different sizes As subject librarians who served as cocoordinators of a UX team on a voluntary basis we also confronted the question of how we could attend to user needs while staying on top of our regular workload Haphazard experimentation is unsatisfying and wasteful particularly when there is limited time so we sought to develop a process we could implement that applied approachable purposeful UX space assessments while building trust and buyin with colleagues administrators and users 

The essential thrust of our approach is to perform small carefully selected projects that can be accomplished with very little preexisting support and to communicate methods results and goals with stakeholders in order to develop trust and buyin across the organization Building that trust sets the stage for better collaboration with peers and an increased likelihood of support from upper management improving the chances that libraries will be able to act on gathered data in a meaningful way Building trust with and engaging peers is essential to making changes to services and spaces Building trust with upper management can help secure access to the financial and social resources needed to make larger changes In this article we will discuss how to establish a process of small interventions and create buyin from colleagues and administration in order to meet more significant needs By combining several loweffort techniques libraries can begin to integrate a consistent approach to assessing and improving the UX of their physical spaces even with minimal institutional support Those efforts can lay a foundation for better understanding and acceptance of UX work generally within the library as well as making improvements to library spaces that matter to users

Literature Review

In the past two decades a theme of using ethnographish methods to study library users with an emphasis on creating welcoming physical and digital environments has emerged in library literature Lanclos  Asher 2016 In some instances this emphasis came from a new library dean or director Kim Wu  Lanclos 2011 wanting to create library spaces that meet the needs of the user while other initiatives stem from a desire to understand changes in undergraduate student study behavior and the connection to library spaces and services Foster  Gibbons 2007 One example is the anthropologistled Undergraduate Research Project at the University of Rochester which applied ethnographic approaches to the study of user behavior This piece brought these methods into wider awareness while demonstrating the importance of understanding local contexts and giving librarians new tools to assess user experience Foster  Gibbons 2007 Ten years later a follow up to the project revisited portions of the original study and incorporated new areas of focus demonstrating the iterative nature of user experience work and the importance of examining user behavior over time Foster 2013 MacDonalds 2017 surveys and interviews with UX librarians articulate the benefits of emphasizing UX work including a greater big picture view of library spaces and services improved outreach to community members and greater empathy and responsiveness to the user Throughout this body of literature there is a growing recognition that library user experience is central to libraries missionsnot a distraction from or an accessory to them This literature which positions user experience as foundational to libraries grounds our approach to developing an accessible model for integrating user experience in library practice

Large scale library renovations often serve as a driving force for conducting user experience and space assessment projects but this can also frame user engagement as limited to distinct projects rather than an integrated regular process Collaborative design methods Somerville  Collins 2008 increase interactions with users and reshape librarians perspectives on the library throughout the redesign process Although the focus remains on renovation and redesign projects Somerville and Collins note that this process initiates interactive relationships between users and the library setting the stage for the development of integrated UX Participatory action research allows libraries to understand the needs of hardtoaccess user groups identify new ways of using the library and avoid the influence of unproven preconceptions and past precedents in redesigns BrownSica Sobel  Rogers 2010 Somerville  BrownSica 2011 Having seen the benefits of space UX for redesign the next step is to integrate user experience and engagement in day to day assessment of services and spaces 

Although the results of these approaches indicate the benefits of engaging with users through the space analysis and design process a range of barriers and challenges prevent libraries from pursuing this type of assessment consistently Indeed even in oneoff space redesign efforts where one might expect attention to UX implementation of such projects is lacking In a recent report on academic library renovations librarians and architects said they valued understanding user needs but only 31 percent of the sample acted on that statement and formally collected user data to plan and assess UX even those assessments tended to be traditional metrics like gate counts Head 2016 Subjects identified logistics time energy expertise and resources required to do evaluation as barriers to even oneoff UX assessment Head 2016 Barriers exist in implementing extended UX assessment as well MacDonald 2017 indicates that even with a dedicated UX position consistent challenges remained including navigating library culture securing trust and support from administrators and colleagues resource limitations such as lack of time and money challenges with scale and scope of work and lack of staff expertise Clearly there is a need to develop a space UX approach that takes these constraints into account 

A teambased approach offers one way to address some of the challenges and barriers to UX work laid out by Head 2016 and MacDonald 2017 Many case studies describe ongoing project teams for website usability testing that demonstrate a level of success in gathering staff across the organization to build a level of expertise in usability assessment Godfrey 2015 Kavanagh Webb Rhodes Cook Andresen  Russell 2016 Nichols Bobal  McEvoy 2009 Godfrey 2015 suggests the team model could be transferred to space UX Other cases describe the creation of project teams to examine user experience in specific library spaces Khoo Rozaklis Hall  Kusunoki 2016 Kim Wu  Lanclos 2011 These examples highlight the importance of engaging users when reimaging spaces outside the context of a largescale renovation but remain limited in scope and do not address how to sustain an ongoing space assessment program 

In addition to staffing models establishing organizational buyin with peers and administration is another factor libraries must consider when developing UX programs UX work whether in creating a group or acting on findings challenges organizational decision making processes and requires buyin on multiple organizational levels Godfrey 2015 Kavanagh Webb et al 2016 Kim Wu  Lanclos 2011 Nichols et al 2009 Working with colleagues to build buyin and develop empathy for users creates conditions where UX projects can move forward with librarywide support or at least understanding Godfreys web usability model of training buyin and demonstrating impact can be applied to UX for library space and services and is especially useful for creating buyin with colleagues 2015 In an academic library with limited staff and resources Westbury 2016 carried out meaningful smallscale projects that altered administrator assumptions increased empathy with users and led to increased support for UX and space improvements There are good models for building buyin with colleagues but few models specifically outline building buyin with library administration In our paper we suggest ways to formally develop both types of buyin

Many of these strands of buyin staffing and challenges to UX are synthesized in MacDonalds description of a potential maturation model for UX in organizations In this model UX moves from an unrecognized need to being fully institutionalized where nonUX staff members are making UX decisions and iteration and improvement are baked into the culture 2017 p 209 But though MacDonald describes what this might look like the model offers no explicit road map for moving forward in the maturation process Our approach is inspired by this model and by Gullikson  Meyer 2016 who describe an example of integrating UX into regular practice Their process of gathering space use data as soon as possible rather than waiting for a perfect methodology is one that can be used to begin to build useful iterative UX programs and one that grounds our proposed method to locally develop a UX program 2016 p 22 

  

Institutional Description  Overview of UXWG

At the University of Colorado Boulder we have the resources of a large doctoral university with five library locations across campus Norlin library is a sprawling freestanding library covering the social sciences humanities life sciences and chemistry and houses most of the library systems centralized services and staff There are four branch library locations situated in academic buildings with programs the libraries support Business Earth Sciences and Map Music and Engineering Mathematics and Physics This gave us a way to examine UXand particularly related communication issueswithin a large complex organization Each branch library is staffed with between 153 faculty librarians and 35 staff members Although the branches have the support of the larger library system this setting allowed us to approximate how UX techniques might work in smaller libraries We approached our project using these different contexts to draw conclusions relevant to both larger systems as well as smaller libraries

The University Libraries system recognizes the need for UX work but does not have dedicated staffing When our library system underwent a reorganization in 2012 a user experience position was proposed but ultimately not pursued due to library priorities confusion about where such a position might fit into the new organizational structure and limited staffing levels We face challengesorganizational culture people and moneythat are similar to those seen in other organizations MacDonald 2017 In the reorganization a working group model was developed to address gaps particularly those that cut across departments Librarian advocacy led to the recognition of UX as one of those gaps and resulted in the creation of the User Experience Working Group UXWGagain a common solution to the need for UX Godfrey 2015 Kavanagh Webb et al 2016 Nichols et al 2009 The group is comprised of faculty and staff from across library departments Membership is based on interest and many members have limited to no previous experience in UX work Two volunteer cocoordinators manage the group Like membership leadership of the group is based on interest and responsibilities are in addition to the leaderships primary job responsibilities meaning that UX projects have had to be balanced with a preexisting workload Similar to the formation of such teams in other libraries Godfrey 2015 Kavanagh Webb et al 2016 the groups original focus centered on testing of the library website but has expanded since to include UX of physical spaces With the launch of a new website the group continued the work of conducting usability tests for iterative improvement of the site but was able to shift some of its focus to examining library spaces 

One of the common barriers to UX identified by MacDonald 2017 is lack of skills and training in UX so in order to enhance team skills and to increase institutional understanding of UX members and cocoordinators sought out webinars trainings and readings to bolster our skills in assessing UX of spaces The aim of these development offerings was to build our shared knowledge to a point where we could begin to perform simple UX space explorations We made sure training opportunities were open to all library staff not just the UX team because we wanted to increase awareness and understanding of UX work across the institution Since membership rotates we hoped that widespread training would encourage library staff to join the working group Like many libraries development funds were limited so we searched for lowcost ways to build our skills webinars a reading group around Amanda Etches and Aaron Schmidts book Useful Usable Desirable and asking those with areas of expertise to share via inhouse trainings We encouraged a learn by doing approach mutually supporting each other and openly discussing successes and challenges when implementing new methods These efforts positioned us to begin exploring newtous space UX approaches and fostered interest in UX across the library We began to see nonmembers who attended the reading group and webinars undertake their own UX projects and advocate for projects impacting the larger organization For example after the training when plans for a significant redesign in the research area in Norlin were revealed we saw increased acceptance of the final plans as backed by UX methods than we did two years prior when website redesign plans were presented as backed by UX methods Colleagues were primed to understand that user needs were valid and reasonable and that the plans were not just generated from a single persons vision or whim 

Developing our approach to smallscale assessment

Our twopronged approach stages a series of scaffolded UX explorations while concurrently developing a trust building process with peers and administration and a communication protocol By focusing on developing trust and communication at the same time as developing the smallscale assessment this approach sets up a climate where UX can permeate the institution more broadly to make it more feasible to enact changes based on collected data Staging smallscale UX studies makes it possible to quickly build a basic foundation and learn what questions to ask in more involved investigations

Build an Understanding of Users

In order to build a space UX program from the ground up we recommend starting with easy noninvasive explorations to build a knowledge base that serves as a foundation for designing productive largerscale explorations It also provides opportunities for small wins that encourage users and librarians alike In particular we recommend beginning by employing methods of collecting feedback with a low barrier to entry such as easel questions comment boxes and reply cards Table 1 Written feedback can generally be collected passively with low investment by both librarians and users making it an excellent option for beginning space UX projects These initial methods identify barriers assumptions and misperceptions about user experience that warrant deeper investigation using more time intensive methods and consequently help formulate a longer term UX plan and better questions for use in later more involved stages see Table 1 They identify a range of immediate smaller problems allowing low effort high impact UX fixes to be put into place after early rounds of assessment and then reassessed for success and adjusted as needed increasing trust engagement with and interest in UX 

Table 1 Approaches advantages limitations and time investments

	
Approach

	
Advantages

	
Limitations


	
Easel feedback 

		Brief time commitment
	Quick turnaround between posting and actionable information
	Can gather information from wide range of users
	A useful first or second step 

		Feedback can be altered by other participants
	No demographic information
	Only users of physical space are reached


	
Comment Box

		Informal
	Minimal time commitment
	Maintains awareness of emerging issues in library as a whole
	A useful first or second step

		Feedback is spotty and ad hoc
	Little demographic information
	Little opportunity to ask for clarification
	Only feedback from current users of physical spaces is accessible


	
Reply Cards

		Can target specific areas within a library
	Provides detailed information about current space use
	Time commitment is relatively manageable
	Can serve as a bridge to more timeintensive methods

		Little opportunity to ask for clarification 
	Only feedback from current users of physical spaces is accessible
	Little opportunity for indepth reflection


	
Intensive inperson methods semistructured interviews charrettes journey mapping

		Opportunity for deep exploration and user reflection
	Opportunity to clarify or collaboratively solve issues identified in previous feedback
	Can address particular user communities faculty undergraduates graduate students

		Hard to cover feedback from lowstaff times
	Captures feedback only from active users willing to talk to strangers
	Time intensive




In addition to being lowcost and building a foundation of small victories these techniques also provide essential perspective Library staff know the library its daily rhythms and many of its barriers well But this familiarity can blind us to user needs and experiences For example in Norlin Library there was a perception that two hightraffic heavily used areas were used only for short periods of time perhaps between classes and projects for improvement were prioritized based on that assumption But initial user experience researchgathering easel feedback observations and reply cardsproved that wrong with minimal investment of time and money allowing us to prioritize projects and focus later user experience investigations in ways that matched actual rather than assumed user need Although we realized how important it was to check our assumptions only as we developed our process we recommend explicit attention be paid to identifying assumptions around spaces at the beginning of investigating them and continually revisiting those assumptions Consider bringing together library staff closely affiliated with the space in question and collaboratively describing perceived use of spaces issues and needs There are a range of ways to carry out this process we suggest having people contribute to collaborative documents or having staff members write their perceived user concerns on post it notes and then collaboratively group them into themes We recommend the user experience team use the resulting document to identify shared assumptions and test them explicitly

To begin exploring user experience and testing assumptions we recommend starting with comment boxes and easel prompts used in tandem as both are lowcost unobtrusive methods Either option could be employed as the initial data gathering tool and then fuel the establishment of the other depending on the context Selecting a method to start with depends on library size available materials library layout and traffic flow For example in the Engineering Mathematics and Physics Library the space was small and traffic flow allowed nearly all users to be funneled past a comment box with freeresponse cards quickly collecting enough comments to identify common concerns We then used what we heard in the comment box to develop more focused solutionsbased questions to ask on easel prompts such as Where would you like more power strips When would you like to attend workshops Would you prefer chair style a or style b When working in a more sprawling environment with a wider variety of users it is more useful to flip the order of the approaches to begin with a more attentiongrabbing method To accomplish this we set up two easels in a large heavily used space with the prompt I wish my library knew that This prompt was chosen for its openendedness and ability to be interpreted in many ways The prompt was left up for three weeks and a clean prompt was put up when the previous sheet became too overcrowded with responses a whiteboard could be used as well The benefit of this prompt was that our users told us about many ways they use and interact with the library including comments regarding outlets furniture lighting helpful staff and even the emotions they experience when using and studying in the library 

Ultimately we recommend using the two methods to build a foundation of UX knowledge and monitor the situation on an ongoing basis Which to begin with depends on local context but the two productively reinforce each other A comment box serves to maintain awareness of continuing and newly developing concerns and easel prompts can be used to address the resultant specific questions and assess changes made in response to comments Both methods are low cost take little user and investigator time and do not significantly intrude on the spaces around them making them a relatively easy sell to others and an ideal place to begin integrated UX efforts 

Some challenges identified using lowbarrier methods are easily solved and we recommend identifying and addressing such challenges immediately Quick attainable change is satisfying for staff and students and builds momentum and appetite for further change In the Engineering Mathematics and Physics Library for example administrative involvement was not required and no ones role was threatened by purchasing a dozen more power strips and scattering them throughout the branch library solving some of the power access issues users reported Of course the feasibility of these solutions varies in Engineering Mathematics and Physics this worked well because the space was small and desks and tables are close to walls In a larger space like Norlin this quick fix was unavailable since power strips were a hazard in floor plugs but it shifted thinking about furniture purchasing in the longer term Wherever possible establishing a positive feedback cycle like this bolsters integrated UX 

Some changes involve more significant investments and a wellgrounded argument for that investment makes success more likely A still easy but more indepth next step method is reply cards These are cards with a series of questions exploring how people use a particular space in the library distributed in the library for a set period of time at seats in areas of interest see example in fig 1 Distribution varied slightly depending on the type of the library staffing levels and the information we were gathering In the Engineering Mathematics  Physics Library we wanted to know about the space experience of the whole library we had a smaller body of users who we know resent interruption and had no incentives to encourage responses Over the course of a midsemester week we placed cards throughout the entire library collecting them at the end of each day and replenishing in the morning with blank cards In Norlin library there was more focused interest in four zones of a particular section of the library a substantial body of users and access to student workers and incentives This allowed us to hand out and collect reply cards individually and encourage participation with the chance to win a gift card We identified two days in the middle of a semester where we expected moderate use in Norlin library and in a twohour time frame on both days distributed and collected replay cards Handing cards out yields more demographic and spatial information but both options yield useful information 

Reply card template

	Help us improve the library spaces Tell us a bit about how and why you use this space
		Why did you choose this seat today
	What are you here to do
	How long have you been using this space today
	What is the last time you used this area
	If you could not use this space right now where would you go




Figure 1 Reply card template

In order to construct the reply card questions and identify spaces to investigate with them we used the information gathered from the easel prompts For example we learned from easel and comment boxes feedback that users in numerous locations found our wooden chairs painful for long use and in the branch unremittingly squeaky Consequently we decided to investigate how people used the space and particularly how long they used it with reply cards From this we learned that our assumptions of how the spaces were used were incorrect rather than using the space briefly between classes students indicated that they typically spent long periods of time studying in the space and could find few alternative spaces These results from the reply cards coupled with observations of the space made clear that users spend lengthy amounts of time studying in the Norlin research area and in the branch libraries which changed our priorities and provided us with justification for phasing out the uncomfortable wooden chairs as a key change In the branch this led to replacement of chairs on the main level and has influenced purchasing decisions and priorities in the Norlin library

Digging Deeper

After building buyin and identifying assumptions and new questions by exploring with lowbarrier methods we recommend moving on to more time consuming but richer inperson methods such as focus groups and semistructured interviews Other methods to consider at this stage might include mapping diaries or cognitive mapping Asher  Miller 2011 journey mapping Marquez Downey  Clement 2015 or design charrettes Somerville  BrownSica 2011 Small focus groups of fewer than five people at a time proved to be a useful approach in our context still feasible for a small busy team to complete but providing opportunity for deep exploration For example we held focus groups looking more closely at the concerns we discovered earlier from easel prompts and comment box responses These focus groups followed a semistructured interview process and were a combination of spontaneous and prescheduled This mixture reduced the time team members needed to spend scheduling and also allowed for flexibility to meet users preferences For example in the Engineering Mathematics  Physics Library we that found users with very busy school schedules could more easily be convinced to attend an impromptu session in an onsite study room with snacks than to book a 30minute focus group with a monetary incentive ahead of time We asked questions like

	How do you use the library What could make that use better
	What do you like about the library
	What improvements would you make
	Do you feel welcome at the library
	Who else do you think is using this library elicit who is using this Who do you think this library is designed for in other words do you feel like this library is for you
	How does the noise level work for you
	What technology needs do you have in the library


Exact questions should be tailored to the library in question of course but a mix of specific and openended questions will ensure coverage of both what librarians know they want to know while leaving room to explore the unanticipated needs of students Again results helped us set priorities and justify changes Although we already knew that squeaky chairs were annoying these interviews helped frame that the chairs contributed to an unwelcoming environment a deeper nuance and powerful argument we would have overlooked if we had not followed our earlier UX information collection with inperson work

 Each semistructured focus group interview was conducted with the caveat that students were welcome to think creatively and propose grand schemes regardless of their likely viability This is important to emphasize regardless of the investigation method used because wild and unattainable solutions sometimes lead back to very real problems For example one set of students in a branch library requested a severalstory rock climbing wall leading to a study area that could only be used by senior majors in the area the library served This was obviously not feasible But it gave us insight into a real problem that students in the subject areas served by the library sometimes felt sidelined by users dominating the space not because of the subject areas served but because of the librarys proximity to a large lecture hall While we could not build a climbers paradise we asked followup questions to identify other more attainable ways of creating intellectual community at the library In this case the library implemented a geology photo contest This dream big approach allowed students to indicate frustrations and problems they might not otherwise have articulated whether from a concern about seeming mean or a lack of awareness that their frustrations are valid and addressable It is important to be explicit about this dynamic with other library stakeholders because a common fear we heard from colleagues was of students asking for impossible things Translating the wish into the problem they wanted to see solved led to a viable solution addressed the concern 

In some cases we could jump start this translation process by directly asking students to help solve problems we had identified in earlier steps of the process This provided us with further creative solutions such as the geology field trip photo contest that students suggested to create community in the Earth Sciences  Map Library It also meant that the identified solutions sounded appealing to at least some students and helped build confidence among the students that we sought to act on act on their feedback By telling users that we heard their feedback and wanted assistance in developing solutions we were able to convey our seriousness in working with them to build a more usable library 

 One issue to watch out for in this stage is ensuring appropriate representation from stakeholders What this looks like depends of course on the project and space and it is important to consider which stakeholders the library needs to see represented for each individual project is it important to balance graduate undergraduate and faculty needs the needs of a particular discipline Many of the lowbarrier foundation methods we suggest cannot identify representation so it is particularly key to thoughtfully seek out representative stakeholder groups in the more intensive investigations as we attempted to do in our focus groups Too often library space user samples mainly consist of undergraduates Head 2016 which can lead to neglecting the needs of graduate students and faculty and can make it easy for staff to dismiss UX studies as unrepresentative But here again we agree with Gullikson and Meyers assessment that some information is more important than none of the most perfect information 2016 

Combining multiple methods in each stage is also important When feedback from multiple locations was consistent it strengthened our arguments for confronting particularly knotty challenges that might otherwise fall lower on the list of priorities because of their difficulty For example we consistently heard requests for more or betterplaced outlets from all avenues of investigation This not only led to piloting a new electrical system in Norlin library but also contributed to discussions at the campus level about electrical access in the libraries While the majority of the studies we discuss were undertaken as part of UXWG projects done by others and standing assessments such as LibQual often reinforced the feedback we collected Seeking out and correlating our findings with other work helped build institutional trust in our findings 

Building Buyin

While the assessment approaches we recommend can easily be incorporated into individual practice and performed without significant organizational commitment working with others across the library including peers and administration is ultimately necessary to spread the approach across the institution and ensure there are resources to pursue the changes identified Whether the context is a large system with many branches or a small library with a handful of spaces buyin from others is often key to ensuring that attention to UX is widespread and can eventually be developed further Buyin in this case involves building an institutional recognition that user experience and empathy matter that user experience methods have validity and building trust between advocates of user experience and library staff and administration with less familiarity


With Colleagues

We advocate for a participatory training approach as a method to address some of these challenges with colleagues We developed a workshop designed not only to build empathy but to increase knowledge around user experience and shift the impression colleagues had of the working group The centerpiece of the workshop was a participatory session in which library faculty and staff served as participants in user experience testing of the coffee shop that leases a part of the Norlin library In general library workers had positive and frequent relationships with the coffee shop everyone had opinions about it but no one had an investment in it as a personal project This helped achieve several aims First it helped make clear that user experience feedback was not necessarily the rantings of the disgruntled by putting the participants in a situation where they assessed a space they both were fond of and could improve It made it clear that user experience mattered in spaces as well as on the web It also was a way for librarians to take the position of users and understand how a space could in fact be improved by users All of this helped attendees develop empathy with users at the same time as it increased their knowledge of space UX techniques

We started by breaking the attendees into three groups spaces website and servicesaspects that mapped nicely to the work of the library and provided a bridge from familiar aspects of UX website to the less familiar space and service Using the questions in Table 2 the groups identified numerous issues that echoed concerns shared by library users In the spaces group participants identified dirty microwaves and unsuitable furniture which corresponded to feedback UXWG gathered around cleanliness and unwelcoming furniture in the library The website group identified challenges finding basic information such as hours of the coffee shop The services group identified that they had had pleasant interactions with individual staff but that crowd control systems could be improved It helped all of us recognize things that we felt were easy in the librarybecause they were part of our everyday lifemight not actually be so for users By situating library faculty  staff as users this activity helped participants to begin thinking of themselves as people whose work impacted users and made clear that just learn how to do it right is not a viable solution to user experience problems The workshop ended with a brief presentation about UX principles and best practices while integrating themes from the session with projects undertaken by the working group 

Table 2 Question for librarians to assess user experience in a nonlibrary space

	
Group assessing

	
Questions


	
Spaces

	
How did being in the space make you feel What was your first impression


	
Describe your experience waiting in line or for your coffee


	
Describe your experience finding or asking for what you wanted  Could be seating a menu item a tool like the microwave supplies


	
What is your ultimate impression of the space What was your experience as you left the space 


	
Services

	
How did interacting with the staff make you feel What was your first impression


	
How long did the experience take Did the duration of your visit meet your expectations for customer service Why or why not


	
Describe your experience finding or asking for what you wanted 


	
What is your ultimate impression of the services What was your experience as you left 


	
Web

	
Think back to your last time on the coffee shop website How did interacting with the site make you feel What was your first impression


	
Describe your experience finding what you wanted example hours gift certificates menus 


	
What is your ultimate impression of the site 


	
Does the site match your experience of the cafe Why or why not Does this matter




In our context and we suspect in many others one of most important foundations to spreading user experience is making it clear that studying user feedback is not punitive We aimed to make it clear that we were not the user experience police that we were not trying to catch anyone By framing UX in a context where the participants were trying to improve a place they had affection for we were able to shift the assumption that UX is primarily negative criticism For our group this punitive perception was a key consideration First as an interest based group rather than an expertise based group we cannot simply rely on claims to positional authority but instead need to educate ourselves at the same time as we educate stakeholders Additionally the libraries had just completed a lengthy web redesign in which many requests and preferences were necessarily denied The UXWG had been heavily involved in user testing iterations of the design and consequently had picked up something of a reputation as the kind of group that existed to say no Our workshop helped counter this narrative position ourselves as a resource increase general knowledge around user experience and raise awareness of the role of the librarys UXWG in physical spaces To identify when and how best to hold a similar workshop it is important to examine institutional context We selected a meeting that was open to all faculty and staff was wellestablished and had recently sent out a call for more contentrich agendas At other institutions a similar workshop could be delivered in analogous meetings during a professional development series or day or simply as a oneoff 

Structuring a feedback loop for UX changes is another essential component of building trust and communication with colleagues as well as of iterative UX design It can be discouraging for UXWG as well as other faculty and staff involved when changes do not work out as intended To mitigate this baking in the idea of iteration and feedback loops from the beginning is helpful When the process of change includes preplanned tweaking and iterating it feels less like a failure when things do not work as intended because it is part of the process rather than an untoward outcome For example when we planned to make a change at Engineering Mathematics and Physics we would plan after implementation to ask users what worked well what they would change and if they noticed the changes we made based on their feedback In one instance a large screen originally purchased for a conference room was repurposed to test out the idea of a popup theater which would allow for streaming of live events or be used for student presentations After a few semesters of testing out this initiative the project never took off so the staff of that location came together to discuss what was working and what was not what kind of needs students had identified and how the project should move forward After testing a few tweaks the initiative was dismantled and the screen repurposed into a display center highlighting library activities which had been identified as a need Rather than failing to build a popup theater the builtin iteration reframed the process as finding the best way to meet student needs with a piece of technology This experience made it easier later to introduce a room reservation system users had requested as a pilot because we had established a group willingness to use criticism productively and make changes as needed




With Administration

As well as building trust with colleagues it is also essential to build buyin upwards While the participatory method was also useful in building buyin with administration library administration has different priorities than colleagues In order to further build buyin upward we identified several strategies

	To clearly align user experience with the libraries strategic plan
	To start with lowcost highimpact projects
	And to apply UX to approach known problems with innovative solutions


Tying user experience to strategic planning is perhaps an obvious suggestion but it can be easy to overlook or to do overly subtly Library administrators are often barraged with needs requests and problems clearly calling out a link to established priorities makes it easier to say yes The key is to attend to what language the administration is using Is it a university strategic plan An internal library strategic plan An overall zeitgeist In our case the libraries had recently completed a new strategic plan which called out student success and improved reputation as explicit goals which were easily aligned with UX space projects Bringing our requests for support to administration couched in the language of these goals made it clear that we understood their priorities and made it easier for the administration to see how our goals fit with their vision 

Another tactic we took in building trust with the administration was to start addressing small projects based on UX feedback that made relatively modest demands on library resources presenting resultant successes and building to making larger requests By gradually accruing evidence of particular issues over time and by piling up small successes library management can begin to trust that UX projects are impactful and worthwhile Starting with a big ask and little proof requires management to make a leap of faith but starting with lots of proof and small asks makes it easier to move forward Such an approach also mirrors the iterative nature of good UX preventing us from sinking large amounts of resources into projects that still need modifications or might be just right for a particular scenario but not ready for generalization Gullikson and Meyers case study suggests that ready access to UX information can be used to inform and be prepared for new phases of or surprise renovations 2016 in our experience we have been able to respond more confidently to sudden availability of funds of the kind that arise at the end of a fiscal year or when another project falls through 

Finally we found that presenting solutions to identified issues was a useful way of highlighting the positive impact of smaller iterative UX For example it was wellknown that quiet versus conversational zones were a consistent bone of contention across the libraries with students confronting each other or perhaps worse feeling silently more and more frustrated and unable to complete their work One solution students asked for at a branch library was permission signs rather than wanting signs that told them to be quiet students wanted signs that explicitly permitted them to be louder where it was acceptable and suggested quietness where it was not The suggested approach was positive nonpunitive and probably something we would not have thought of without student feedback encouraging that reframing Rather than requesting management fix the problem of loudness we were able to present a solution and ask for assistance with creating a series of signs establishing expectations 

There are however some remaining areas of challenge to keep an eye out for in any organization One is the challenge of identifying the unwritten roles of peers and administrators and taking them into account when developing chains of communication In our case we assumed that it was sufficient if the associate dean in charge of the positions that relate to space communicated necessary actions to those staff However both to make the staff feel integrated into the process and to avoid confusion we realized we needed to loop in staff such as the facilities manager earlier in the process We had begun a project in a branch library which the facilities manager supported but did not extensively work in not realizing that the discarded branch furniture would immediately be distributed in the main library Instead of communicating at an end point we needed to communicate from the beginning of any project because the written facilities manager role differed from the performed role In any situation where new work partnerships are formed it is important to look for moments where written and performed roles might diverge For libraries with multiple locations this is especially important because although locations might operate with great autonomy there is often a ripple effect that might reach beyond what a casual assessment predicts

In an organization of any size without a single individual assigned to space management identifying and making a consistent plan for space priorities is an important challenge We found we were examining spaces in isolation and sometimes ad hoc based on who requests assistance or takes an interest While we have made some improvements to our process with no one person looking at the whole picture of library spaces and prioritizing projects in a programmatic way our UX work will remain somewhat fragmentary However this is an area where we feel that imperfect UX is better than no UXwe will continue to assess what we can Gullikson  Meyer 2016 For libraries with a person or team in charge of the big picture of spaces it is important for UX researchers to tap into that expertise and join forces

Finally it is important to realize that trust building works both ways and when possible call out when administration may not be consistent We found policies were occasionally inconsistent for example one branch library was allowed to purchase a comment box where anothers purchase request was denied Developing an approach to cope with this is useful In our experience and in most functional organizations this inconsistency is more a matter of lack of understanding so being prepared to explain clearly and patiently why particular support is needed and give the benefit of the doubt without giving too much ground is important 




With Users

As well as being important to administration small solutions and communicating those solutions are important to building trust with users Providing UX input even with loweffort methods demands users time and effort so it is important to make it clear that we value that time and effort by clearly communicating how their input is used What have we changed what are we working on what is hopefully temporarily currently insoluble For example results from the reply cards coupled with observations of the space made clear that users spend lengthy amounts of time studying in the research area and students requested more quiet space during finals since the commons were too loud at that time This request has led to additional investigations into extending library hours as well as exploring extending the commons space itself to encompass a quiet area but it also served as justification for opening a library classroom during the last few weeks of the semester and during finals as an additional space for quiet study Providing an immediate response like opening a classroom while slowly amassing enough evidence to take longerterm action builds trust with our users that the feedback they give us is valued and applied



Conclusion

By combining several loweffort techniques librarians can begin to integrate a consistent approach to UX even with minimal institutional support Indeed this approach can be used to build institutional support and begin to move towards a more mature integration of UX into libraries building organizational trust both between colleagues with administration and with our users Doing so positions libraries as active participants in the maturing field of UX preparing the ground perhaps for more established collaborations and positions

The past few years of building up a user experience program at our institution and developing organizational buyin has resulted in some positive changes We find that colleagues across the organization now ask if there are reports or data from user experience projects that can assist in decision making Recently a Web Governance Group was created to oversee consistent iterative improvements of the library web presence This group is comprised of five representatives from across the libraries One spot is designated for a UXWG representative While this is a step in the right direction this seat is the only one not aligned with any one persons job duties So while we have made great strides in getting UX work to be a part of our library workflows we still face barriers in that it is no one persons job to coordinate the many projects and determine a longterm vision However we believe that the gradual increase in the groups presence and visibility are helping to engrain UX into the libraries and prepare for an eventual more centrally managed UX approach

References

	Asher A D  Miller S 2011 So you want to do anthropology in your library Or a practical guide to ethnographic research in academic libraries Retrieved November 21 2017 from httpwwwerialprojectorgpublicationstoolkit

	BrownSica M Sobel K  Rogers E 2010 Participatory action research in learning commons design planning New Library World 11178 302319 httpsdoiorg10110803074801011059939

	Foster N F Ed 2013 Studying students a second look Chicago Association of College and Research Libraries a division of the American Library Association
	Foster N F  Gibbons S Eds 2007 Studying students the Undergraduate Research Project at the University of Rochester Chicago Association of College and Research Libraries 
	Godfrey K 2015 Creating a culture of usability Weave Journal of Library User Experience 13 httpdxdoiorg103998weave125356420001301

	Gullikson S  Meyer K 2016 Collecting space use data to improve the UX of library space Weave Journal of Library User Experience 15 httpsdoiorghttpdxdoiorg103998weave125356420001502

	Head A J 2016 Planning and designing academic library learning spaces Expert perspectives of architects librarians and library consultants Retrieved from httpspapersssrncomsol3paperscfmabstractid2885471

	Kavanagh Webb K Rhodes T Cook E Andresen C  Russell R 2016 Our experience with user experience Exploring staffing configurations to conduct UX in an academic library Journal of Library Administration 567 757776 httpsdoiorg1010800193082620151109892

	Khoo M J Rozaklis L Hall C  Kusunoki D 2016 A really nice spot Evaluating place space and technology in academic libraries College  Research Libraries 771 5170 httpsdoiorg105860crl77151

	Kim Wu S  Lanclos D 2011 Reimagining the users experience An ethnographic approach to web usability and space design Reference Services Review 393 369389 httpsdoiorg10110800907321111161386

	Lanclos D  Asher A D 2016 Ethnographish The state of the ethnography in libraries Weave Journal of Library User Experience 15 httpsdoiorghttpdxdoiorg103998weave125356420001503

	MacDonald C M 2017 It takes a village On UX librarianship and building UX capacity in libraries Journal of Library Administration 572 121 httpsdoiorg1010800193082620161232942

	Marquez J J Downey A  Clement R 2015 Walking a mile in the users shoes Customer journey mapping as a method to understanding the user experience Internet Reference Services Quarterly 2034 135150 httpsdoiorg1010801087530120151107000

	Nichols J Bobal A  McEvoy S 2009 Using a permanent usability team to advance usercentered design in libraries EJASL The Electronic Journal of Academic and Special Librarianship 102 Retrieved from httpirlibraryoregonstateedujspuihandle195712686

	Somerville M M  BrownSica M 2011 Library space planning A participatory action research approach The Electronic Library 295 669681 httpsdoiorg10110802640471111177099

	Somerville M M  Collins L 2008 Collaborative design a learnercentered library planning approach The Electronic Library 266 803820 httpsdoiorg10110802640470810921592

	Westbury M 2016 UX and a small academic library In A Priestner  M Borg Eds User Experience in Libraries Applying Ethnography and HumanCentred Design pp 137144 New York Routledge





Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS
























































A Method of Improving Library Information Literacy Teaching With Usability Testing Data


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










A Method of Improving Library Information Literacy Teaching With Usability Testing Data




Catherine Baird and Tiffany Soares

MONTCLAIR STATE UNIVERSITY



Skip other details including permanent urls DOI citation information
Volume 1 Issue 8 2018



DOI httpdxdoiorg103998weave125356420001802



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













This paper was refereed by Weaves peer reviewers

This article is licensed under a CCBYNCSA 40 license


Abstract


Usability testing is a commonplace practice in many academic libraries but the data produced during the course of usability testing have many more stories to tell if given the chance Not only can the data help us improve our users online experience as they engage with our website and search tools but it can tell us about how our students search and research and what motivates those choices That kind of data can guide our information literacy practices to be even more successful This article describes the methodology used to analyze usability testing data for insights into information literacy teaching under the auspice of an IRBapproved study It concludes that usability testing data can be analyzed and reused to help bridge gaps and make connections between different library departments and roles and to motivate change in teaching practices that are informed by observations of local user behavior 


Introduction

In one room of your library a group of librarians and staff gathers to observe this months usability tests They are deciding on changes they can make to the library website to improve the experience for student users Down the hallway a different group is meeting to analyze the interview data theyve collected of students describing their research process This group is deciding on changes they will make to their teaching practices to improve the learning experience for student users These two groups may have more in common than they think including common practices and goals We contend that they also produce information that can enrich each others work Yet in most libraries these two groups are largely disconnected and sometimes they can even be at odds

Which is a better use of limited staff time teaching information literacy or structuring information systems to make information seeking more successful Are teaching librarians focused on teaching users to navigate complex systems and search tools when these could actually be made much simpler Are web librarians oversimplifying the search interfaces and therewith the search process of users Does good design make the teaching librarians role redundant Does good teaching make the web librarians role redundant These questions dont have to invoke a sense of rivalry between different library positions and areas of responsibility This article highlights one way in which the focus on the user can lead to mutually beneficial collaborative and productive opportunities that strengthen collegial relationships and ultimately improve a variety of user experiences including the experience of the user engaging in information literacy learning

At Montclair State University our usability team members were meeting each month to discuss current usability tests and make changes to our website However we soon noticed that we were observing behaviors in our data that could also provide us with useful insights for our teaching In the sections that follow we will describe how we reused the usability testing data analyzing and mining it for insights related to information literacy teaching 

Since usability testing participants followed a thinkaloud protocol the data we had collected were much like oneonone interviews with the participants describing their actions and thoughts while the interviewer probed for deeper understanding or clarification The result was hours of data very similar to the data that might be collected during a qualitative information behavior research study This is important because although some libraries might not have the resources to conduct a standalone information behavior research study they might be able to collect and analyze their usability testing data to inform information literacy teaching 

In the following sections we will review existing literature relevant to the crossover between information literacy teaching and usability testing We will also discuss in depth the methodology we used providing specific examples and lessons learned throughout the process Finally we will introduce some of the new knowledge and understandings we gained from mining our own usability testing data set at Montclair State University and how we used this information to help advocate for local change Though our sampling method was not designed to produce generalizable results to the broader population we describe these details as a way to make more vivid the usefulness of this methodology 

Literature Review

User experience literature focuses on employing data collected from users to change and improve the design of a system or experience so that the user can move more independently and successfully through an experience Similarly information literacy literature pays attention to the design and process of a learning experience so that a learner can navigate more independently and successfully the world of information The Association of College and Research Libraries defines information literacy as the set of integrated abilities encompassing the reflective discovery of information the understanding of how information is produced and valued and the use of information in creating new knowledge and participating ethically in communities of learning 2015 

Many studies on information literacy have explored students search practices often utilizing a methodology that involves recording andor observing the search process a thinkaloud protocol and sometimes probes or questions Holman 2011 Porter 2011 Bloom  Deyrup 2015 Valentine  West 2016 Finder Dent  Lym 2006 Dalal Kimura  Hofmann 2015 The methodologies employed in these information literacy studies are similar to what takes place during the course of a typical library usability test Of course this is not the only type of methodology used to better understand student behavior Other large and smallscale library and information literacy and behavior studies use different methodologies such as indepth interviews surveys and focus groups Lee 2008 Head  Eisenberg 2009 Duke  Asher 2012 Thomas Tewell  Wilson 2017 Finder Dent  Lym 2006 Clearly we still need studies of user behavior that employ other methodologies but it is important to capitalize more fully on data that our organizations may have already collected such as usability testing data 

For example Janyk 2014 describes using her institutions Google analytics data collected from the discovery layer service to better understand users search behaviors She concludes that this type of qualitative data can be used by librarians who teach information literacy focusing their attention on ineffective search habits Janyk is not alone in linking student search behaviors to library teaching Some other researchers have also previously drawn connections between usability testing and library teaching and instructional practices Graves  Ruppel 2007 In their 2002 article Vassiliadis  Stimatz advocated for instruction librarians to become more involved with usability projects and website redesign initiatives Many authors of online tutorials and learning objects have used usability testing techniques to test the tutorials and learning objects they have created Bury  Oud 2005 BowlesTerry Hensley  Hinchliffe 2010 Lindsay Cummings Johnson  Scales 2006 Usability testing has even been used following library instruction activities to assess the effectiveness of library instruction and teaching Novotny  Cahoy 2006 Castonguay 2008 Lee  Snajdr 2015 The above literature acknowledges but does not expand upon the relevance of usability testing initiatives data and methods to library teaching In most cases the relevance of usability testing results to teaching is glossed over in a short paragraph or a few sentences 

In Turners 2011 study and in Valentine  Wests 2016 study both usability testing studies the authors comment at more length on the implications of their findings for library instruction programs and practices Turner concludes that the different categories of users librarians library staff and students approached searching with different mental models and expectations influenced by what they knew or didnt know about the structure of information and the tool they are using for search She suggests there are applications for her study for instruction and reference but only very briefly Valentine  West go further and discuss how their usability testing initiative sparked changes in librarian teaching moving it to more of a conceptual level 2016 p 192 More generally they advocate for teaching librarians to conduct usability testing themselves in order to inform their teaching

While most of the studies we have discussed have referenced the connection between usability testing and information literacy only in passing we are making it the focal point of our article In doing this we are hoping to make connections between silos that have formed within the academic library community bridging a gap between teaching librarians information literacy instruction reference and web librarians and UX librarians We contend that web usability data can provide the teaching librarian with a constant stream of data that illustrates current user practices behaviors and strategies in the context of their own librarys website and online search tools discovery layer catalog databases research guides etc Rather than conducting a separate information literacy study the teaching librarian can benefit from the data collection that the web librarian has already completed or better yet from getting involved in the data collection itself Given limited resources in academic libraries where budget and time do not always allow for regular information literacy research projects this practical reuse of usability testing data can help us better understand our users and therefore teach more effectively As we will detail below ideally usability testing data collection would be a collaborative initiative providing both the web librarian and the teaching librarian the understandings they need to improve the user experience in the classroom and on the library website

Methodology

The usability testing data described in this article was collected under the auspice of an Institutional Review Board IRB approved study in which data were collected over the course of 22 months between March 2015 and December 2016 by the library website usability team all members of the IRBapproved research team We recommend that all members of your web usability team are also members of the research team so that they can work with the data for research purposes If you are embarking on a similar project ensure your IRB protocol is written in a way that gives you a bit of flexibility For example you might initially plan to do usability testing exclusively with students but if you say in your IRB proposal that you will work with members of the university community it gives you the opportunity to decide to do testing with faculty and staff Our IRB protocol clearly stated that we would keep the recordings and transcriptions rather than discard the recordings after they had been transcribed Had we made a different decision when writing the IRB protocol we wouldnt have been able to return to the recordingsdata to look at them more thoroughly


Data Collection and Transcription

The team had a goal of conducting three usability tests per month with members of the university community The website usability team is made up of six librarians from the following library areas Access Services Reference  Instruction Cataloging  Archives and Government Documents Half of the members of the usability team teach information literacy to students on a regular basis conduct reference and research consultations and regularly create and contribute to library research guides This mix of people and their different perspectives proved to be extremely useful for the team 

One area in which diversity was helpful was in formulation of the test questions Each months usability test questions were scripted collaboratively in advance by the members of the website usability team The content of each test varied from month to month but often participants were asked to find a source eg an article a book in the context of a particular fictional assignment Some tests involved participants selecting a database to search while others asked participants to perform more informational tasks such as finding a subject librarian or finding the library hours on a certain day The collaborative scripting was important since it helped us craft good questions often drawn from reallife scenarios observed by members of the team during their interactions with students The diversity of our team with members from different library departments also enabled us to craft multiple followup questions we called them probes which helped us better understand what motivated the users choices For example once a student successfully identified an article to use for their fictional assignment we might probe as to why that particular article was chosen over others or we might ask what type of information the student thought the article would help them with eg background information developing an argument piece of evidence

The recordings 33 tests at 30 minutes each were transcribed by the usability team and student researcher position funded by an internal grant the latter also a member of the research team We recommend hiring a student with strong language skills eg linguistics languages communications and presenting it as an opportunity for a student to participate in a research project If youre requesting this extra student support through your library administration highlighting the benefits to the student in terms of gaining firsthand experience on a research project a potential author credit and increased student engagement might be a compelling argument and can help your request for resources stand out The student coauthor and the lead author did the bulk of the transcribing with the assistance of Otranscribe a free Chrome extension that facilitates transcription eg keystroke shortcuts for startingstoppingtimestamps and automatically rewinding by a few seconds when playing after pausing On average it took us 90120 minutes to transcribe a 30minute test We also included descriptions of screenrecorded activities enclosed in square brackets in our transcriptions This sped up the process of prereading each transcript in preparation for analysis rather than watching the recording in its entirety We recommend starting with 1015 interviews which will be less work in terms of transcription and coding You may do more or fewer if you find you are still uncovering interesting themes or if you are starting to see a lot of repetition in your coding and less development of themes in which case youve likely reached a good time to stop

We recommend choosing unique file names for each transcript Transcript 1 Transcript 2 etc and within each transcript use unique speaker codes for individual speakers I1 for interviewer I2 for second interviewer PtSt1016 which stood for student St participant Pt 10 from 2016 Align participant numbers with transcript numbers The speaker codes come in handy when you are analyzing your data and comparing themes across participants It is important to make decisions about speaker codes as early in the process as possible and ideally before transcription begins so that the speaker codes can be created and inserted during the transcription process Deciding on speaker codes after transcription will result in returning to all of your data to clean up these codes In addition if you make use of Words heading styles in your transcript files you can automatically identify and autocode participant speech and interviewer speech as long as you have applied different heading styles to these sections of your transcriptions

Keep in mind that when using fictional scenarios as we did you are relying on the participants to act as if they are experiencing a particular scenario It is possible that our participants did not take these scenarios seriously or that they made up their responses in order to please the interviewers In order to mitigate such effects we tried to establish a rapport with participants during the interviews to put them at ease We made it clear that we wouldnt be offended by any of their comments even if they were negative We also emphasized that it was useful for us to know where their pain points were when using the library website to accomplish an informational task or to do research since understanding their perspective would help us to make improvements 




Software

Initially we tried doing our analysis without using specialized software ie using spreadsheets but we needed the functionality of keeping track of the codes and coding hierarchy across all of our transcripts which the spreadsheet software did not do for us We therefore decided to use qualitative data analysis software called NVivo for coding and analyzing the data You begin by importing all of your transcripts into an NVivo project and as you do close readings of each text and annotate them the software enables you to easily capture your codes and coding hierarchy We equate it with using different colored highlighters on a print transcript to denote and collate different themes as you find meaning in your data There are a few different software options that work similarly to NVivo1 We chose NVivo since it is used by other researchers on our campus and is better supported on our campus than other options You may be able to get a free copy of NVivo or another qualitative data analysis software tool from your institutions IT department If not a license costs a few hundred dollars You can also look into comparable qualitative data analysis software that is available via a monthly subscription services eg Dedoose 

The time and effort it took to learn the NVivo software was well spent as it saved us time in the long run and made the data easy to query Regardless of what qualitative data analysis software you choose we feel the most important thing is to make sure you have adequate support eg experts who have used the software access to free training materials We made a lot of use of the free NVivo webinar series online training videos and user manual2 Our student assistant was able to complete some of this training independently which was yet another time saver If you are new to this type of software expect to devote a bit of time at each stage of your project to software training We suggest setting up a test project with a sample of your data and taking the time to play with the software to become familiar with how it works It isnt particularly complex or difficult but the few hours you spend with a test project will save you from making mistakes later

Yet another advantage of using NVivo was the ability to link our survey information with our transcripts As mentioned above in our discussion of transcription speaker codes allow you to easily store some demographic information eg status  student but not everything We used NVivo Cases an NVivo feature that allowed us to tag transcripts with the participants demographic information in order to manage all of the survey data we had collected We recommend collecting the following information from each participant status eg faculty staff student year of study eg freshman sophomore majordepartment affiliation experience using the library website multiple questions and whether or not they had used certain library services eg reference library instruction session oneonone research consultation We collected this demographic information through a short online survey included in our IRB application that participants completed before the usability test 

Linking demographic information to the transcripts is useful because it allows you to easily query your data to compare participant behaviors across specific attributes For example we were curious to see how freshmen and seniors differed in their use of our research guides Since we had coded our transcripts for website location eg research guides we could quickly perform an NVivo query and focus our investigation to data we had collected in which freshmen or seniors were using research guides




Qualitative Coding

We decided to analyze our usability testing data as if it were data collected during a qualitative interview of an information behavior study Themes emerged organically as we did a close reading of each transcript while sometimes reviewing parts of the screen capture and audio recording We annotated or coded chunks of the transcripts as we observed these themes of importance and identified meaning in the data We chose to code inductively creating codes and coding based on our observations rather than deductively creating a set list of codes ahead of time and applying the codes to the data since this was our first time approaching this kind of data set in this way We wanted to ensure that we didnt limit our observations and analysis by sticking to a set list of codes as we werent sure what to expect from the process We will discuss the iterative process of uncovering themes in more detail below but generally it meant that we might uncover a code in one coding session and could return to it later as we noticed patterns across different participants 

We applied two different types of codes thematic and descriptive codes As mentioned above thematic codes emerged from observing meaning in the data whereas descriptive codes identified a specific chunk of a transcript having to do with a specific section of the website or a specific participant task The two coding schemas reflected the dual purpose of the research to improve teaching as well as improve the website The thematic codes were of more interest to the teaching librarians whereas the descriptive coding made the data more useful for the website usability teamresearch team to return to and utilize We did both kinds of coding simultaneously as we were sifting the data

For example we uncovered a theme and created a corresponding thematic code called Time which we used whenever a participant indicated or demonstrated that they were taking their time or the opposite that they were rushing or that they demonstrated patience or impatience both timerelated phenomena Eventually we established a hierarchy under the Time theme dividing it into subcategories After we had applied these codes to all of our transcripts we could query all of the transcripts to compare Time and the subcategories of Time across multiple subjects 

An example of a descriptive code we used was website location codes If our participant was doing a task on the Database AZ page we would code that chunk with Database AZ so that later we could easily pull out all of the sections of the different transcripts where participants were using the Database AZ section of our website 

This method of multipurpose coding was not carried out with the intent that we would code all of the website usability data in such a manner on an ongoing basis Few academic libraries would have the resources to sustain such a project On average a 30minute usability test took us 6090 minutes to code However we envision taking the time every few years to repeat this project delving deeply into a sample of new usability testing data coding that data though likely reusing much of the same coding terminology and structure to create a snapshot that eventually we can compare with other snapshots on a longterm basis 




Descriptive Coding

Given that library website usability testing data likely have many similarities eg in terms of tasks webpage search tools between different institutions we are listing some descriptive coding conventions here that we believe will be useful to others pursuing a similar project The following descriptive coding for participant website location and task can easily be done by a trained student employee We have found these descriptive codes useful when we want to pull up different parts of different transcripts and compare for example how participants approached a particular task eg Find Book in Catalog

To begin we coded all participant speech in each transcript with a descriptive participant code Participant and then with the same unique speaker code as used in the transcripts PtSt1216 Primarily these codes were used when we later compared behaviors tasks and themes across different participants An extra benefit of having our transcripts marked up using these participant codes was the ability to quickly run an analysis to see how much of a given transcript was participant speech and how much was interviewer speech This let us know whether or not the usability testing interviewers were speaking too much during a usability test 

	Sample Participant Codes
	PtSt115 student participant ID1 from 2015
	PtSt215 student participant ID2 from 2015
	PtSt3316 student participant ID33 from 2016


Next we coded each transcript for website location and task These codes are used to mark up sections of each transcript where participants are using a specific section of the website or where they are performing a specific task such as finding a book on reserve or requesting an item through interlibrary loan Usually these codes mark up a long chunk of text and thus encompass both participant and interviewer speech and retain the conversation and context 

	Sample Descriptive Website Location Codes
	Homepage
	Catalog
	About the Library page
	Contact the Library page
	Hours page
	Database AZ page
	EDS Search
	Journals AZ Search
	Research Guides
	Library Instruction page
	Archives
	Descriptive Task Codes
	RequestILL
	FindReserve
	FindBook
	FindArticle


In addition to these descriptive categories of codes two other descriptive coding trees coding hierarchies were also used very frequently in our analysis Terminology and Notices The terminology coding tree had three branchesclear unclear and incorrect use respectively when the participant expressed that a term was clear when the participant expressed that a term was unclear and when the participant expressed that a term was clear but nonetheless demonstrated an incorrect use Terms were then divided by location of occurrence For example the term Library Instruction when seen by student participants from our library homepage was often an unclear term so those sections of the transcript that demonstrated this would receive the following coding columns 24 represent childnested node layers 

Table 1 Coding for sections of the transcript that used the term Library Instruction

	
Parent Code

	
Child Code 1st level

	
Child Code 2nd level

location

	
Child Code 3rd level

term


	
Terminology

	
Unclear

	
Library Homepage

	
Library Instruction




Retaining the location allowed us to see if context had any impact on the clarity of terminology The Notices coding tree similarly used location divisions For example if a participant noticed leftside limits in the library catalog the coding would be 

Table 2 Coding showing patron awareness of leftside limits in the library catalog

	
Parent Code

	
Child Code 1st level location

	
Child Code 2nd level


	
Notices

	
Catalog

	
Left Limits




The coding conventions as discussed thus far are largely descriptive in nature They address questions of who is doing what and where Other descriptive codes included FailureSuccess used and subdivided to describe moments of failure or success during the usability test and Aesthetic subdivided into categories such as likes pictures likes simple cluttered Thematic codes which identified observed themes often looking at the why and how of a particular behavior will be discussed next 




Thematic Coding

We marked up our transcripts with thematic codes codes which were a result of analytical or interpretive observations of our transcripts as we noticed meaning in the data This was work that could not be done exclusively by a student assistant While coding for themes it helped us to view this coding through the lens of answering how and why questions about participant behavior If we noticed an interesting moment in a transcript we paused to ask ourselves how the participant was behaving or why the behavior was happening and we created codes that captured these themes For example two codes emerged called Research for Learning and Research for Citing These codes were used to capture moments in the transcripts where participants demonstrated that they saw research as a process of learning and discovery or as a process to simply find sources to cite See Ryan and Bernard 2003 for more information about identifying themes in qualitative research



Uncovering Themes


Search Mechanics

The first theme we will discuss from our own research is one we called Search Mechanics We observed a group of strategies and actions employed by participants which we initially coded simply as mechanics We treated this as a descriptive group of codes to describe what participants were doing but we soon became more caught up not just with what they were doing but how they were doing it This group of behaviors included the mechanistic use of filters such as the peerreview full text or date check boxes each identified with a unique code In these instances the actions seemed to be performed in a rote or habitual manner From a usability perspective it was excellent that these features were being used without difficulty However the automatic manner in which participants sometimes used these limits suggested that they were not thinking about why they selected these limits and how this impacted their research 

As we encountered this theme repeatedly in our data we collated our ideas and insights in an NVivo Memo simply a place in your NVivo project where you can keep track of your analysis while linking it to your coding and data We used the Search Mechanics Memo to come back to the theme each time we noticed it in a transcript and continued to write and expand upon it throughout our analysis Using this memo we developed a narrative around Search Mechanics which we essentially were able to then use as the basis for a pitch in meetings with colleagues when discussing opportunities for improving information literacy teaching 

While our observations of search mechanics werent new or surprising what was useful was we now had evidence to advocate for a change in our local teaching practices When librarians are teaching classes at our library they often choose to highlight at least a few mechanics of search eg demonstrating how to use filters to limit search results Armed with the evidence from our research we were able to increase the use of some recently created online instructional videos that highlighted search mechanics and had them embedded in the learning management systems of key courses While there was some concern that this would in the minds of our faculty negate the need to bring their classes to the library in fact this has not been the case 

Another behavior we coded repeatedly and included under the Search Mechanics theme was participants habitual use of a search box for an unintended purpose For example the search boxes on our Journals AZ list and Research Guides homepage respectively are not meant for traditional topic keyword searching However we saw participants consistently use the available search boxes for this purpose It repeatedly failed participants but they often persisted with the same strategy over and over again On one hand with respect to the user experience this prompted the website usability team to reconfigure access to our Journals AZ list and remove search boxes from individual research guides But on the other hand with respect to information literacy teaching these observations gave us pause in regards to our teaching strategies Once again we were able to use this evidence to encourage librarians to begin to incorporate teaching activities that shifted the learners awareness to a metacognitive space 

Good search mechanics alone will not necessarily lead students to successful search outcomes but they are useful if not critical to master given the mass amount of information contained in academic databases and other search tools For some of our participants the mechanics of search seemed markedly difficult and to occupy most of their available cognitive energy This impeded a successful search and therefore it is clear that avoiding teaching search mechanics entirely is also not a good strategy Now instead of simply brainstorming a list of key terms to use in a given search box during instruction sessions or research appointments we also try to elicit a metacognitive moment so that our students think about why they are searching what they are searching and what their expected results are before they type keywords into a search box




Flatness

Another Memo we developed throughout our analysis and eventually identified as a theme we called Flatness short for Information Flatness Many of our participants demonstrated a flat conceptual model of the library website and the many information structures it provides access to such as databases and individual publications such as journals magazine and news sources When they searched from the library website they were simply searching the database Many participants used language that implied a lack of understanding of the depth and organization of the information structures they were using Not only was the terminology eg jargon such as database and journal unclear to them they also didnt understand the relationship between these things Furthermore those who exhibited flatness tended to treat all information they encountered equally which negatively affected their ability to select useful sources They simply made selections based on the availability of a fulltext PDF file Some participants demonstrated a flat conceptual model until they began talking about citing At that point the participant recognized that understanding what they had in front of them was important but it only was viewed as important if they planned to cite the source

Once again this was not all new information Mental models and how they relate to search have been explored by a number of library studies both information seeking research studies and usability studies Holmans 2011 research concludes that students dont possess a strong mental model of search and that this negatively impacts a successful outcome Lees 2008 research study on information structures and undergraduates concluded that students had knowledge of only a few search tools 217 and they preferred resources that were immediately and conveniently accessible 2008 p 217 Similarly in their 2011 usability testing study Swanson  Green remarked that Users do not appear to be very aware of differences between databases catalogs and other tools  As results for different types of sources are comingled the users ability to recognize the differences between results becomes more important for the successful use of the library website 227

Combing through the data in such detail however really opened up our eyes as to how widespread across our sample these behaviors and understandings were We had understood many of these things before yet we hadnt fully enacted this knowledge to change how we taught Of course we often talk about teaching practices but with this methodology we first looked at behaviors and grounded our ideas about teaching in the context of the data we were seeing Its a small shift but for us it was important because it helped actually galvanize change 

We noticed that the thinkaloud protocol used in our usability testing forced a moment of metacognition that many novice researchers are not likely used to engaging in It is exactly this process of reflection that we think will help a novice researcher to unflatten their conceptual model and so we sought ways that we could use this in our teaching For example when teaching students within a particular discipline we are devoting more time and teaching activities to exploring the list of databases available for use within a given subject area If users dont understand that databases are essentially containers of different types of information they will be unlikely to use them A teaching strategy that has been useful in this regard is having students draw their research process andor visually depict a specific search tool they are using This type of visualization activity inevitably contributes depth to their mental model of the information structures they are encountering during their research process Mayer  Anderson 1992

Contemplating flatness also has made us rethink our library research guides Since our research guides list what we now understand may be unrecognizable information structures such as individual journal titles databases and other search tools it makes sense that users are not likely motivated to use them Understanding how to use a research guide requires the understanding that its an intermediary tool that points to other information containers databases journals and search tools Some of our participants expected a research guide to act like a database They thought that they should be able to use search limits within a guide so that they could access directly the content they were seeking such as articles and statistics We recognize from a usability perspective that the search boxes on our research guides are most likely being used incorrectly and we plan to remove them From a teaching perspective we no longer treat research guides like selfexplanatory web pages that are intuitive to use for research At a minimum when using research guides in our teaching we need to model how they can be useful and use the guides to help address the potential flat model of information that our students might possess 

Clearly the themes that we observed in our local data are not new information to the field The above studies both research studies and a usability study suggest similar conclusions However the point of the methodology explored in this article is to highlight how local data can be reused to provide opportunity for conversations between different library areas and facilitate change in library teaching practices 



Conclusion

Teaching is often an independent activity and bringing about changes in teaching practices can be a challenge To change teaching practices you need to change teachers minds To change teachers minds it helps to have evidence Slowly we are seeing a culture shift at our library Before this project it was common for opinions to be expressed as just that opinions But now usability testing data often get invoked in meetings when we are discussing issues or problems we are trying to solve For example our librarians knew that good search mechanics were important and therefore we devoted some time to that when teaching Systematic review of the usability testing data ie our descriptive and thematic coding revealed that good search mechanics were important but often failed our students when they lacked a deeper understanding of research and saw it as a simple exercise of matching keywords in their topic to keywords in an article title

For many academic libraries motivating a change in practice or use be it space a service or teaching philosophy can be difficult The ability to produce compelling and local evidence to support new ideas or create a change in practice is powerful and that is where we see some of the greatest potential for our data analysis in the local context We are not suggesting that this method should or could replace rigorous research investigating user information behavior However when time and resources do not permit for such an investigation usability testing data can serve as a convenient and useful data set that can be used to enhance understanding of user behavior and apply that understanding wherever it is needed

We also see value in the process of analyzing the data by a team of people from across library divisions or departments The careful study of existing data provides unanticipated opportunities to inform other areas of library operations and there is great potential for enriching crossdepartmental conversations focused around observations of user behavior One of the advantages of looking at these data through the methodology described in this paper is the opportunity for people from different library areas not traditionally involved with usability testing and user experience initiatives to have the chance to deeply engage with the data and apply it to a practice a service or an initiative from a different perspective In this case we focused on information literacy teaching but there are potentially other areas where it could be useful eg eresources discovery team 

 That being said the most time intensive component of this project was also the process The method discussed in this article recycles preexisting data but can be very time intensive in terms of data organization preparation and analysis The task of coding and analyzing the amount of data generated from even fifteen 30minute usability tests is substantial If you decide to embark on a similar project to this one we would recommend either taking a snapshot of your data ie focusing on a few consecutive months worth of usability tests or selecting random tests from a larger pool of data collected over a longer period of time eg selecting one test from each month if you are conducting regular usability tests We found that after analyzing 1520 tests we had seen clear themes emerge and were beginning to see much repetition in our data analysis and were finding more and more examples of our themes but few new themes You may find you reach this point of saturation even earlier eg after 710 tests If you are pursuing this methodology we recommend you emphasize quality over quantity Transcribe and code fewer usability tests but do a thorough job of the ones you do We found the role of the student researcher coauthor invaluable and were able to get a small internal research grant to compensate the student Consider also the possibility of student labor to help with aspects of the project 

In terms of frequency we envision repeating this analysis every few years in anticipation that changes in user behavior interface design and instructional practices happen incrementally over a longer period of time We anticipate that having established a coding structure and familiarity with qualitative software in our case NVivo future projects will be less resourceintensive

Acknowledgements

The authors wish to acknowledge the members of the website usability team at Montclair State University for their work writing conducting and transcribing usability tests as well as their contributions to the initial data analysis and for many fruitful discussions Paul Martinez William Vincenti Darren Sweeper Denise OShea and Siobhan McCarthy

References

	Association of College and Research Libraries 2015 Framework for information literacy for higher education Retrieved from wwwalaorgacrlstandardsilframework

	Bloom B  Deyrup M M 2015 The SHU research logs Student online search behaviors transscripted Journal of Academic Librarianship 41 593601
	BowlesTerry M Hensley M K  Hinchliffe LJ 2010 Best practices for online video tutorials A study of student preferences and understanding Communications in Information Literacy 41 
	Bury S  Oud J 2005 Usability testing of an online information literacy tutorial Reference Services Review 331 5465 
	Castonguay Remi 2008 Assessing library instruction through web usability and vocabulary studies Journal of Web Librarianship 223 429455 doi 10108019322900802190753

	Dalal H A Kimura A K Hofmann M A 2015 Searching in the wild Observing informationseeking behavior in a discovery toolACRL 2015 Proceedings Portland OR ACRL Retrieved from httpwwwalaorgacrlsitesalaorgacrlfilescontentconferencesconfsandpreconfs2015DalalKimuraHofmannpdf 

	Duke L M  Asher A D 2012 College libraries and student culture What we now know Chicago American Library Association 
	Finder L Dent V F  Lym B 2006 How the presentation of electronic gateway pages affects research behavior The Electronic Library 246 804819
	Graves S  Ruppel M 2007 Usability testing and instruction librarians A perfect pair Internet Reference Services Quarterly 114 99116
	Head A J  Eisenberg M B 2009 Lessons learned How college students seek information in the digital age Project Information Literacy Seattle WA 2009 Retrieved from httpspapersssrncomsol3paperscfmabstractid2281478

	Holman L 2011 Millennial students mental models of search Implications for academic librarians and database developers Journal of Academic Librarianship 371 1927
	Janyk R 2014 Augmenting discovery data and analytics to enhance library services Insights 273 262268 httpdoiorg10162920487754166

	Lee H 2008 Information structures and undergraduate students The Journal of Academic Librarianship 343 211219
	Lee Y Y  Snajdr E 2015 Connecting library instruction to web usability The key role of library instruction to change students web behavior Retrieved from httpsscholarworksiupuieduhandle18057291

	Lindsay E B Cummings L Johnson C M  Scales B J 2006 If you build it will they learn Assessing online information literacy tutorials College  Research Libraries 675 429445
	Mayer R E  Anderson R B 1992 The instructive animation Helping students build connections between words and pictures in multimedia learning Journal of Educational Psychology 4 444452
	Novotny E  Cahoy E S 2006 If we teach do they learn the impact of instruction on online catalog search strategies portalLibraries and the Academy 62 155167 doi101353pla20060027

	Porter B 2011 Millennial undergraduate research strategies in web and library information retrieval systems Journal of Web Librarianship 54 267285 doi101080193229092011623538

	Ryan G W  Bernard H R 2003 Techniques to identifying themes Field Methods 151 85109
	Swanson T A  Green J 2011 Why we are not Google Lessons from a library website usability study The Journal of Academic Librarianship 373 222229
	Thomas S Tewell E  Willson G 2017 Where students start and what they do when they get stuck A qualitative inquiry into academic informationseeking and helpseeking practices The Journal of Academic Librarianship 433 224231 httpsdoiorg101016jacalib201702016

	Turner N B 2011 Librarians do it differently Comparative usability testing with students and library staff Journal of Web Librarianship 54 286298
	Valentine B  West B 2016 Improving Primo usability and teachability with help from the  users Journal of Web Librarianship 103 176196
	Vassiliadis K  Stimatz LR 2002 The instruction librarians role in creating a usable website Reference Services Review 304 338342




	 See more options in this guide to qualitative data analysis including ATLASti MAXQDA QDA Miner HyperRESEARCH

	 See also Using Software in Qualitative Research a Step by Step Guide 2014 by Silver and Lewins 






Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS






















































A New Call for Submissions


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










Dialog Box A New Call for Submissions




A Scarlet Galvan

WEAVE EDITORIAL TEAM



Skip other details including permanent urls DOI citation information
Volume 2 Issue 1 2019



DOI httpdxdoiorg103998weave125356420002103



Creative Commons 40 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 40 International License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













Dialog Box was created at Weaves founding with the goal to extend beyond the traditional book review section and feature critical dialogue not only with books but with other media that set the boundaries of library user experience As new editors settle into our roles with the journal we reconceive our original aims 

Dialogues about user experience should reflect the possible and not the predominant The boundaries of UX are fluid broad and impact most aspects of work in libraries regardless of our official job duties or the spaces we are permitted to occupy Weaves voice has limitations with our current editors and board reflecting majority white and middle class values with most of us holding permanent positions at privileged institutions These limits influence which narratives shape UX 

Dialog Box offers a broad invitation to library workers and others who may not view themselves as UX people In particular we are interested in pieces which avoid the traditional scholarly voice A dialogue is a conversation and taking the opportunity to more broadly conceive of how Dialog Box legitimizes those conversations makes for a richer more inclusive and engaging discussion All of us are practitioners in some form user experience belongs to everyone We invite you to consider your work for submission

This includes but is not limited to submissions taking the form of 

	Email or social media symposium 
	Practitioner interviews
	Intermittent columns
	Ethnographic andor personal narratives
	Interactive pieces artwork zines
	Visual notetaking from conferences
	Thing Explainers that break down difficult concepts and systems 


Addressing topics such as but not limited to 

	Privacy
	Politics of measurement and assessment
	All forms of accessibility
	Implications of UX as an intersectional social justice issue
	UX as a reflection of organizational culture
	Analysis of power labor and organizing in design UX or library systems
	Engaging the concepts of maintenance failure and innovation


We are interested in highlighting work from marginalized groups precarious workers students and other voices absent from these subjects Were here for the challenging and difficult the wellsubstantiated manifesto Wed like to see the draft you cant quite get rid of the thing someone called you brave for writing We want to amplify voices and emphasize the possible 

Submit your pitch or draft through our website or contact us at helloweaveuxumichedu with your thoughts and questions  






Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS
























































Service Design An Introduction to a Holistic Assessment Methodology of Library Services


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










Service Design An Introduction to a Holistic Assessment Methodology of Library Services




Joe Marquez

Reed College

Annie Downey

Reed College



Skip other details including permanent urls DOI citation information
Volume 1 Issue 2 2015



DOI httpdxdoiorg103998weave125356420001201



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













This paper was refereed by Weaves peer reviewers

Abstract


This paper explores service design as a relevant method for service assessment and creation in a library environment Service design allows for a holistic and systemic look at the various systems that make a library function This methodology is a cocreative process conducted with library staff and patrons By working together librarians and patrons can create more relevant services or refine current services to be more effective and efficient



It must constantly be borne in mind that the object being worked on is going to be ridden in sat upon looked at talked into activated operated or in some way used by people individually or en masse If the point of contact between the product and people becomes a point of friction then the designer has failed If on the other hand people are made safer more comfortable more desirous of purchase more efficientor just plain happierby contact with the product then the designer has succeeded Dreyfuss 1950 p 80



Libraries are in a constant state of evolution as we adjust services to better meet user needs Incorporating usercentered changes in the design of services allows libraries to stay lockstep with evolving needs and expectations Librarians have explored a variety of techniques and methods to study and assess user behavior in order to guide changes and improvements to services Usability studies are a common method libraries have used to find out more about how users access and use information These have focused primarily on the interaction between humans and computers but it is also imperative that we study the services and spaces our patrons or customers use Dreyfuss 1950 In recent years libraries have increasingly incorporated traditional anthropological analysis and assessment tools such as ethnographic research into their assessment of library spaces and services in order to better understand the various cultures of libraries and library patrons Duke  Asher 2011 Foster  Gibbons 2010 While this gives libraries a better understanding of user behavior the type of ethnographic research practicing librarians often have time for tends to focus on bits and pieces of users library experiences rather than looking at the entire service ecology of a library and the community it serves Service design a holistic cocreative method puts the user in the center of the service delivery model and focuses on the users entire experience rather than bits and pieces

While still a relatively new field service design and the tools associated with service products are highly relevant to library work The purpose of this paper is to demonstrate the importance of the service design methodology as a viable method for assessing and analyzing service delivery in libraries The paper will also define services and describe the various factors that the authors used to create a successful service design project

What is Service Design


What is a Service

Librarians are not new to designing or assessing services but we tend to develop each service in isolation from the other services we offer and with little to no user input prior to implementation For example circulation policies are usually developed by circulation staff and then distributed to the rest of the library staff Likewise interlibrary loan reference collection development and so on all tend to focus on their own policy development The way librarians typically bring services together is to communicate with one another what each department has decided and then get user feedback by assessing services after they are in place Service design demands that we look at our seemingly disparate services as a whole entity and from users perspectives so that the service is compelling and indispensable and delights the user Heath 2014 para 1

To begin to unpack how to do service design it is important to clarify the meaning of service in this context Services are intangible interactions that are tied to experience According to Kotler 2001 a service is any activity or benefit that one party can offer another that is essentially intangible and does not result in the ownership of anything p 291 Services are the unseen exchanges that happen everywhere and because they are an intangible and cannot be possessed Shostack 1984 they are closely tied to experiences which are highly personal and exist within the mind of the individual Pine  Gilmore 1998 Within the context of service design in libraries the collections and physical space of the library are services in the same way that reference and circulation are services In order to evaluate these services librarians need to focus on users experiences




Service Design a Definition

Service design is a holistic cocreative and usercentered approach to understanding customer behavior for the creation or refining of services Mager  Sung 2011 Polaine Løvlie  Reason 2013 Stickdorn  Schneider 2011 It is holistic in that it views the elements that make up a service or an experience as part of a larger service ecology Under the service design methodology the library as a whole eg the physical and virtual environments as well as all physical service desks or touchpoints defines a service ecology Services do not operate in a vacuum but rather in tandem with other established services When taken as a whole the entire ecology is evaluated and assessed to better inform the experience from the users perspective

Service design is cocreative in that the library design team works with stakeholders eg users and staff to cocreate or refine services that meet or adjust to customer expectations while also working with frontline personnel to deliver a highquality service At the center of the process is the user and insights into user behavior Polaine et al 2013 It is through this lens that services are refined and improvedor even createdto meet user needs and expectations




Service Design and Participatory Design

In recent years there has been an increased focus on the user experience in libraries Recent user studies have emphasized including the user in the design process Foster 2014 Foster  Gibbons 2010 This method is commonly known as participatory design which incorporates the user at the beginning of the design process in order to create a more usable end product It dates back to the 1970s in Scandinavia Holmlid 2009 and was originally used to focus on the work environment Like service design participatory design uses ethnographic methods to get at what users need and how they interact with their environment While not entirely different from participatory design service design diverges slightly in its approach to service in that service delivery is always held as the center of gravity within a specific ecology or environment The aim of service design is to focus on the delivery of service regardless of what the service is In this context the physical space of the library is a service as is the website catalog databases service desks and printing and all of these services inform and interact with one another to influence the total experience of the user

Participatory design and service design share a similar toolkit eg ethnography cocreation journey maps blueprints have a usercentered approach and are relevant methods for approaching a more usercentered library and both methods overlap in how they assess and work with users Service design differs in that it emphasizes the entire ecology in the delivery of service

For example when looking at circulation services consider all of the parts that go into a complete user interaction In this case checking out a book may seem simple on first glance and that it only includes the circulation staff member checking out the book and the user But there are a lot of other elements and people that must be considered The process of checking out a book starts with users walking into the library and searching the online catalog and the final facetoface interaction depends on them being able to find the book on the shelves For the purposes of this paper we are looking at the overall library ecology ie the physical library various touchpoints and all services as a dynamic system of services Felix 2011




Elements of Service Design

Service design is performed through a series of actions focused on observations interviews and activities involving users While there is no prescribed guideline or recipe for which tools or approach to use there are three basic phases to the methodology observation understandingthinking and implementing1 Throughout these phases a design team and users work together to corefine existing services or cocreate new ones The final product or goal of service design is to ensure that service interfaces are useful usable and desirable from the clients point of view and effective efficient and distinctive from the suppliers point of view Mager 2008 p 355 The methodology is best undertaken and facilitated by a design team with some different areas of expertise For example a balanced library design team will have someone from a variety of functional areas of the library reference circulation technical services web design etc


Cocreation

Cocreation is a key element of service design Through the cocreation process the library design team works with stakeholders in order to create a service delivery model that matches patron and stakeholder expectations Steen Manschot  De Koning 2011 while taking into account any limitations or access issues at the institutional level Service design is about finding solutions2 for a given service ecology which can show up in different ways for different institutions The scope of a service design project could be allencompassing and seek to explore every aspect of service in a library but it is more likely that a library design team would start with one or two services such as reference service and then seek to understand everything about that service within the context of the library and the institution

The library design team should create a user working group UWG comprised of a diverse group of patrons to provide different levels of feedback from their unique perspectives For example the UWG that we used at the Reed College Library included students from the freshman sophomore junior and senior classes We were primarily interested in services from the student perspective but if a library wanted to understand services from the perspective of all patron types it may be appropriate to recruit faculty and staff for the UWG as well The design team will work closely with the UWG through the various phases to identify the most important and relevant issues to users and to cocreate solutions The UWG may be assembled as a shortterm entity to work on one service design project or they may be created as an ongoing entity to work as consultants on service design and other userfocused projects

Cocreation is also not limited to working with only external stakeholders3 such as patrons and other community members The cocreation process should also include internal stakeholders Ideas provided by those who offer and support the service are just as important as patron or user input Cocreation only works when relevant stakeholders are identified and as many as possible are included in the process In the example of checking out a book some of the questions that immediately emerge that point to important internal stakeholders include

	Was it cataloged correctlycataloging
	Was it shelved correctlystacks management
	Could they find their way around the library Do they need a mapfacilities marketing
	Was there someone available if they needed helpreference


The library design team may want to create a stakeholder map see fig 1 to identify key stakeholder groups for a given service point or service task


Figure 1 Stakeholder map






Beware the Devils Advocate Especially in the Beginning

Service design is an open exploratory process especially in the beginning and intermediate phases when the team is looking for and clarifying problems and initial ideas for solutions With that it is important to be openminded optimistic and willing to take risks A best practice in service design is to understand the situation compile possible solutions and only then evaluate each idea for the most viable and feasible solution The devils advocate while sometimes a powerful tool can also hinder progress innovation and solution making Tom Kelley the general manager of design firm IDEO believes that the devils advocate may be the biggest innovation killer in America today 2005 p 2 because the focus in conversations initiated by the devils advocate are rooted in negativity Focusing on problems before fully seeking creative solutions and trying out new possibilities can squash new ideas before they have time to be nominally developed To innovate means to try new ideas and approaches but finding those requires the ability to think beyond the status quo




Making the Intangible Tangible and Finding Touchpoints

Another element of service design is making the intangible tangible Returning to the process of checking out a book think of the few simple steps we outlined above A lot of these steps are hidden and not just from the user but also from other library staff members Work tasks are often very isolated from one another in libraries both physically and mentally For example technical services may be in a separate building from the main library building so while cataloging is a major part of the process for a user hoping to check out a book the user and the circulation staff member may never see or talk to the person that made it possible for them to find the book in the first place The circulation staff member at least knows this person exists but the user may not even be aware of how the library works When we use service design to create or refine services it is important to bring out all of the disparate pieces in order to make them tangible and so we can find out where the touchpoints are for users

Service design deconstructs service processes into single touchpoints and interactions which combine to create service moments Stickdorn  Schneider 2011 p 40 Touchpoints occur any time a user uses or interacts with your product or service They can be between the user and another person the library website databases the physical space with artifacts such as maps and signs or any other point at which the user uses a service They can also occur through third parties such as when a professor recommends a student contact their library liaison when a community member reads reviews of the local library or when users hear from other people they know about their experience using the library Identifying touchpoints can help tremendously in the process of making the intangible tangible and can help the library design team identify moments of success and failure with a service




Blueprinting

Blueprinting is one tool that can help to make the intangible tangible Services are processes that are dynamic and timedependent Bitner Ostrom  Morgan 2008 As a result it is important to understand what makes a service possible and to better understand the beginning and end points of a service Shostack 1982 Blueprinting outlines the evidence of service deliveryfrom the layers that are visible to the patron to all the behindthescenes workings that are required for a service to be rendered With the blueprint the service provider can determine the best delivery method while also understanding potential fail points throughout the delivery process Shostack 1984 It is useful to create a blueprint when you establish a service delivery model because it can be refined and reproduced with minimal effort




Design Ethnography and Observation

Ethnographic methods have been established as a tool to better inform libraries on how their patrons interact with space and resources Foster 2014 Foster  Gibbons 2010 Unlike traditional ethnography that often requires months and numerous trips to perform fieldwork design ethnography is constrained by workplace demands and time Salvador Bell  Anderson 1999 As a result design ethnography requires the practitioner to rely on a wider range of ethnographic tools such as interviewing structured and informal photography and observation

The purpose of design ethnography is to focus on illuminating broader patterns of the everyday that are important and relevant specifically for the conception design and development of new products and services Salvador et al 1999 The need to be flexible in how the library design group approaches the ethnographic process forces the participants to take what Crabtree Rouncefield and Tolmie 2012 refer to as a vulgar competence p 190approach which means that the team needs to quickly understand their environment and users and decide which methods or tools are best suited to gather the necessary insights within a givenoften limitedtimeframe

As librarians our intention is to learn insights into our users behavior and patterns The library design group should borrow heavily from established academic practices as mentioned above in order to grasp who are the librarys users what are their behaviors and how do they prefer to interact with the library Observing is one way to begin to develop this picture it is the act of witnessing users as they work in the library environment be it physical or virtual

Observation involves immersing oneself in the culture of the user in order to take a more empathetic approach to the design process Segelström Raijmakers  Holmlid 2009 This can be accomplished through working closely with the UWG oneonone interviews having them detail their interactions with the library in a diary or having them respond to various scenarios Combined with interviews in a more formal focus grouptype setting the information gathered in these activities can lead to a thick description Geertz 1973 What this means is the library design team can gain insights into user behavior with the end goal of obtaining a deep understanding of users and their behavior within the library ecology




Prototyping

A prototype is quite simply a physical representation of an idea The prototype can take many forms from a simple sketch to a fully functioning desk to simulate a physical touchpoint The purpose of a prototype is for the design team to develop a far deeper understanding of a service than is possible with written or visual descriptions Stickdorn  Schneider 2011 p 192 Developing a working prototype and testing it with actual users helps in the overall design process A functioning prototype helps move the abstract to the real A design may work flawlessly on paper but fail miserably in the wild Prototypes are quick inexpensive ways to find these problems before committing to permanent changes

As with all prototypes it is important to factor in editing time to fine tune the prototype experience Rarely is the prototype correct the first time out They typically need to be refined tested and refined again until you find the final product For a full treatment of prototyping check out the IDEO design process Kelley 2005




Journaling

Journaling or keeping a diary is a longestablished sociological method for measuring and tracking time allocation Gross 1984 The journaling method can inform the design team on how and when users interact with a service Clark 2010 A journal or diary also emphasizes to the user the role they play in creating a service transaction Employing a diary as a method for capturing insights also allows the focus of the diarys content to be on the user and makes the user into both the subject and the observer Zimmerman  Wieder 1977 Additionally journaling allows the library design team to learn more insights that might not be shared in a traditional focusgroup setting Zimmerman and Wieder 1977 advocated for a user maintained diary because it can be used as an observational log maintained by subjects which can then be used as a basis for intensive interviewing p 481





Service Design in practice

While there is no prescribed guideline or recipe for which tools or approach to use the service design process presented here was done at Reed College Library over a series of phases In each phase a different goal is reached the various pieces of the service puzzle are revealed the overall needs of users are explored and solutions are developed in order to create a rich satisfying experience for both users and the staff serving them


PreWork Phase

During this phase the design team should create the UWG and draft a schedule of activities4 The activities can change depending on the dynamic of the group and relevancy of the issues discussed and witnessed but starting with a rough schedule will help to keep the project moving Each phase and its characteristics and goals are discussed below Within each section there are suggested tools and activities to use These are only examples of activities




Observation Phase

In this phase the library design team observes interviews and documents acts in order to better understand the problem In service design observation means more than just watching it is about witnessing and understanding the experience As Salvador et al state our participants do not make facts they do acts 1999 p 37 This phase includes working with the UWG to create documents that help illustrate the actual behavior necessary to complete a task

During this stage the team will discover and refine actual problems and then focus on the characteristics and barriersphysical and virtualthat exist when patrons use library services For example a library design team may be interested in investigating why their reference numbers have been consistently going down for several years In this case the actual problem is illdefined because while declining reference numbers are the surface problem the team is still unsure of the real cause Service design helps to get to the root of the problem The purpose of the observation phase is to create a foundation for the project It is also about understanding the user at the most basic level

The observational and documenting methods used depends on the library environment and the goals for the project that the design team and the UWG have established Beyond just walking through the library and making notes of activities the design team might opt to perform a space analysis Space analyses5 investigate how users use space where and when they go and what they do when they get there Design ethnography builds on space analysis to better understand individual users This type of study can help librarians identify who users are what their motivations are and what similarities they may have with other users Personas can then be created based on observations to assist in the design process Design ethnography also uses interviews and talking to patrons in context when and where they are working to get a better understanding of how and why users do what they do The design team will also learn a lot about patron behavior while working with the UWG Examples of possible activities

	Space analysis
	Interviews
	Focus groups
	Surveys
	Personas





UnderstandingThinking Phase

The UnderstandingThinking phase seeks to build upon the design teams observations In this phase the design team works with the UWG to begin creating solutions and visualizing behaviors which should include prototyping The team may work with the UWG to create a diagram of the customer journey see fig 2 The customer journey diagram is essentially a graphic representation of the path a user takes in order to complete a task The main goal is to document the actual journey required to complete a task It is important to note that the form of the diagram should be something the UWG members are comfortable with creating More creative members may draw elaborate depictions or storyboards while others may want to write notes The diagram may be created individually by each UWG member and then compiled by the design team or it may be a group activity in which the whole UWG creates the diagram together Regardless of form this activity allows the design team to visualize the actual steps necessary to complete a task from the users perspective For example as depicted in figure 2 students may look for a book in the stacks differently depending on why they are looking for it where they are physically located when they start the process how they hear about it how comfortable they are with the library and so on


Figure 2 Customer journey mapa user looking for book in the stacks multichannel



Other possible activities might be to put the UWG in various scenarios in order to capture user thought processes and measure the gap between expectation and actual service delivery or have the UWG create diaries of their library interactions The scenarios see fig 3 should include situations users may face when interacting with the library Examples might include having trouble with printing approaching the reference desk when it looks like the librarian is busy on her computer or a user attempting to decipher the library floor map to find the correct location of a call number The scenarios can be depicted in staged photos that are shown to the UWG The UWG will then write down or discuss their thoughts when they have found themselves in these situations or what they imagine they would think if they have never been in the scenario depicted


Figure 3 Scenario exercise



Diaries while timeconsuming are an excellent tool that can help document actual patron behavior and make them more aware of how and when they interact with the library The diary exercise can be done over a period of a day or a week and requires each UWG member to track their interactions with the library This activity provides the design team with a view of user interactions from their perspective without actually shadowing a patron When employed in the user working group at the Reed College Library the users verbal response to the activity was that they learned how much they actually use the library


Possible Solutions and Testing

A major component of the UnderstandingThinking phase is testing possible solutions When users delve into and talk about their experiences with the library solutions begin to emerge At this point the design team should gather and document their ideas for solutions While users often have wonderful ideas which are the reason they are included at such an intense level in the process they do not understand the full service ecology so it is important for the library design team to return to the other stakeholders to investigate the feasibility of the ideas Some ideas for solutions may fall off the drawing board at this point For example a common issue at the academic library where we work is printing There are a lot of issues that arise around printing including students not knowing what to do when printers do not work correctly where the printers are located who can help them how much printing costs and how to get started with printing A solution that a student recommended was to move a printer to the counter next to the circulation desk so students would not have to find the printers in the library they could pick something up on their way out and help would be located at a potential point of need A staff member from access services on our team pointed out logistical issues for circulation staff who run the busiest service point in the library It is just as important to find a solution that works for the people who provide the service as those who use the service

Solutions that continue to look like good possibilities for implementation should be more fully developed For simple things like putting up clearer signage above printers or closing a service desk an hour or two later the design team may decide to jump straight to implementation but more complicated solutions should be tested first with prototypes

For example the Reed College team was interested in solving the problem of where to place the reference desk within our very traditional and quiet library so that students felt comfortable asking questions without disturbing other students To test possible placement for the reference desk and to help students on the UWG visualize it in different locations we used a large wardrobe box as a reference desk prototype By moving the box around students could concretely visualize a desk in a specific place to include getting a feel for how the work would flow in that space where and how sound would travel and what lines of sight desk workers would have

Examples of possible activities

	Diaries
	Customer Journey Map
	Scenarios
	Prototypes







Implementing

The implementation phase is the culmination of the work of the design team and the UWG After the prototyped service has been created and deemed ready to go live it is time to implement it During this time the library design teams focus shifts to fully documenting managing and marketing the new or revamped services


Figure 4 Service blueprint showing overview of user getting book from reserves This figure illustrates the necessary steps required to check out a book on reserve



At this point the design team should create the service blueprint which documents the service The service blueprint6 see fig 4 like those used for building structures creates a foundation for the delivery of a service or services It identifies the components of a step or action to reveal the inputs needed and steps covered and permits analysis control and improvement Shostack 1984 p 135 The blueprint creates for service providers a written record to look at and refer to in the delivery of service It can also highlight fail points that exist during service delivery By highlighting the entire process service providers can realize these processes are important because changing them may alter the way consumers perceive the service Shostack 1984 p 135

Implementation is also the beginning of the management phase of a project This is where the service changes hands from the library design team and moves to an administrator to manage Services are live interactions that need to be monitored even after the design team has signed off Moritz 2005 After a service has been implemented or redesigned it will have to be reviewed to see if the executed version meets expectations as determined or defined during the design phase In the implementation phase the library design group can gather additional user feedback and review the service blueprints created to fine tune the touchpoints



Conclusion Advocating for Service Design in Libraries

Libraries are by nature service providers and are an environment that stands to benefit from implementing a service design approach when assessing refining and creating services Even as libraries evolve with technological innovations and new methods of accessing information the dedication to service is at the heart of librarianship which highlights the importance of being constantly aware of how services are being provided to ensure the best user experience The service design approach is particularly promising for libraries because of its holistic focus and cocreative process With service design library staff are encouraged to look at all services how they interconnect as a whole and from the perspective of users This can open staff up to a level of understanding of their users that they may not have considered before especially in light of the functional siloing that is common in libraries

Implementing a service design methodology can also help the librarys bottom line Libraries are rarely tied to a revenue model but they are budget conscious The service design methodology can assist in the creation and refining of services that are based on demand rather than creating services around national trends By focusing on actual demand as heard from patrons and working alongside the UWG managers can be more informed when making budgetary and resource allocation decisions Taking a service design approach demonstrates a willingness to serve the users of the library rather than merely providing lip service to the service ethic

References

	Bitner M J Ostrom A L  Morgan F N 2008 Service blueprinting A practical technique for service innovation California Management Review 503 6694
	Brown T 2008 Design thinking Harvard Business Review 866 8492
	Clark K 2010 Mapping diaries or where do they go all day In N F Foster  S Gibbons Eds Studying students The undergraduate research project at the University of Rochester pp 4854 Association of College and Research Libraries Retrieved from httphdlhandlenet18027520

	Crabtree A Rouncefield M  Tolmie P 2012 Design ethnography in a nutshell In Doing Design Ethnography pp 183205 London Springer Retrieved from httplinkspringercomchapter101007978144712726010

	Dreyfuss H 1950 The industrial designer and the businessman Harvard Business Review 286 7785
	Duke L M  Asher A D 2011 College libraries and student culture What we now know Chicago ALA Editions
	Felix E 2011 Learning space service design Journal of Learning Spaces 11 Retrieved from httpslibjournaluncgeduindexphpjlsarticleview284

	Foster N F 2014 Participatory design in academic libraries New reports and findings Washington DC Council on Library and Information Resources Retrieved from httpwwwclirorgpubsreportspub161

	Foster N F  Gibbons S Eds 2010 Studying students The undergraduate research project at the University of Rochester Association of College and Research Libraries Retrieved from httphdlhandlenet18027520

	Geertz C 1973 The interpretation of cultures Selected essays New York Basic Books
	Gross D R 1984 Time allocation A tool for the study of cultural behavior Annual Review of Anthropology 131 519558 doi101146annurevan13100184002511
	Heath PJ 2014 Service design for libraries Presented at the librariescambridge Conference 2014 Quality Cambridge England Retrieved from httplibatcamblogspotcom201301servicedesignforlibrarieshtml

	Holmlid S 2009 Participative cooperative emancipatory From participatory design to service design In Proceedings of the first service design and service innovation conference ServDes2009 Linköping Sweden Linköping University Electronic Press Retrieved from httpwwwresearchgatenetpublication228629923ParticipativecooperativeemancipatoryFromparticipatorydesigntoservicedesignfilee0b4952a0de7cd2fcdpdf

	Kalakota R 2003 Services blueprint Roadmap for execution Boston AddisonWesley
	Kelley T 2005 The ten faces of innovation IDEOs strategies for beating the devils advocate and driving creativity throughout your organization New York CurrencyDoubleday
	Kotler P 2001 Principles of marketing 9th ed Upper Saddle River NJ Prentice Hall
	Mager B 2008 Service design In M Erlhoff  T Marshall Eds Design Dictionary pp 354357 Basel Switzerland Birkhäuser Retrieved from httpdxdoiorg1010079783764381400244

	Mager B  Sung TJ 2011 Special issue editorial Designing for services International Journal of Design 52 13
	Martin R L 2009 The design of business why design thinking is the next competitive advantage Boston Harvard Business Press
	Moritz S 2005 Service Design Practical access to an evolving field Retrieved from httpstefanmoritzcomfilesPractical20Access20to20Service20Designpdf

	Pine I Joseph B  Gilmore J H 1998 Welcome to the experience economy Harvard Business Review 764 97105
	Polaine A Løvlie L  Reason B 2013 Service design from insight to implementation Brooklyn NY Rosenfeld Media
	Salvador T Bell G  Anderson K 1999 Design ethnography Design Management Journal Former Series 104 3541 doi101111j194871691999tb00274x
	Segelström F Raijmakers B  Holmlid S 2009 Thinking and doing ethnography in service design Presented at a meeting of the International Association of Societies of Design Research Seoul Korea Retrieved from httpwwwidaliusestehoiasdrSegelstromRaijmakersHolmlidpdf

	Shostack G L 1982 How to design a service European Journal of Marketing 161 4963
	Shostack G L 1984 Designing services that deliver Harvard Business Review 621 133139
	Steen M Manschot M  De Koning 2011 Benefits of codesign in service design projects International Journal of Design 52 5360
	Stickdorn M  Schneider J 2011 This is service design thinking basics tools cases Hoboken NJ Wiley
	Zimmerman D H  Wieder D L 1977 The diary Diaryinterview method Urban Life 54 479498


Notes



	Roger Martin in his book The Design of Business uses phases Observation Imagination and Configuration and Tim Brown in his article Design Thinking uses Inspiration Ideation and Implementation

	 It is important to emphasize that creating the scope of a project should fit the environment in which it was created The purpose of this article is to demonstrate a methodology that can be adapted to any size library but the library design group should determine scope of the project for their specific library as they know it best

	 Stakeholders are defined as all parties internal and external that interact or perform a service This could include library staff librarians students staff faculty and even community members It is up to the library design team to outline parameters and define stakeholder in their service ecology

	 For a more thorough list of possible tools and activities refer to the website Service Design Tools httpservicedesigntoolsorg and articles published at the Livework website httpliveworkstudiocom as well Stickdorn and Schneider 2001 and Polaine et al 2013

	 A great tool to measure space usage is Suma httpwwwlibncsuedureportssuma Created at North Carolina State University this product can conform to any environment and outputs rich data to be analyzed

	 Additional resources for creating service blueprints can be found online httpwww31voltscom201005theserviceblueprintsoverview httpwwwservicedesigntoolsorgtools35 See also Bitner et al 2008 Kalakota 2003 Polaine et al 2013 and Shostack 1982 1984






Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS



















































The Dialog Box Interview with Courtney Greene McDonald


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










The Dialog Box Interview with Courtney Greene McDonald



Amy Barlow


Skip other details including permanent urls DOI citation information
Volume 1 Issue 1 2014



DOI httpdxdoiorg103998weave125356420001105



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	














Putting the User First by Courtney Greene McDonald is an accessible actionfocused handbook full of ideas for improving user experience right away and in any library It will be published by ACRL in late August 2014 as part of its new Strategies series  


McDonald head of Discovery and Research Services at Indiana University Bloomington is also coauthor of The Anywhere Library A Primer for the Mobile Web McDonalds scholarly writing currently focuses on discovery tools and mobile services in academic libraries Her most significant recent projects include overseeing the migration of the IUB Libraries 8000 page site from a legacy homegrown content management system to Drupal and the implementation of an open source discovery layer Blacklight as the public interface for IUCAT the Indiana University Libraries shared statewide online catalog She is also the chair of the editorial board that publishes WeaveUX


Check out a WeaveUX exclusive outtake from Putting the User First Dare


Amy Barlow humanities liaison at Wheaton College MA  interviewed McDonald about her new book over email in July of 2014 Their exchange is included below and infull





In Putting the User First you highlight the importance of the elevator speech If you had a few moments in an elevator with the readers of Weave UX how would you describe your book 

As readers of Weave UX probably already know working in libraries is user experience work periodall of our work comes together to become how people experience the library This book is intended to give a reader at any level of familiarity with UX something tangible to think about or apply right awaya new perspective a tool or technique an article to follow up onto positively impact the user experience at his or her library As a secondary goal I hope it finds use as a sort of actionoriented primer on UX thinking for a broad library audience 

Tell us a little bit about your mantra You are not your user What practical advice can you offer to professionals who wish to understand the behavior of their users For librarians that have achieved this understanding what can they do to make the case to colleagues in their organizations 

We have first to believe that our users experience with our systems should not have to be informed nor should it need to be informed by our intervention Once youve jumped that sticky wicket its really quite easy and fun

Spend as much time as possible with people who might possibly be your users and with people who have a quite different view of things than you do The first group will provide you with data insights or questions to explore The second will remind you that there are lots and lots of people who upon the completion of a shared experience will draw vastly different conclusions about it than you did the surprise you will feel when this happens underscores our basic tendency to slump back into our own points of view

Returning to the idea of understanding user behavior I like a nice mix of formal and informal observationuser studies contextual inquiry surveys focus groups a chat with the student employees at the desk noting questions and complaints submitted through any venue reviewing search logs reading case studies and even eavesdropping in the coffee line As there is no replacement for firsthand observation of someone elses experiences carry your colleagues along to the degree possible share the comments invite them to observe or participate in user testing forward around articles and studies you find insightful and relevant create meaningful graphs and charts out of that log data that help tell the story ask lots of questions 

I like that you use a variety of datagathering techniques What happens when you discover that your user groups have very different experiences For example a community college library serves multiple dissimilar groups its academic population noncredit students charter high school general public local businesses etc Who is the user and how do we prioritize experiences

This is a great question and one that I address in the book so Ill try and keep it brief here There are things you can do to tease out the various groups that together make up your constituency always knowing that membership overlaps and once you have a sense of that you can better work through the impact of decisions or changes on those groups As you note this has to be combined with identifying which you are going to view as your primary user groupnot easy but much easier and ultimately more productive than the alternative primary user group everybody 

Im also a firm believer in identifying a few really basic tasks or needs that resonate across your entire population and making those as straightforward easy and pleasant as possible Examples of a couple of things that might fall into that category What are the librarys hours today or I want to renew my book 

What initiated the writing of Putting the User First 

A couple of years ago I got a note from Kathryn Deiss mentioning that ACRL was starting a new book series to be called the Strategies series The idea was that each book would center on a topic or discipline and each page would have a concrete pragmatic strategy that could be applied right away

The format sounded ideal to me so then it was a matter of thinking what content I might be able to offer Putting the User First is my attempt to present user experience thinking as something thats accessible to library staff across the board at all levels of the organization and at all levels of familiarity with UX practice Because its published by ACRL and my experience is in academic libraries the examples do tend in that vein but Im hopeful that there might be value in it for others as well

Like who

Librarians in other contexts than academicpublic special schoolwould be the immediate other potential audience that had come to mind Who knows perhaps some of our more frequent collaborators throughout higher ed instructional designers or student affairs professionals for example might find something useful in it  

It seems to me that you put the reader first when developing the structure tone and contents of your book How did UX influence your process as a writer 

Thanks That is a wonderful compliment To be honest I had an abstract a title and a terrible case of writers block for six months until I hit on the structure I ultimately used 

User experiences are individualized personal specific and authentic This book came from a very personal placeits a sort of bildungsromanslashworkbook of my UX journey thus far I found that I could only begin from my experience thinking directly of the experience of the reader building out the concepts and ideas as if I was discussing with a friend or colleague Occasionally I think I was writing pep talks for future me thinking to myself What kind of book do I wish Id have handy for when I can grab a few minutes to pull away from the immediate action to refocus and recharge my enthusiasm for putting the user first Given that I now wonder if it is fair to say that in this one case I might actually be my user

Given the breadth of your research and expertise what concerns do you have about the future of UX in libraries What have you learned that gives you hope

In my opinion the conversation around user experience is the latest means for libraries to discuss and interpret our foundational shared values around service I think this is overwhelmingly positive 

Its an opportunity to ask ourselves a crucial question What is at the root of what we are doingis it about us or the user Our organizational structures our budgets our comfort zones our peer institutions our preferred methodsthese are perhaps more often than wed like our motivators for action but all of those things emanate from a selforientation from fear or uncertainty about our own environment our own perceptions of ourselves or how we are perceived by others These arent worthy drivers if we truly want to orient ourselves to prioritize the user experience 

I think that there are a lot of opportunities to move to extremes none of which would be helpful to libraries Lets consider vended systemsto some degree you outsource a good deal of the user experience decisionmaking to the company that has built the system Do we consistently hold our vendors accountable for what and how much they invest into UX research and to demonstrating how thats impacting the product over time  There is also the added complication that we inevitably layer many separate vended system interfaces across each other What does that do to our ability to offer a holistic endtoend experience for the user To be fair I should ask how internal politics or institutional branding interfere with our ability to offer a holistic experience as well Its not just the vended systems that complicate things 

Lets say then that a library opts to reject all external interfaces or systems and tries to roll their own every time Certainly this can be done to varying degrees but Im not confident that every library has the technological expertiseor the budget to hire that expertisethats needed to stay on top of this as an extreme position because golly its a lot of moving pieces to manage Most concerning to me though would be the temptation for libraries to turn away from the conventions of the free web where most nonlibrarian civilians spend their lives The free web is the space that forms the baseline expectations of our user populations Lets be honest we in libraries sometimes have a tendency to build for the way we believe users should behave rather than the way they do

Changing how you do something should not endanger why you are doing it UX isnt a spectator sport its a practice of being open to observing patterns and behaviors and changing how we operate to prioritize the needs of our constituencies If we can be open to possibility and willing to consciously proceed in this way then we have some place to go and I believe that we can and will




Dare


A WeaveUX exclusive outtake from Putting the User First


Make no little plans They have no power to stir mens blood

Daniel Burnham as quoted in Devil in the White City




Recently I was sitting on an airplane without anything to read For a librarian Im notoriously bad at forgetting my reading I wasnt too upset it was a short flight andtrue confessionI love airline magazines

On this particular day in this particular Southwest plane there was this particular article titled Chasing Beautiful Questions by Warren Berger It begins with a story about Van Phillips the man who engineered the FlexFoot prosthetic limb after he himself lost a leg in a boating accident


 he asked a question that would change the world of prosthetics If they can put a man on the moon why cant they make a better foot

It was a good question But it did not become a beautiful questionone that leads to invention and profound changeuntil Phillips changed a pronoun Gradually he found himself taking ownership of the question Instead of asking Why cant they make a better foot he asked Why cant I Berger 2014 70



Berger identifies a cycle of three questions asked by innovators he calls master questioners Why curiosity What If speculation and How actionoriented He opines that it is in the How phase beautiful questions appear leading to answers that change lives in ways large and small mobile phones microwave ovens windshield wipers bar codes Polaroid cameras Gatoradeor a prosthetic limb

User experience work is all about questions those our patrons answer using our resources we hope those asked of us by patrons or the questions we ourselves ask about our patrons or our services I oversee a couple of web applications and work at the reference desk so I field plenty of questions How can I renew Why doesnt this or does this do  A portion of the questions really boil down to this Why did you do this to us Given a diverse enough user base one persons enhancement is not unlikely to become anothers complaint

With so many variables to consider its hard to be certain you are asking the right question much less a beautiful one which can lead even the most earnest user experience professional toward a cynicism spiral Henry Ford supposedly said If I had asked people what they wanted they would have said faster horses1 Snappy quotation certainly and who hasnt in a brief fit of self pity fancied herself a misunderstood innovator ahead of her time Patience grasshopper great user experiences do not emerge from regularly making assumptions about what people need and want Instead that tendency can easily reroute you from wouldbe visionary into the express lane to horses patootie

Sometimes questions inspire me and some days they just make me want to engineer a conveniently timed power outage take the grid down and switch to my Plan B2 A pretty attractive answer can occur at any level substitute any words that add up to yes or I fixed it or better today than yesterday A beautiful question generally winds up being big messy and fraught with contradictions 

Im not much of a philosopher so let me lay it out for you straight these beautiful questions are really just a dare Many of us probably associate dares with our younger selves and feats of prowess  jumping off a swing at the highest point illadvised pool dives of all sorts grabbing that really gross bug We can have grownup dares though  even library dares Lets face it some days just fixing that one link totally qualifies as a feat of prowess

Beautiful questions are about daring to question what is to believe that things could be different and then to dream a big dream that difference will be better This sounds suspiciously like user experience work to me The last and most difficult step is as Berger noted taking ownership of the question and believing that however unlikely however long and drawn out the process however difficult that you yourself yes you can make a change Noble yes but be advised it can take a long time often results in being misunderstood and requires a lot of work few other people will notice Inspirational arent I

You might need to start small We will go from two request buttons to just one We will stop asking people to provide contact information we already have Once you can believe six impossible things before breakfastan excellent skill if you plan to continue your work in library user experiencewhy sweat to scry a soapbox racer when you can picture the grand prix winner Our users will find and use our stuff no matter where they are or where they begin looking Easy sustainable scalable data management for everybody

How do you go about sharing a beautiful question with a lot of other people Can a library ask a beautiful question

I dare us to make it easiereven funto interact with the library I dare us to find a better way I dare us to ask to listen and to answer in search of a better user experience




Contemplate  Questions to ask yourself

Bernadette Jiwa outlines a difference map intended to help companies and individuals identify their unique niche articulate it in terms of the users needs and then position themselves accordingly This reminded me of Druckers Five Questions 

	Drucker	Jiwa
	What is our mission	
Principles Trust about meus Truth about the marketindustry Truth about the people Iwe want to serve

Purpose Why do we exist
	Who is our customer	
People Who is this for What do they care about
	What does the customer value	
Personal How can we change how people feel

Perception What do they believe
	What are our results	
Product What do people really want or need How do we create value for our customers
	What is our plan	
Personal How can we help them live better lives

Perception What would we like them to believe about us


Try really engaging with Druckers and Jiwas questions and see if they dont challenge your thinking and your practices as they did mine




References

	Berger Warren 2014a A More Beautiful Question The Power of Inquiry to Spark Breakthrough Ideas New York NY Bloomsbury USA
	 2014b Chasing Beautiful Questions Spirit Magazine April
	Drucker Peter F and Frances Hesselbein Leadership Institute 2008 The Five Most Important Questions You Will Ever Ask About Your Organization New York San Francisco JosseyBass
	Jiwa Bernadette 2014 Difference The OnePage Method for Reimagining Your Business and Reinventing Your Marketing Australia CreateSpace Independent Publishing Platform
	 2014 The Difference Map Difference Accessed May 21 httpdifferenceisdifferencemap
	Larson Erik 2003 The Devil in the White City Murder Magic and Madness at the Fair That Changed America New York Crown Publishers
	Vlaskovits Patrick 2011 Henry Ford Innovation and That Faster Horse Quote HBR Blog Network httpblogshbrorg201108henryfordneversaidthefast





Notes

1 Vlaskovits Patrick 2011 Henry Ford Innovation and That Faster Horse Quote HBR Blog Network httpblogshbrorg201108henryfordneversaidthefast

2  Speaking of which you heard it here first the postapocalyptic future is going to revolve around cheese and ruminants according to Matthew Reidsma Margaret Heller and myself






Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS





















































Launching a Native App Lessons Learned in Academic Libraries


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










Launching a Native App Lessons Learned in Academic Libraries




April Siqueiros

Samantha Raddatz



Skip other details including permanent urls DOI citation information
Volume 1 Issue 1 2014



DOI httpdxdoiorg103998weave125356420001104



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	














If your library has a website and your users have mobile devices congratulations you have a mobile user experience But is that experience a good one for your users


Libraries seeking to offer good user experience on mobile devices have two choices a responsive website which scales the amount of content displayed up and down depending on screen size and a native app downloadable from platform marketplaces


Would a native app improve your mobile user experience Is an app mutually exclusive to a responsive website Why would you choose one over the other Is there any reason to have both Who will do this development


In academic libraries effective user experience always starts from an institutional context and what that context makes possible For that reason the editors of Weave will not presume to tell you whether your mobile presence should take the form of a native app a responsively designed website or both This is despite the fact that we generally believe that a welldesigned responsive website will serve the mobile patrons But thats in a vacuum Your library ours they dont exist in a vacuum


We hope youll read the following five brief case studies put together by April Siqueiros and Samantha Raddatz of Pratt SILS of academic libraries that chose to develop a native app with your own institutional context in mind 


How will you best serve your mobile users


San Diego State University Library

The San Diego State University SDSU Library iOS app has been the pet project of Library Services Specialist Tyler Rogers He knew there was a user base for a mobile app but the school had just undergone massive budget cuts following the 2008 financial crisis and there wasnt money available to hire an outside vendor Rogers began work on the app because he was eager to develop his programming skills and also felt an obligation to nab the SDSU Library title in the Apple App Store before South Dakota State University could so he started developing the app in 2011 It was released in July 2012 and has been updated three times since then Key updates have made the app available on the iPad and updated it for compatibility with iOS 7

Rogerss first task was to decide on app content Which services would the app feature He took a look at a variety of existing library iPhone apps like DC Public Libraries which was particularly instructive because their code was posted online He also looked at apps by UCLA and Cornell and found that they tended to offer a few tools in common catalog search library location information address hours and access to the new books list The resulting app features all of the above and utilizes both XML parsing and inapp views of the librarys mobile catalog User testing came from librarian collaborators who offered feedback tested the app on different devices and acted as a crucial sounding board for Rogerss ideas 

Though the app is a success 1000 downloads in the last two years Rogers sees potential improvements in mobilesspecific features such as geolocation and data sharing with other apps  Hed also like to pare down the code and write a feature that allows users to save searches Simultaneously the library is developing a responsive website Both projects require the vital consideration of the external services and tools that the library utilizes like Summon and how those can be integrated into mobile interfaces both native and browser 

Is there value in having both a mobile app and a responsive website Rogers says yesat least for now Primarily he cites the fact that app users can count on a standardized interface familiar from the desktop website More apps have functionality such as the use of a camera geolocation streaming audio from a device on standbywhich arent yet available in web browsers Over time says Rogers the answer will be that you really only need a good responsive website  There seems to be a lot of focus on developing standards for bringing native app functions into websites


Dialog Box Takeaways from SDSU

	One staff member or librarian can make an app happen and the project can be a great professional development opportunity




John M Pfau Library at Cal State San Bernardino

The iPhone app for the John M Pfau Library at Cal State San Bernardino came out of the classroom Jonathan Smith the Head of Library Information Technology was approached by Dr Arturo I Concepcion the professor teaching an undergraduate course in software engineering who asked Smith if he would serve as the customer for a student team project that would build the library app on  both iOS and Android Smith agreed The app was released on Jan 8 2013 and has been updated once since then 

The process was collaborative from the start Smith provided the students with a list of requirements culled from a review of other library apps with particular inspiration from the one developed by the Washington Research Libraries Consortium From those requirements the students developed and presented three iterations of wireframes to Smith followed by further iterations of the functional interface Jonathan always gave feedback inperson and was impressed with the resulting application 

Though Smith considers the process and the resulting app categorical successes support for the app will soon be discontinued Priority has shifted toward the development of a responsive site 


Dialog Box Takeaway from Cal State San Bernardino

	Want an app but uncertain you want to or can devote the staff time or resources it takes to get the ball rolling Student coursework could get you started but be sure to have a plan for maintenance of the app after the student project is complete




Cheng Library at William Paterson University

When LibraryLinkNJ WPUs consortium offered to subsidize the cost of hiring a vendor to develop apps for memberlibraries Kurt Wagner Cheng Librarys Assistant Director of Library Information Systems saw an opportunity He was familiar with Boopsie one of the vendors approved by LibraryLinkNJ having seen it in action at the ALA LITA conference in 2011  Boopsie had developed the conference program app and Wagner was impressed Because the Cheng library website was built within a larger content management system that was not responsive an app made particular sense

Usage data from the library website drove content decisions  Some of this content includes library catalog search user account access and  a feature called BookLook that allows users to scan a book barcode to see if the library carries it  Best practices were applied from libsuccessorgMLibraries a rich resource that lists development tools testing vendorspublishers and suggested readings for libraries  Wagner looked at other library apps for inspiration particularly the Seattle Public Library a fellow Boopsie customer

The app was promoted in library instruction classes orientations and other similar events  Although the app received positive responses and met a need Cheng Library did not renew its contract with Boopsie  As of this past spring all of the universitys websites are responsive


Dialog Box Takeaways from William Paterson University

	Your consortium might be in a position to remove some of the barriers to developing an app
	Instruction librarians have direct access to your apps user base Partner with them to promote your library app




William A Blakley Library at University of Dallas

The University of Dallas UD created a mobile app for its library in 2013 after receiving a Mobile Solutions grant through the Texas State Library and Archives Commission TSLAC  Cherie Hohertz now Director of Libraries at UD became a part of the app process as Access Services and Systems Librarian  UDs online catalog was not responsive and she was hearing complaints from users attempting to access the catalog on mobile devices

UD uses SirSiDynex as their library system which offers BookMyne a standard mobile app that can be customized for each library UD was assigned a product consultant for the process who worked with them to plan and develop the app  They worked together to decide on customizations and functionality and they sent test apps using Pieceable a platform for viewing iOS applications in a desktop browser  UDs library app was built primarily to make their OPAC accessible from mobile but it also featured basics such as location hours event promotion and contact information Most of the default BookMyne functionality was used with customization focused on institutional branding  SirsiDynex launched the app in the Apple Store on behalf of UD once it was approved

Since then the UD Library app has been successful receiving positive feedback and wide usage It has been downloaded about 2000 times since its release


Dialog Box Takeaways from UD

	Your catalog vendor might offer a mobile app Check in with them and see if theres a partnered solution for your mobile users




University of California Los Angeles Libraries

Simul8 a group of student developers from the University of California Los Angeles UCLA builds iOS Android and responsive web apps for the universitys library  The group came to be when Kevin Rundblad UX  Social Technology Strategist at UCLA submitted a proposal with a former colleague in 2009 for a team made up of student talent that would be based on fun and experimental principles and an emphasis on individual responsibility  Says Rundblad Just as members of a small technology startup might be trusted to own their area individual responsibility means that Stimul8 students are given respect and decisionmaking ability for their area of expertise They each carry responsibility for their choices in the context of the group When people are provided this respect they tend to be invested in the process much more and thus connect with projects in a more personal way

Over time the group began to focus on mobile platforms and released the first iOS UCLA Library app in September 2011 The development process was driven by the studentdevelopers  While they did look at other library apps when starting out they mostly used popular nonlibrary apps as a reference point  The design was created from scratch with wireframes and mockups along the way

User interviews were conducted in the initial stages but Simul8 Group was responsible for most of the concepts and decisionmaking reflecting a sense shared by Rundblad and the members of Simul8 that using studentdevelopers would help keep the app focused on student need

While other libraries are staffcentered in the development process Simul8 Group remains in control of the apps scope  This model has been symbiotic for the team and UCLA since the university has a welldesigned app and some of Simul8 Groups former members have landed positions in Facebook Yahoo Amazon and Box among other places

The UCLA Library app has been considered a success with over 9000 downloads since 2011  The next major iOS update may be released around October 2014


Dialog Box Takeaways from UCLA

	Student developers working for pay and portfolio items bring a powerful motivation to doing good work Creating a group like Stimul8 covers you as some students graduate and others come on board




Considerations when deciding between app development and a responsive website

	Apps are at this time the only way to use mobile device features such as GPS a camera or sharing between apps Consider whether your mobile users might benefit from these
	An app is devicespecific and wont reach all mobile patrons That said there are reasons to think that users who access web content via apps are more likely to come back
	Apps require maintenance apart from your website Make sure someone is assigned to that task and that they have time for it
	Consider the technical specifics to your task For example research for this article indicated that catalog content must be hosted online and cannot be cached on a phone
	Vendor contentprimarily database content but also potentially subject guide contentcannot always be incorporated into an app
	Responsive web design allows you to design web pages that work on any PC tablet or phone


If you choose to develop an app

	Aim for a small team and include your demographic in the development process if possible
	Develop a set of standards and follow them across platforms
	Dont be afraid to try things out and use datauser testing analyticsto see how they work
	Determine how much content you would like to be native and what should remain serverside 
	Follow the systems development lifecycle
	Expect a considerable wait after submission to the Apple App Store and factor this into your project calendar
	User testing is your best means for ensuring that all the work that goes into app development isnt wasted Test early and often





Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS



















































Grassroots UXD in the Library A Review Essay


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










Grassroots UXD in the Library A Review Essay



Monica Rettig


Skip other details including permanent urls DOI citation information
Volume 1 Issue 1 2014



DOI httpdxdoiorg103998weave125356420001103



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













Bowles C  Box J 2010 Undercover User Experience Design Berkeley CA New Riders 

Buley L 2013 The User Experience Team of One A Research and Design Survival Guide Brooklyn NY Rosenfeld Media




Ill admit it I am excited about the potential for User Experience Design UXD to bring about change in libraries I look around at our spaces and interfaces and think We can do better And I see the user experience approach as a way to get us there 

But all this boldfaced enthusiasm only gets me so far Much of what I read about UX in libraries is in the form of largescale projects such as redesign of the homepage or reference desk I can see how an individual could make the decision to introduce user experience thinking as the lead on a major project or as a manager for a library service  It is expected that a leader influences the groups approach to a problem A mandate sure helps too in most of our workplaces the UX process and philosophy is a significant departure from how things are done

What if I the UX hopeful do not have the mandate or team or job title Are there ways to apply UX methods to smallerscale daytoday work in the library And at the same time how do I convince my colleagues and administrators about the value of this approach to improve my chances of tackling an official UX project Is there such a thing as grassroots UX 

Two recent books from the general field of user experience address the challenge of putting the users at the heart of a business in environments not yet fully convinced of the value of UX Cennydd Bowles and James Boxs Undercover User Experience Design 2010 provides a stealthy practical approach to introducing UX from the ground up with process techniques and insights on organizational culture  Leah Buleys The User Experience Team of One A Research and Design Survival Guide 2013 focuses on the unique challenges facing the sole practitioner detailing both philosophical concerns and practical methods

These two titles are written for the individual working with constrained resources whether those are time finances or support from management The authors all share extensive experience as UX designers deriving a wealth of insights from work in a variety of companies In spirit the objectives of these two books are in sync provide the reader with both a map and moral support for good UX work Yet the style and format differ significantly and there is surprisingly little repetition in content 

Going Undercover

In Undercover User Experience Design Bowles and Box open with a manifesto stating several memorable maxims such as good design today is better than great design next year delivery not deliverables and action not words p 31 True to their word the authors delve directly into undercover UX techniques with almost no preamble The bulk of the book is dedicated to brief descriptions and instructions for UX methods spanning from content audits to wireframes Whenever possible the authors identify techniques that can be conducted solo and without official clearance as well as strategies for determining when to throw off the cloak and expose the UX mechanisms 

The books design is conducive to quick reading with an unintimidating voice and clearly defined scope There is an explicitly stated and unapologetic focus on web UX design This limitation was somewhat disappointing for this libraryminded reader I had been hoping for a more holistic approach to UX touching on the web but also physical spaces and services Even with a webonly lens our online offerings are so much more complex than a typical web page It is difficult to think of the librarys online environment as just the website We are well aware that we are managing a gateway to an overwhelming array of resources while simultaneously trying to facilitate the discovery process for a multitude of distinct user groups Competition is stiff user expectations are high Our continued relevance depends upon both the functionality of our systems and the users experience of success when she uses them It sounds like an unwinnable war but it is core to the mission of libraries to facilitate access to knowledge for our publics despite the multiplying hurdles So yes while our web presence does include elements familiar from corporate websites forms news stories promotional items our demands are higher

Following the chapters on UXD processes is the Working with section which lists a number of populations within a business eg developers visual designers senior managers their likely motivations possible causes of conflict and ways to arouse their interest in UX design p 132 The authors admit that they have presented the UXD process in relative isolation and while this reader has found some Working with information applicable to the library world the result of separating the human angle from the methods feels disjointed 

In the instances where it is integrated the advice related to people and organizational culture is much more compelling Bowles and Box recommend that method choices should be informed by the personality of the organization Are stakeholders motivated by numbers Or success stories p 19 The authors warn against common cultural red flags such as design disinterest enormous expectations and difficult deadlines p 21  Likewise certain terms have a bad reputation and should be avoided Instead of focus groups say group interviews p 28 Distinguish collaborative design from the dreaded design by committee p 51 The reader benefits from the authors experience in a broad range of organizations

The Undercover book is a straightforward read and lowers the barriers of entry to UX practice This book offers feasible methods and memorable insights for someone starting UX work Particularly notable examples for this reader include a warning against fetishizing deliverables eg wireframes personas etc p 70 and the advice that handling critique well is an important way to earn trust p 120 Bowles and Box provide recommendations for further reading and useful lists of tools Finally the authors propose a UX adoption ladder ranging from undercover to emergent to maturing to integrated UX p 161 It is helpful to map your organization on this ladder to appreciate where you are coming from what to aim for and how to recognize progress 

Flying Solo

In The User Experience Team of One Leah Buley is speaking to a similar audience anyone who is interested in taking on the challenging and rewarding work of spreading a usercentered mindset to new places p iv Buley astutely identifies a unique challenge of operating as a UX team of one You need to evangelize and Youre learning on the job p ix Exploring the tension between these two efforts is the motivation for the book and as a result Team of One is divided into two equal parts Philosophy and Practice 

Similar to the other book under review Buleys tone is empowering and encouraging She lists the founding principles of a UX team of one UX is a force for good The world needs more of it You can make that happen p xvii In comparison to the Undercover book it is written in a dense style but compensates by being very thorough and broad in scope 

Buley expends considerable energy on situating the reader within a bigger picture of UX as a field The brief history of user experience design is delightful movements in business design and technology over the past century are woven together to form a narrative of the fields evolution 10 A UX team of one can adapt to change by focusing on the durable value and purpose of design p 226 emphasis mine The author elegantly offers both grounding and perspective

The good news Buley insists is you dont really need permission to be a UX team of one You can infuse the UX philosophy into work that youre currently doing p 30 However it is critical to have the support of peers and leaders and the author offers a number of methods for building awareness Several common objections to UX are listed complete with a cheat sheet of possible responses p 52 The UX Evangelism methods range in style and tone the reader can select the method that best fits her personality and workplace culture whether that is posting a notice on the inside of the bathroom stall door Bathroom UX or hosting a peertopeer learning community Individuals building a UX practice are warned too much emphasis on process can be a distraction that takes your energy and attention away from relationships which are most important Instead Buley advises rooting oneself in a mindset with principles of engagement such as invite people in and truly listen p 45 

Given the constraints facing a team of one Buley uses the Practice section to highlight methods that are inclusive selfdocumenting focused on prioritization and the lowest possible fidelity p 82 Each method includes a description sample visual approximate duration for planning and implementation circumstances for use and stepbystep directions The vast majority of methods are related to web UX projects Despite this Buley does point to the expansion of UX beyond the user interface to fields including service design industrial design and physical space design We are all working on the same basic problem How can we design flowing experiences that respect empower and delight real people p 15 Later in the book the author briefly points to the field of service design as an option to study a task or experience flow that switches channels or has nondigital components p 179 This libraryminded reader found new vocabulary for UX beyond the digital sphere

The division of philosophy and practice is sometimes strained especially in the example of the two sections Building Support for Your Work chapter 3 and Evangelism Methods chapter 9 In the preface the author does state that the book is designed to allow the reader to dip in and out as needed p vii Perhaps this book just does not function best when read covertocover as a reviewer would but a practitioner might not

Conclusion

Both Undercover User Experience Design and The User Experience Team of One deal with the reality that introducing UXD in an organization involves a cultural shift User experience work could be in principle easy to endorse Not only is it trendy it involves sidling up to our users and trying to make our spaces and interfaces work better for them all things that everyone in libraries wants 

But many of our colleagues do not expect UXD to encompass a new philosophy and practice for the beginning middle and end of a project I have often encountered the misconception that user experience just means that there will be usability testing at some point in the project calendar These books reinforced the concept that UXD is a creative collaborative iterative process of design with a wide variety of methods and techniques This broader understanding of UX is a threshold concept to use the language of information literacy2 Getting there will require real awarenessbuilding 

But yes there is such a thing as grassroots UX One can employ a UXD process on even the smallest of projects Working on a LibGuide Take the time to think first about the target users their primary goals and the tasks the design should support Perhaps sketch multiple possible layouts before jumping in to add text and links Planning a workshop Draft up a protopersona select a particular user type and sketch up an individual with a name backstory needs values and frustrations3 This process can help to humanize your potential workshop attendees while also identifying gaps in your knowledge about them You can bring the UXD philosophy to your daytoday work by spending more energy on thoughtful planning making efforts to see beyond your personal preferences and habits and searching for opportunities to better understand your users


Sample proto persona from The User Experience Team of One CC BY 20 license httpsflickrpf2iSaL




The choice to focus on the underresourced UX designer is significant this novice read the opening pages of both books and felt included in the sphere of UXD despite my limited experience and resources While reading I was working as the lead on a project where we were feeling overwhelmed by a growing todo list for an online research skills program In Buleys book the Opportunity Workshop description spoke directly to our need to prioritize and assess what work needed to be done to improve the user experience p 101 So I trashed the agenda for our upcoming meeting and ran a workshop instead complete with PostIt notes and markers I guided the team through an activity where we each wrote down problems and strengths in the current program posted them on a large whiteboard and worked together to organize these issues into themes Finally we prioritized the issues by voting on those most urgent we each had an allotted number of checkmarks to distribute4 The experience was positive it got all of us out of our chairs and debating our challenges and it resulted in a surprising shift in priorities These books are nothing if not practical reading through the methods it is hard not to think Hey I could do that 

That said the modus operandi of both Undercover and Team of One is learning as you go In this case I was fortunate to have a small team with a high level of trust and I could rely on my team members to be openminded and play along The design process involves creativity  even fun  and gives credit to affect not just logic For many of us this will mean taking a risk and breaking from our traditional rules of engagement

Questions about UXD in library culture remain While both books address the common critiques of UX how does one respond to the statement that libraries already are usercentered Libraries have a long history of engaging the users How does one argue for the role of UX without dismissing the previous userfocused initiatives or alienating those userminded colleagues What does it mean to think of the librarian as a designer This reader has a renewed desire for a network of librarians interested in UX in order to ask these sorts of questions And libraryminded readers are left wanting more There is a hunger for examples and advice for applying the UXD approach to services and physical spaces 

Both Undercover User Experience Design and The User Experience Team of One provided me with many leads books to read people to follow conferences and associations to look up and software to consider More importantly I was left with a renewed sensitivity and appreciation for the need to balance user goals and institutional goals Grassroots UX is delicate and dynamic work equal parts people and process

Notes

1 Undercover Manifesto available online at httpundercoveruxcommanifestophp

2  Threshold concepts are those challenging gateway or portal concepts through which students must pass in order to develop genuine expertise within a discipline profession or knowledge domain Craig Gibson  Trudi Jacobson June 2014 Framework for Information Literacy for Higher Education draft p 25 Retrieved from httpacrlalaorgilstandardswpcontentuploads201402FrameworkforILforHEDraft2pdf Read more about threshold concepts as used in ACRLs new Information Literacy Competency Standards for Higher Education httpacrlalaorgilstandards 

3  More about ProtoPersonas as a method in Buley 132135 See persona examples templates and more information at httpwwwpinterestcomkoojpersonas 

4  More about the Opportunity Workshop method in Buley 101103 




Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS





















































WeaveUX Tweetposium May 2 2014


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










WeaveUX Tweetposium May 2 2014





Skip other details including permanent urls DOI citation information
Volume 1 Issue 1 2014



DOI httpdxdoiorg103998weave125356420001106



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













WeaveUX weaveux is lucky to have some awesome Twitter followers Their expertise and willingness to engage with ideas gave us the chance to try something new and while were at it coin the term Tweetposium Google it

Curious fool and WeaveUX Dialog Box editor Pete Coco pfcoco ably assisted by Wheaton College Content Strategy Assistant Julie Bogen 14 jabogennow of refinery29 took to Twitter this past May with the intention of stirring the library UX pot Three questions emerged

	What are the historical roots of humancomputer interaction and its overlap andor divergence from library science andor librarian professional identity as it relates to users and usercentered service
	Related to the above or not what are the challenges specific to library user experience
	Finally what are some easy improvements to user experience that any library can make


We got some great responses and the beginning to some very interesting answers








Want to curate a WeaveUX tweetposium Get in touch weaveux or pfcoco with the questions youd like to ask our Twitter followersan ace group of Library UX experts stakeholders and curious fools

Want to pitch a piece for WeaveUX that digs a bit deeper on any of the above Wed love to hear from you Get in touch with weaveux email us at helloweaveuxorg or check out our author guidelines httpweaveuxorgsubmit




Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS






















































Creating a Culture of Usability


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










Creating a Culture of Usability




Krista Godfrey

Memorial University



Skip other details including permanent urls DOI citation information
Volume 1 Issue 3 2015



DOI httpdxdoiorg103998weave125356420001301



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













This paper was refereed by Weaves peer reviewers

Abstract


While usability testing is primarily applied to websites it can and should be applied to many aspects of the library Standing usability teams are an ideal means of improving usability across the library As usability is applied to more library projects and usability skills develop the library moves towards a culture of usability This paper explores the creation of web usability teams as a means to develop a culture of usability and examines the steps taken by Memorial University Libraries to move in this direction


Introduction

Libraries actively test the usability of their virtual spaces Library literature is full of the results of usability tests conducted on library websites It is regular practice for libraries to hire web designers and developers who are proficient in usability concepts tools and practices Yet a key aspect is missing from the discussion Physical spaces and services which are as important as their virtual counterparts are rarely put under similar rigorous testing to ensure usability or improve the user experience

By leveraging the skills of library web designers and developers libraries can work to ensure usable spaces and services and improve the user experience throughout all aspects of the library Forrest takes this idea one step further asking what if an entire library committed itself to the user experience 2009 p 8 The usability and user experience expertise that web designers and developers possess can be used to help bolster these skills throughout the library As these skills spread the library moves towards adopting a culture of usability ultimately focusing on improving the whole user experience

Memorial University Libraries is exploring Forrests question of an entire library committing to the user experience through the creation of a permanent web usability team Establishing a permanent group devoted to usability testing is the first step towards an overall culture of usability and user experience As a distinct and permanent group the library is highlighting the importance and value of these skills to the organization The team which has rotating membership from across the library system acts as both a group of experts in usability testing who can take back their skills for use in their own departments and as a training team to further develop these skills among all library staff By increasing usability skills among staff it becomes an organizational value Usability becomes ingrained in library projects and improves the usability and ideally user experience in both our physical and virtual spaces and services

By examining the ways in which usability can be applied to all aspects of the library as well as developing usability skills throughout the organization through a standing committee Memorial University Libraries aim to move towards a culture of usability

Literature Review

Despite their often synonymous use usability is only one aspect of user experience Morvilles user experience honeycomb illustrates the complexity of user experience highlighting each element that must be addressed including usability Morville 2004 The goal of usability testing is to inform our judgment and decisions rather than to provide or disprove existing beliefs and practices Krug 2006 It is important to remember that while usability is a key element of user experience a product or website that is usable can still provide a poor overall user experience

While there are numerous articles on usability testing and library websites within scholarly literature there is little discussion of the creation or importance of standing usability or user experience teams Emphasis is placed on usability tests and their results rather than on those who complete the work There are two notable exceptions to this trend These articles provide an examination of usability teams or committees and represent the strengths and failures of creating such groups Dethloff and German 2013 present the case study of a web usability team at the University of Houston Libraries noting the difficulties their group encountered A standing usability team was created but the group experienced compositional issues and initially lacked usability testing expertise Their culture of multipleweb related teams and consensus decisionmaking also made it difficult to complete usability testing in a timely manner This minimized the impact of their group and resulted in the teams dissolution Nichols Bobal and McEvoy 2009 provide a very different experience at Oregon State University where they successfully created a standing usability team They provide an overview of the teams skills structure and roles and outline both successes and challenges faced by the team

With little research examining usability teams and their impacts on the wider institution it is useful to explore who is responsible for usability testing These duties tend to fall to a web team or a single individual such as a web librarian A survey conducted by Kneip 2007 found that webmasters in mediumsized academic libraries frequently performed usability work Connells 2008 survey of nearly 300 academic institutions found that just over half used a web team Bundza Vander Meer and PerezStable 2009 noted that 75 percent of survey respondents indicated the use of a web team of some form A survey conducted by Chen Germain and Yang 2009 revealed similar results with 52 percent responding that they had a web advisory committee and 15 percent had a specific usability team Composition of these teams varies and is largely dependent on the specific institutional needs and local culture

Since web teams frequently perform usability work it is also valuable to examine web team skill sets and determine whether usability is a valued skill within these groups The rise of social media discovery layers and the need for mobile websites may account for the recent decline in library literature on the topics of library web responsibilities and skills Veldof and Nackerud 2001 note usability testing skills as one of the seven skills required for successful website design Church and Felker 2005 also note usability study as a skill required by web teams but as a subset of the broader skills associated with information design While Bundza et al 2009 report that 75 percent of their respondents conducted usability testing they found far fewer used usability testing to set priorities Connell 2008 found that despite identifying usability testing as an important aspect of web work it was completed by less than half of the survey respondents Her survey also found that the web team members were primarily chosen by interest rather than by their webrelated skills Although Cervone 2005 does not examine usability or web teams specifically he stresses the need for usability skills and usability training as an organizationwide goal

Usability Beyond the Website

Usability is an ongoing iterative practice that involves observing our patrons using our resources Usability testing is a cycle as Krug simply states you make something test it fix it test it again 2006 p 135 It is most frequently associated with websites and incorporates a range of tools and tests to determine if a website is easy to use such as heat maps eyetracking software card sorting AB testing and taskedbased testing Schmidt and Etches 2014 include usability testing as part of user research techniques to determine user behavior As user needs are better understood and met the user experience improves

Usability testing does not need to be limited to websites or other online resources Usability principles can be applied to most library services and spaces Graves and Ruppel 2007 discuss how participation in usability testing resulted in improvements to library instruction practices Wu and Lanclos 2011 use ethnographic approaches for both web usability and space design They included usability as part of their ethnographic definition and observed and tested their users in both their physical and virtual spaces Hahn and Zitron 2011 also used ethnographic methods to determine how students navigate space

By examining how our users interact with library service points stack arrangements and furniture it is possible to discover pain points Wherever a decision is made such as a route branching or which service desk to approach it is possible to test how easily that decision is made Hahn and Zitron 2011 Wu and Lanclos 2011 Questions that can be asked observed and tested include Where do users stop to make a decision Is it unclear where to go or what to do next Can users see the service desk or is there a stack blocking the view This is similar to using usability testing to determine pain points on a website Schmidt 2010 By observing our users interacting with our spaces both virtual and physical we can create more usable and enjoyable experiences

The principles and methods applied to websites to improve usability and readability can also be applied to all library communications including emails for fines and recall notices newsletters and signage By avoiding library jargon using personal and friendly language and reducing unnecessary text library communication becomes usable useful and clear Testing of library communications can include AB testing or card sorting to test appropriate terminology to ensure the message is clear or test signage location and readability

In many ways signage within our physical spaces are similar to a website navigation and text text and layout are important in both mediums Too much text can make a website or sign unreadable Font color size and placement can all influence whether or not the signage is useful and usable Barclay and Scott 2012 Design options can be assessed through usability tests such as AB testing and through user feedback to determine user perceptions Bosman and Rusinek 1997 Location of signage as well as fonts and text can undergo usability testing practices Applying usability principles to signage can reduce confusion and increase library service usage

Expanding the principles of usability beyond the website improves the entire library experience By incorporating usability into all aspects of the library both physical and virtual usability also becomes a recognized skill and value within the organization

Creating a Culture of Usability

Cervone 2005 notes the need to create a culture of usability but it is difficult to define what makes up an organizations culture It can include such things as values beliefs assumptions behavior leadership management styles and more Lin 2008 This is further complicated because an organization rarely has a single culture It is usually composed of a number of subcultures that must also be taken into account Lin 2008

The inherent problems of defining both culture and subcultures have led some to suggest that the goal should not be to change culture Lin 2008 Rather than transforming a culture drastically it is better to aim for new goals over time that will influence existing culture As these goals are adopted and achieved they can influence the broader culture of the organization effectively transforming the culture

The creation of a team devoted to usability can act in a similar method As a permanent group it highlights both the importance of user feedback and evidencebased decisions within the organization A standing team devoted to usability testing also implies administrative support for the practice and values the skills the group will develop among its members As skills grow and spread from this team usability becomes an organizational value and inherent aspect of the library culture

Buyin is also important when implementing change one must believe in the changes in order for them to succeed The idea of joinin can be even more powerful than buyin Rather than passively accepting the change joinin promotes participation in the change and ownership over the outcomes Once staff become actively involved there is a greater chance of successfully implementing new goals and affecting change within the organization The establishment of a committee devoted to usability allows library staff to participate in the development of new skills and improving new or existing resources

Staff can join in usability testing in a variety of ways either as a participant in a test a volunteer notetaker or observer or as a member of the usability team Engaging in any of these ways provides further insight into the value of usability testing and develops related skills After testing both library staff and users Turner 2011 noted that participation in usability testing could offer librarians insights into their users and their needs and led to improvements in both website and instructional design Graves and Ruppel 2007 illustrate Turners point as they outline how participation in usability testing helped librarians improve their instructional methods to better meet their users needs Usability teams that open up testing within the library offer an opportunity for staff to joinin and can provide user insight staff skills and positive changes within the library

The Importance of Usability Teams

Usability testing can be accomplished in a variety of ways from single individuals to committees of varying sizes or departments devoted to usability and user experience Many libraries hire a position devoted to user experience which includes usability testing and may work best for smaller organizations While such a position illustrates a librarys devotion to usability and user experience it is often viewed as the responsibility of the single individual Usability testing can be time consuming and overwhelming for a single individual and may not allow for the development of skills in other staff Without participation it may be more difficult to accomplish all necessary testing or for the skills to be appropriately valued by the entire organization and applied to all of the librarys physical and virtual spaces and services

Nichols et al 2009 note two models for conducting usability testing a centralized group in a single department or a distributed or open model The latter is a group whose membership is distributed throughout the library encouraging members from all departments to participate Limiting to a specific department such as a user experience department a systems division or an information services department does increase the number of individuals with user experience responsibilities and shares the workload but still keeps the skills among a small set of individuals As such it may be more difficult to move usability towards an institutional value

Usability teams or committees represent Nichols et als idea of a distributed model for usability work The team draws membership from numerous departments bringing members with differing expertise and skills together The two usability teams created at Oregon State University and the University of Houston libraries stress that interest in usability rather than usability skills was key in team membership Dethloff and German 2013 Nichols et al 2009 Rotating membership allowed numerous individuals from a variety of departments or divisions to gain usability skills spreading these skills throughout the organization while at the same time offering a joinin opportunity

Chen et al 2009 note that only 15 percent of survey respondents had some type of usability team or committee and permanent usability teams are not currently standard practice in libraries Teams tend to be created for specific projects and disbanded when the project is complete There are however numerous benefits to creating permanent usability teams A standing committee on usability allows the work to become part of expected duties rather than viewed as extra responsibilities that are low priority Nichols et al 2009 A permanent team also allows for quick and efficient usability testing as members are familiar with required processes Nichols et al They can readily identify testing priorities for the year prepare ethics clearance in advance of projects and ensure appropriate testing in all phases of a project The team can also act as consultants for projects in other departments Project groups may choose to ignore usability testing if they need to build these skills among their members or view it as slowing down their process However if a standing committee exists projects can consult this group for quick guidance and assistance and ensuring usability is part of all projects

Schaffer 2004 stresses that usability can only succeed if it permeates the organization Skills can be spread throughout the organization via this group especially if one adopts a distributed model for the team As noted this model encourages membership from across the library rather than a particular department or level and allows skills to develop throughout the system Employing this model not only builds skills across the library but may help break down silos within the organization as it brings together individuals who do not normally have the opportunity to work together Nichols et al 2009 Rotating membership in the team brings in new perspectives and knowledge to the group and allows skills to develop and disseminate throughout the organization

The team can also act in a training capacity offering workshops and opportunities to participate in usability testing further spreading usability skills throughout the organization Cervone 2005 suggests that a training program be used to promote a culture of usability He identifies two types of training knowledgebased and skillsbased Knowledgebased training provides background information or context behind usability testing and user experience concepts These can be done as a lunchtime series or as a single day workshop Skillsbased training emphasizes specific tools and techniques and results in knowing how to do something Cervone 2005 It requires both handson experience and time to practice and develop the skill A standing team is ideally situated to implement a training program spreading usability skills throughout the organization and moving the library towards a culture of usability

Usability teams can fall prey to normal pitfalls Most libraries are familiar with the phrase death by committee Personalities come into conflict skills may need to be built lack of clear authority or reporting structures can hamper the group workload or conflicting priorities can be problematic Ensuring administrative support and recognition of the group can help alleviate some of these issues Despite these potential issues the strength of building a usability team lies in the development of skills among many divisions and staff members As usability testing is applied to key projects throughout the library and included in strategic goals the value in a usability team as well as usability skills is highlighted

Memorial University Libraries Experience

Memorial University Libraries located in Newfoundland and Labrador is a system composed of five libraries and three resource centers and serves nearly 18000 students I was hired as the first Web Services Librarian in 2011 and my primary responsibilities included improving the library website and frontend user experience As such one of my first major tasks was reorganizing the large web team in anticipation of a website migration to a new content management system and subsequent website redesign The reorganization of the web team presented me the opportunity to highlight usability skills and work towards a culture of usability through the creation of a web usability team

Previously the library website had been the responsibility of a monthly committee of ten members from across the branches and most library divisions Members represented the needs of their individuals divisions or branches and their users The large size of the group made regular meetings with full attendance difficult and did not offer representation from all public services divisions As web skills were not required members possessed varying degrees of web skills and much of the work fell to a smaller group with stronger skills such as HTML coding I reorganized the web team in a way that recognized the culture of consensus building via committee work and resulted in the creation of three groups each with a specific focus the web advisory team the web implementation team and the web usability team All three groups are presently chaired by me allowing website goals and priorities to be aligned among the three teams while also ensuring information can flow between the groups

The advisory team a group of ten members closely resembles the composition of the former web team and includes members from all library branches and public services divisions Members represent their areas and users and are not required to possess web skills but must be in a public services role This team meets less frequently than the other teams and is consulted on major web decisions ensuring the public services divisions continue to have a voice on web related issues

The implementation team is a smaller core group of five individuals including myself and members are required to possess web related skills such as HTML coding While the team includes a web programmer members tend to come from public services backgrounds This groups meets frequently to discuss and implement website needs and improvements and was a driving force behind the library redesign project deciding the sites information architecture recommending design and building the website within the new content management system As a smaller group it is usually easier to meet regularly and accomplish tasks than it had been in the previous web team The implementation and advisory teams essentially compose the older web team but separate out the focus of building and advising

Previously usability testing was done by members of the web team or through subcommittees working on individual projects Although usability work could have been assigned to the implementation group a new team the web usability team was created to focus on these skills and tasks By pulling out usability work as a specific focus it highlights the work as significant and important to the library Furthermore membership in implementation and advisory groups is generally limited to librarians in particular roles or divisions As a separate group the usability team is open to all with an interest in usability testing and allows more library staff to participate in the work thus developing new skills and an understanding of usability throughout the organization The team consists of four individuals as well as myself and these memberships are staggered twoyear terms with two new members joining the team each year The term length allows for overlap and development of skills Members must have approval from supervisors who will ideally help with workload issues associated with their participation Librarians can count membership in the team as part of their service if it is outside their regular duties In its first two years the usability team has had members from three branches and two major library divisions By opening membership to all usability skills are developed in numerous departments and ideally incorporated into divisional projects Broad membership also brings in new perspectives strengths and skills to the team

The usability teams primary responsibility is to perform usability testing of the library website and other online resources such as the link resolver the OPAC and the discovery layer in order to implement iterative changes although the website redesign took precedence in its early stages As the group shares usability testing results and builds skills through learning opportunities it is hoped that eventually the team will be consulted by other groups in the library to assist with projects both for virtual and physical services and spaces

Strategic objectives for the group also include a role as trainers building usability and user experience skills throughout the library Team member skills are strengthened as they create these learning tools and provide instruction building the skills of their colleagues Goals include the creation of training materials for others in the library such as an online toolkit and formal and informal training sessions such as lunchtime brown bag talks Initial talks have shared testing results and will eventually include hands on workshops on various usability tests and tools In the first year we created a wiki to act as a usability toolkit and members were assigned a type of usability testing such as scenariobased testing or clickheat maps to research explain and provide a list of online tools or readings for others to use and explore The wiki is also used as an informationsharing tool and usability tests are outlined and results shared with staff in this area Creating a shared understanding of usability testing and user experience can help shape library goals and projects and ideally influence the culture towards good user experiences 

Reactions and Successes

The website usability team has played a key role in the library website redesign and migration to a new content management system In the first two years of the group the team successfully conducted a variety of tests and activities including focus groups a universitywide survey open and closed card sorts prototype testing and taskbased testing on the new library homepage Results from these tests have influenced the design of the new website

In testing the usability team has reached out to groups on campus for both feedback and assistance The response to requests for assistance in testing has been overwhelmingly positive and the team has been thanked for including student feedback in the redesign process An added bonus of the universitywide survey which resulted in more than 2000 responses was a list of more than 500 volunteers interested in assisting in future website testing This list has been essential as we continued to test the library website redesign and highlights that our users want to be heard The group has given them an outlet for this feedback Another success is that the team has been contacted by other groups on campus for assistance with usability testing These groups have also used the wiki toolkit on types of usability testing The wiki has helped us build usability skills and move towards a culture of usability and user experience both in the library and in the university

Initial steps have been taken to expand usability skills among library staff As focus was placed on conducting tests rather than training sessions in order to meet launch deadlines these learning opportunities have been fewer than originally intended As mentioned the first year saw the creation of a web usability toolkit and it continues to develop Developing the toolkit acts as a training opportunity for members but also allows those interested in usability to learn more The usability team has also offered a brown bag session to staff that offered an overview of usability tests and the work we previously accomplished offering staff an insight to the type of work the team does and its importance to the redesign project An overview of usability test results was also offered at our local librarians research fair

A call for volunteers in the teams second and third years resulted in several librarians and library staff members volunteering to participate illustrating interest in both the work the usability team accomplishes and the skills it develops Interest in the team continues to grow as we share findings from the testing and bring to light how our users interact with our library website

Next Steps 

The website redesign has been the focus for the usability team to date and training activities have taken a back seat to conducting usability tests to inform the redesign Increasing the training opportunities through brown bag lunches and staff training sessions will be a focus moving forward While iterative testing of the website will continue over time another goal for the future includes further outreach to existing groups within the libraries such as those involved with signage and space Future projects include ongoing testing on the new library website The library is also implementing a new discovery layer as part of a larger move to a new unified resource management system and the usability team will play a key role in testing the discovery layer

The team has just begun its third year which means that we have had four members return to their divisions or branches with their developed usability testing skills It is still too early to tell how or if these skills have influenced their areas It is hoped that once new projects are begun within their departments and branches the former members will highlight the need to include usability from the beginning of the project Currently smaller projects are being sidelined by a major shift to a new library services platform and discovery layer Library administration expects the usability team to conduct testing on the new discovery layer confirming the librarys commitment to usability 

In this last year our library updated their vision mission and values statement The revised service value although it does not explicitly use the term user experience or usability explicitly enshrines these principles when it states that we provide a consistent highquality experience through our spaces collections policies and interactions with all our users Memorial University Libraries 2015 The work that the web usability team accomplishes is now a stated value within our library and it is hoped that the group will become key in developing the skills so that we may live up to this value within all of the stated areas

Conclusion

Culture does not shift or change overnight but takes time and planning When implementing change it is important to consider the existing culture in the library and ensure that web team structures work within specific institutions what works for one does not work for all By creating goals that work towards realigning priorities rather than implementing drastic culture shifts it is possible to introduce new values such as usability and slowly adopt a new culture

Memorial University Libraries have taken the first steps towards a creating a culture of usability and user experience through the creation of a permanent group focused on usability The team allows for quick and efficient usability testing and builds usability skills throughout the organization through open rotating membership and training Although the team is presently focused on web usability the foundations are in place to develop usability skills more generally and can be applied to other aspects of library work and spaces

Libraries cannot meet user needs without talking to and observing users in their spaces both physical and virtual Usability testing is key to gathering this data and ensuring we are creating usable websites spaces and services As libraries adopt a datadriven culture on account of budget constraints and embrace evidencebased decision making as a practice usability testing becomes an essential tool and an important aspect of a librarys culture A standing usability team highlights the importance of usability within the library allowing the work to be completed quickly and efficiently and increasing the skills within the library while ultimately enhancing the user experience Schmidt and Etches 2014 note the trinity of user experience as useful usable and desirable The implementation of a permanent web team is the first step to creating a culture of usability and improving the user experience

References

	Barclay D  Scott E 2012 Directions to library wayfinding American Libraries 4334 3638
	Bosman E  Rusinek C 1997 Creating the userfriendly library by evaluating patron perception of signage Reference Services Review 251 7182
	Bundza M Vander Meer P F  PerezStable M 2009 Work of the web weavers Web development in academic libraries Journal of Web Librarianship 33 239262

	Cervone F 2005 Usability training An overlooked component in an ongoing program of web assessment and development OCLC Systems  Services 2130 244251
	Chen Y Germain C A  Yang H 2009 An exploration into the practices of library web usability in ARL academic libraries Journal of the American Society for Information Science and Technology 605 953968
	Church J  Felker K 2005 Web team development portal Libraries and the Academy 54 545554
	Connell R 2008 Survey of web developers in academic libraries Journal of Academic Librarianship 342 121129
	Dethloff N  German E 2013 Successes and struggles with building web teams A usability committee case study New Library World 11456 242250
	Forrest C 2009 Academic libraries as learning spaces Library effectiveness and the user experience Georgia Library Quarterly 463 710
	Graves S  Ruppel M 2007 Usability testing and instruction librarians A perfect pair Internet Reference Services Quarterly 114 99116
	Hahn J  Zitron L 2011 How firstyear students navigate the stacks Implications for improving wayfinding Reference  User Services Quarterly 511 2835
	Kneip J 2007 Library webmasters in mediumsized academic libraries Journal of Web Librarianship 13 323
	Krug S 2006 Dont make me think Berkeley CA New Riders
	Lin M 2008 Organizational culture An important factor to consider The Bottom Line Managing Library Finances 213 8893
	Memorial University Libraries 2015 Vision mission values Retrieved from httpwwwlibrarymuncaaboutusaboutourlibrariesvision

	Morville P 2004 User experience design Retrieved from httpsemanticstudioscomuserexperiencedesign

	Nichols J Bobal A  McEvoy S 2009 Using a permanent usability team to advance usercentered design in libraries Electronic Journal of Academic and Special Librarianship 102 18
	Schaffer E 2004 Institutionalization of usability A stepbystep Guide Boston AddisonWesley
	Schmidt A 2010 Touch points and testing Library Journal 1358 20 
	Schmidt A  Etches A 2014 Useful usable desirable Applying user experience design to your library Chicago ALA Editions 
	Turner N 2011 Librarians do it differently Comparative usability testing with students and library staff Journal of Web Librarianship 54 286298
	Veldof J  Nackerud S 2001 Do you have the right stuff Seven areas of expertise for successful web site design in libraries Internet Reference Services Quarterly 61 1338
	Wu S K  Lanclos D 2011 Reimagining the users experience An ethnographic approach to web usability and space design Reference Services Review 393 369389





Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS






















































An Internet of Pings Enhancing the Web User Experience of Physically Present Patrons with Bluetooth Beacons


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










An Internet of Pings Enhancing the Web User Experience of Physically Present Patrons with Bluetooth Beacons




Mikael Jergefelt

Karolinska Institutet



Skip other details including permanent urls DOI citation information
Volume 1 Issue 2 2015



DOI httpdxdoiorg103998weave125356420001202



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













Introduction

Even for users who are physically in the library the website has become a primary interface for interaction This use case presents unique usability challenges In many cases when a user needs to access contextual digital information or services inside the physical library their first step is to find the nearest computerpossibly in their pocketand navigate to the library website Once there the user must navigate through a likely complex information architecture concerned with her need only as one among very many other potential needs This navigation can be rather disruptive to the task at hand

Learning the structure of a new website is usually not a problem for long But if you agree that the website is the primary interface for getting things done in a library you probably also agree that if it were practical to put usable hyperlinks on actual objects or areas that provide fluid access to their virtual equivalents the endeavor would be worthwhile Imagine moving around in the physical library space and always having easy access to the corresponding space on the web

Yes there are QR codes and digital signage While there are creative examples of their use these solutions are typically either unappealing and impractical or unnecessarily expensive and they only solve part of the problem the hyperlink There are still issues of usability user experience and accessibility especially for visuallyimpaired patrons Im writing this to propose another solution built on Bluetooth beacons

Bluetooth 40

You might associate Bluetooth with handsfree headsets or wireless speakers and such devices whichwith their history of erratic functionalitymight turn you off But mainly due to improved battery life and user experience Bluetooth has come a long way since 2010 when the Bluetooth Special Interest Group introduced the 40 specification of the standard In short this made it possible for Bluetooth chips to use a low data rate making them extremely energy efficient and cheaper to manufacture The specification is focused on devices that dont need a constant connection and only exchange small pieces of information using a low power state in between This is why Bluetooth 40 is often referred to as Bluetooth Low Energy BLE and what makes it appealing for inlibrary user experience

Beacons

Beacons are brilliantly simple All they do is broadcast a small advertisement packet a few times per second The packet contains a maximum of 31 bytes and looks a bit different depending on the specifications This article will use the term beacons for all variations of this concept briefly defined as small BLE devices emitting a unique signature that can be picked up by smartphones

iBeacons

Apple was an early adopter of BLE in 2011 when they released the iPhone 4S which was the first phone to support the new 40 specification Android didnt support apps using BLE until 2013 This was also the year when Apple released iOS7 and included an API called iBeacon which at its core is a very elegant combination of hardware and software that gives apps a contextual sense and microlocation of physical spaces Because iBeacon is a proprietary specification limited to iOS only and dependent on the existence of a library app the discussion here will be brief All the same iBeacons are important to understand as the original use Bluetooth beacons

A beacon configured as an iBeacon is set to broadcast a universally unique ID UUID plus a Major and a Minor value Not including the initial Bluetooth advertisement metadata it looks like this


3A66FECC69CA43EA9DD12774795F6ACD 1 9



This 32 character UUID represents your library organization and can be whatever valid values you want Same goes for the major and minor value the two pairs of characters that complete the iBeacon advertisement These values can be set to indicate whatever the administrator wants In the example above taken from Karolinska Institutet University Library the major value of 1 represents the north campus library location and the minor 9 means the academic workshop on the third floor This way an app can know exactly where it is when a user comes in contact with an iBeacon


Figure 1 Theoretical example The app knows the user is outside the academic workshop thats currently closed and offers a link to an online referencing guide instead



When you set your library app to listen for your UUID iOS tells it whenever the device comes in or out of range of one of your beacons if and only if the user has enabled Bluetooth and granted the app permission to do so It is then up to the app to decide how to react to that event The app doesnt even need to be running to react For instance you could send the user a notification as she passes the reserved books shelf reminding her that she has a book to pick up or telling her about the days events as soon as she enters the library Be careful not to spam though


Figure 2 Theoretical example Relevant and informative notifications could be sent as users move through the library but would you like your notification screen to look like this after a visit



If the user has your app open while passing an iBeacon a different approach can be used While in range iOS estimates the proximity to the iBeacon depending on signal strength This can be useful for showing contextual information like ebooks corresponding to the users location among the shelves If in range of multiple iBeacons simultaneously you can even triangulate the signals for more accuracy and in theory build an indoor GPS system


Figure 3 Theoretical example iBeacon triangulation can be used to build an indoor GPS system



iBeacons are a powerful feature in iOS thats easy to code for if you already know your way around iOS development There are also multiple companies selling iBeacon hardware making it a very accessible solution for creating physical contextaware apps The hard part is creating the back end for it all but that can be left for another article

The Physical Web

The Physical Web project is where things get really interesting for libraries Still an experimental projectstarted by Google employed UX designer Scott Jensonthe Physical Web was created out of the frustration of having to download and use apps to interact with smart objects and services in a physical context Searching an app store for the correct app and waiting for it to download before you can even begin to use it is not a process that scales well not to mention the mess it leaves on users phones with repeated use

Native apps can be pretty and polished but for many use cases a web app or web page is more than good enough This is what the Physical Web aims to leverage by creating an ondemand bridge between the virtual web and physical space while also acting as a kind of discovery service The Physical Web can be added to an ecosystem that already has an app too enabling interaction when use of the native apps isnt practical

Bridging the virtual and physical is done by using Bluetooth Low Energy beacons to broadcast plain URLs to inrange devices allowing users to simply tap discovered URLs and bring them up in a browser Any object device or space can broadcast any URL for any web page for any purpose

The real power of URLs is that they are so flexible Consider a few potential uses in academic libraries the schedule for workshops as pinged from a nearby classroom a link to reserve nearby group rooms the ebook collection that best corresponds to nearby shelves and so on No idea is too big or too small and small is probably whats going to be the killer feature when it comes to the Physical Web


Figure 4 Theoretical example Possible Physical Web situation outside the Karolinska Institutet University Library



Of course too many beacons could bring chaos and overload To bring order to the Physical Web the project includes ideas about client sorting and ranking URLs based on signal strength preferences and history

Both the Physical Web and UriBeacon its technical specification for broadcasting and discovering URLs are free of restrictive and proprietary terms by design and developed openly on GitHub making it possible for anyone to contribute Its therefore not bound to any company or operating system in theory making it an ideal solution for reaching the largest number of users

Since a BLE advertisement has a maximum length of 31 bytes the UriBeacon specification has implemented schemes to encode URLs to fit as much as possible into the 18 characters thats left to use after the initial BLE metadata Shortly explained this encoding represents common parts of URLs like the following with typically unused single ASCII characters

	http
	httpswww


or top domains like

	com
	org
	edu


As an example httpweaveuxorg an 18 character long URL could be compressed by 50 percent after using a single character for both http and org as specified by the UriBeacon scheme Not counting the BLE advertisement metadata the URL would be encoded in bytes as

	0x02	0x77	0x65	0x61	0x76	0x65	0x75	0x78	0x08
	http	w	e	a	v	e	u	x	org


The technical specifications of the Physical Web aside and ignoring that as an experimental project it was only published months prior to this writing in October 2014 it can be used today Physical Web beacons are available to purchase or to setup oneself with a variety of hardware The ultimate aim of the project is to be built into the operating system of all smartphones and tablets For now it requires an app Physical Web prototype apps are available for iOS and Android and work in the background pretty much like they would if they were built into the operating system This allows the apps to silently monitor beacons that can be browsed when the user chooses Since its an open standard Physical Web can also be builtin to existing apps as necessary

How is this different from QR codes Where the Physical Web excels is in user experience QR codes are popular in Asia but have not been able to break into the mainstream elsewhere Very few phones have QR code readers builtin and therefore most people dont know what QR codes are The aesthetics of QR codes potentially limit the number of them libraries would want to feature in their spaces QR codes are also short range and can only be used one at a time Compare this to beacons which can be placed out of view and be seen by the user dozens at a time from a large distance A patron could potentially get an overview of services and possibilities available in a mediumsized library right at the entrance Visuallyimpaired patrons can use beacons just as well thanks to the accessibility tools available in smartphones In fact there are countless ways beacons can be beneficial for accessibility but that can also be left for another article

Conclusion

Even though they both share Bluetooth Low Energy as a bearer iBeacons and Physical Web are very different in application A short overview

	iBeacons are mainly tied to Apple and iOS but can be made to work on Android Physical Web is open for any compatible hardware
	iBeacon data are meant to be used by a corresponding app while a Physical Web beacon URL can be understood and used by any app or hardware with BLE support
	iBeacons can trigger actions or display information in the background Physical Web needs user interaction to be opened and seen


In both cases BLE beacons are not without their challenges

	iBeacon development is relatively easy but UX is hard The notifications can easily be designated as spam and opinions about whats actually useful will definitely differ by the user Proper research on what really matters for users is critical
	Even though Physical Web beacons can be leveraged in existing apps it might not be easy to reach users and convince them to download an extra app


Bluetooth beacons are likely an area that will be moving quickly in the coming years Lots of companies are already developing beacon like products in the Internet of Things sector and just recently in November 2014 mobile giant Samsung announced their take on iBeacons called Placedge




Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS



















































Improving Library User Experience with AB Testing Principles and Process


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










Improving Library User Experience with AB Testing Principles and Process




Scott W H Young

Montana State University



Skip other details including permanent urls DOI citation information
Volume 1 Issue 1 2014



DOI httpdxdoiorg103998weave125356420001101



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













This paper was refereed by Weaves peer reviewers

Abstract


This paper demonstrates how user interactions can be measured and evaluated with AB testing a user experience research methodology AB testing entails a process of controlled experimentation whereby different variations of a product or service are served randomly to users in order to determine the highest performing variation This paper describes the principles of AB testing and details a practical webbased application in an academic library Data collected and analyzed through this AB testing process allowed the library to initiate usercentered website changes that resulted in increased website engagement and improved user experience AB testing is presented as an integral component of a library user experience research program for its ability to provide quantitative user insights into known UX problems


Introduction


 Users must be treated as codevelopers  Tim OReilly 2009



Through the process of AB testing user experience UX researchers can make iterative usercentered datadriven decisions for library products and services The AB test and its extension ABn test represent shorthand notation for a simple controlled experiment in which users are randomly served one of two or more variations of a product or service control A variation B and any number of additional variations n where the variations feature a single isolated design variable With proper experiment design the highest performing variation can be identified according to predefined metrics Kohavi 2007 Within a diverse framework of UX research methodologies AB testing offers a productive technique for answering UX questions

AB testing has been a tool of user interface designers and user experience researchers since at least 1960 when engineers at Bell Systems experimented with several different versions of the touchtone phone Deininger 1960 The Bell Systems experiment was framed by a usercentered research question What are the desirable characteristics of pushbuttons for use in telephone sets UX issues such as button size button arrangement lettering button force and button feedback were tested with Bell Systems employees who were then asked which of each variation was preferred most and least In designing this experiment Deininger notes Perhaps the most important factor in the information processing is the individual himself p 1009 Today major companies such as Google Amazon Etsy and Twitter frequently use experiments to make datadriven design decisions1 In accordance with Googles company philosophy engineers use experimentation to understand everchanging user expectations and behavior Tang 2010 p 232 For Google experimentation is practically a mantra Tang 2010 p17 

This approach is widely used because the data derived from AB testing provides direct evidence of user behavior in support of the concept known as perpetual beta In the pursuit of perpetual beta a product or service remains under regular review with feedback from users cycling through an iterative design process that continually seeks to improve the UX of that product or service Usercentered research such as AB testing finds a natural fit within the model of perpetual beta where a culture of userdriven revision helps create products and services that meet current user expectations

  In its overall goal of providing insights into user behaviors AB testing is similar to other widelypracticed UX research methodologies such as usability testing and heuristics evaluation The essential value and distinguishing characteristic of AB testing is its ability to provide quantitative user feedback for known UX problems Whereas usability testing is designed to reveal previouslyunknown UX problems AB testing is designed to reveal the optimal solution from among a set of alternative solutions to an alreadyknown UX problem Since the approach is most suitable for research contexts in which a specific design question can be predetermined the questionanswer structure that defines AB testing also defines the boundaries of its usefulness AB testing is most effective when a clear design inquiry can be formulated in tandem with quantitatively measurable results In this way AB testing can serve as an integral component to a comprehensive UX research program to collect user data and to design for user experiences that meet user expectations The case study presented in this paper demonstrates the technique as applied to a library web design problem

Literature Review

Much of the existing research that explores the statistical structures associated with AB testing can be found within computer science literature with specific investigation of sampling techniques randomization algorithms assignment methods and raw data collection Cochran 1977 Cox 2000 Johnson 2002 Kohavi 2007 2009 Borodovsky 2011 The concept of AB testing has also been present in business marketing literature for several years with a strong focus on ecommerce goals such increasing clickthrough rates of ads and conversion rate of customers Arento 2010 McGlaughlin 2006 New Media Age 2010 A wideranging investigation of the UX of commercial websites is also represented in the business literature This pursuit is couched in the business terms of returnoninvestment customer conversions and consumer behavior with a view towards the usability of online commercial transactions Wang 2007 Casaló 2010 Lee S 2010 Finstad 2010 Fernandez 2011 Tatari 2011 Lee Y 2012 Belanche 2012 While librarians may not focus so intently on the practice of ecommerce the substantial userfocused research found in the business literature is instructive for understanding online user behaviors in general

The library science literature offers no substantial discussion of AB testing Commonalities with computer science and business marketing literature can be found in the shared recognition of the value of user feedback and the objective of designing for user experiences that meet user expectations The library literature offers extensive discussion of UX and usercentered design for a range of library products and services including websites Bordac 2008 Kasperek 2011 Swanson 2011 library subject guides Sonsteby 2013 and search  webscale discovery Gross 2011 Lown 2013 In 2008 S Liu 14 offered a straightforward recommendation for library user experience online future academic library Web sites shouldrespond to users changing needs Within libraries usability studies have been the dominant method for accessing user perspectives and for understanding user behaviors and expectations Other methods include ethnographic studies Wu 2011 Khoo 2012 Connaway 2013 eye tracking Lorigo 2008 Höchstötter 2009 and data mining and bibliomining Hajek 2012 The thrust of these studies converges around an understanding of UX research fundamentally guided by three questions What do users think they will get What do users actually get How do they feel about that The AB testing process when used in concert with these other methodologies can serve as an integral component of a UX research program by introducing a mechanism for identifying the best answer from among a range of alternative answers to a UX question 

AB Methodology  Case Study

The AB testing process follows an adapted version of the scientific method in which a hypothesis is made and then tested for validity through the presentation of design variations to the user The testing process then measures the differences in user reactions to the variations using predefined metrics For the experiment design to be effective the central research question must be answerable and the results must be measurable A successful framework for an AB test follows these steps 

	Define a research question
	Refine the question with user interviews
	Formulate a hypothesis identify appropriate tools and define test metrics
	Set up and run experiment
	Collect data and analyze results
	Share results and make decision


These six steps comprise the AB testing process and together provide the experiment design with clarity and direction The case study presented below follows a line of inquiry around a library website and employs web analytics software to build measurable data that answers the initial research question While the focus of the case study is a website the essential principles and process of AB testing may be applied in any context characterized by a known UX problem a definite design question and relevant measurable user data


Step 1 Define a research question

This crucial first step sets a course for the AB test by identifying an general line of inquiry for the experiment The research question is shaped from a known UX problem drawing on existing user feedback such as that derived from surveys interviews focus groups information architecture tree testing paper prototyping usability testing or website analytics In the example of this case study a research question was developed from user feedback received through website analytics Following a review of the website analytics for the librarys homepage in the spring of 2013 it was apparent that the Interact category of content on the web page was neglected by users


Fig 1 Library Homepage  April 2013




Fig 2 Library Homepage Click Data  April 3April 10 2013



During the sample period from April 3 2013  April 10 2013 which included 10819 visits to the library homepage3 there was a large disparity among the three main content categories The clickthrough rate4 for Find was 35 Request was 6 and Interact was 2 This observation prompted a question Why are Interact clicks so low At this time the content beneath Interact included links to Reference Services Instruction Services Subject Liaisons Writing Center About Staff Directory Library FAQ Give to the Library and Floor Maps The librarys web committee surmised that introducing this category with the abstract term Interact added difficulty and confusion for users trying to navigate into the library website homepage Four different category titles were then proposed as variations to be tested Connect Learn Help and Services 




Step 2 Refine the question with user interviews

Interviews with users regarding the different variations can help refine the AB test This qualitative step serves as a smallscale pretest to confirm that the experiment variations are different enough that feedback through the AB test itself will lead to meaningful results Variations that are too similar will be problematic for the experiment design by not allowing for a clear winner to emerge For the purposes of this case study ad hoc conversations with 3 undergraduate students were conducted with a guerillastyle approach5 Questions were designed to provide insight into the user expectations of the library homepages category titles and category page They included

	Have you previously clicked on Interact
	What content do you expect to see after you select Interact
	Does Interact accurately describe the content that you find after selecting Interact
	Which word best describes this category Interact Connect Learn Help Services


Below are selected excerpts from student responses


Sophomore student

	I didnt know that About was under Interact
	Learn doesnt work
	Connect is too vague and too close to Interact
	 Services is more accurate Help is stronger
	Floor maps seem odd here
	In order of preferences of the choices this student responded Help Services Interact Connect Learn



Junior student 

	I am not a native English speaker so I look for strong words I look for help so Help is the best then Services too


Senior student 

	Ive never felt the need to click on Interact What am I interacting with I guess the library
	I never knew floor maps were there but I have wondered before where certain rooms were
	Help makes sense When Im in the library and I think I need help it would at least get me to click there to find out what sort of help there is
	Services also works
	Learn doesnt really work I just think What am I learning I think of reading a book or something
	Connect is better than Interact but neither are very good
	In order of preferences of the choices this student responded Help Services Connect Interact Learn





From these brief interviews insights about the expectations of users come into focus These interviews indicated that the experiment variablesInteract Connect Learn Help Serviceswere likely to provide meaningful differences during the experimentation period and that either Help or Services was likely be the highest performing variation While these users indicated that the five different options would be adequately distinct for this test users may instead indicate that the experiment variations are too alike Users might also suggest their own unique variations that could be included in the experiment design In either of these cases the UX researcher may wish to further refine the variables and repeat this step




Step 3 Formulate a hypothesis identify appropriate tools and define test metrics

As a counterpart to the general UX research question in Step 1 the hypothesis of Step 3 proposes a specific answer that can be measured with metrics relevant to that question The hypothesis provides a focal point for the research question by precisely expressing the expected user reactions to the experiment variations With the combined data from web analytics and user interviews for this case study the library web committee formed the following experiment hypothesis a homepage with Help or Services will generate increased website engagement compared to Learn Connect and Interact With research question centered around this hypothesis metrics relevant to website engagement must be identified that will enable the hypothesis to be tested for validity

 As this case study centers on a websitebased AB test the experiment was conducted using the web analytics software Google Analytics and Crazy Egg6 The case study objective was to understand which category title communicated its contents most clearly to users and which category title resulted in users following through further into the library website Three key webbased metrics were consequently used for this experiment clickthrough rate for the homepage dropoff rate for the category pages and homepagereturn rate for the category pages Clickthrough rate was selected as a measure of the initial ability of the category title to attract users Dropoff rate which is available through the Google Analytics Users Flow and indicates the percentage of users who leave the site from a given page was selected as a measure of the ability of the category page to meet user expectations Homepagereturn rate is a custom metric formulated for this experiment This metric also available through the Google Analytics Users Flow measures the percentage of users who navigated from the library homepage to the category page then returned back to the homepage This sequence of actions provides clues as to whether a user discovered the desired option on the category page if not the user would likely then return to the homepage to continue navigation Homepagereturn rate was therefore selected as a measure of the ability of the category page to meet user expectations The combined feedback from these three metrics provides multiple points of view into user behavior that together will help validate the hypothesis 




Step 4 Set up and run experiment

AB tests operate most quickly and efficiently when variations reflect a subtle and iterative design progression Experiments that intend to test stark design differences on the other hand may result in a diminished user experience and a less efficient testing process  Consider for instance an AB test that seeks to find the optimal layout of a web page If the experiment were to include significant design changes then users who encountered different variations might become confused page navigation would become difficult and the user experience would likely suffer For AB tests that feature such stark differences the experiment designers may wish to include less than 100 of users so as to reduce the risk of user confusion With tests that feature more finelydrawn design changes users are likely to experience only minimal disruption during the course of the experiment For AB tests that feature minor differences the experiment designers may wish to include 100 of users Tests that reflect iterative design changes and that include all users will lead to faster results as a greater number of users included in the experiment will yield more significant results in a shorter period of time

Since the test variables in this case study were largely nondisruptive 100 of website visitors were included for a duration of three weeks from May 29 2013  June 18 2013 Based on our typical web traffic this period of time allowed us to collect enough data for a clear winner to emerge The experiment was designed to ensure that each user visited a variation with an equal level of randomization and that each variation received an approximately equal number of user visits Other AB test designs may employ alternative sampling techniques and the exact mechanics of an experiment design will vary according to the tools used For example Google Analytics offers an alternate experiment design known as multiarmed bandit in which the randomization distribution is updated as the experiment progresses so that web traffic is increasingly directed towards higherperforming variations This approach is often favored in ecommerce AB tests where a profit calculation may determine that lowperforming variations only be minimally served to users

Google Analytics includes a clientside experimentation tool called Experiments a powerful option that provides the randomization mechanics for websitebased AB testing7 Experiment settings within Google Analytics control the percentage of traffic to be included in the experiment and the time duration for the experiment8 As a supplement to Google Analytics Crazy Egg collects user click data and generates tabular and visual reports of user behavior While Crazy Egg itself is not required to run AB tests it was included in this case study to provide a fuller set of user click data than is available through Google Analytics alone

With the case study hypothesis formulated metrics defined and relevant tools identified the web committee created variation pages and the experiment was set up using Google Analytics and Crazy Egg Five different variations of the library homepage ran concurrently on the website each served randomly and in realtime to website visitors using Google Analytics The original page and each variation were given sequential names and were located within the same directory 

	Experimentation Name	Category Title	URL
	Control	Interact	wwwlibmontanaeduindexphp
	Variation 1	Connect	wwwlibmontanaeduindex2php
	Variation 2	Learn	wwwlibmontanaeduindex3php
	Variation 3	Help	wwwlibmontanaeduindex4php
	Variation 4	Services	wwwlibmontanaeduindex5php



Fig 3 Control  Interact





Fig 4 Variation 1  Connect





Fig 5 Variation 2  Learn





Fig 6 Variation 3  Help





Fig 7 Variation 4  Services







Step 5 Collect data and analyze results

With the hypothesis defined metrics identified and experiment launched the test itself can run its course for its defined duration Experiment visits for this case study reflected a typical number of visits for this time period and at the end of the threeweek experiment duration data for the three key metrics were analyzed Clickthrough rate analysis was organized into five categories according to the primary actions of the library homepage clicks into Search clicks into Find clicks into Request clicks into the variable category title and clicks into Other defined as all other entry points on the page


Fig 8 Experiment Clickthrough rates  Control Page Interact





Fig 9 Experiment Clickthrough rates  Variation Pages




Fig 10 Experiment Clickthrough Rates




Fig 11 Experiment Dropoff Rates




Fig 12 Experiment Homepagereturn Rates



Variation 4  Services was the highest performing across Clickthrough rate Dropoff rate and Homepagereturn rate9 This variation performed exceptionally well in Dropoff rate and Homepagereturn rate During the experiment period of those visitors to this variation who clicked into the category page 0 returned to the homepage and 0 dropped off the page These unusually low figures would likely not be replicated over the longterm When evaluated comparatively however Variation 4  Services emerged as the most successful variation according to the experiment metrics When these results were combined with the user interview responses from Step 2 which indicated that Variation 4  Services or Variation 3  Help would be the most successful variation Variation 4  Services was identified as the overall highestperforming variation 

While the experiment described in this case study produced a successful test not every test will produce a clear winner Ambiguous outcomes may result from poor experiment design or a misconfigured test set up In cases where no apparent winner emerges the UX researcher can follow the AB testing steps to refocus the research question rework the design variables or retest the variations with an altered experiment design If a process of refinement continues to produce no meaningful results the central research question may be more constructively approached from an alternative UX research perspective 




Step 6 Share results and make decision

An essential final step in the AB testing process is to convert experiment data into meaningful results for peers and decisionmakers The UX researcher is tasked with communicating the AB testing process so that the hypothesis metrics and results are meaningful in the context of user experience Data visualization tools such as Crazy Egg for example allow complex click data to be presented compellingly for nontechnical colleagues and coworkers With user data collected and evaluated for this case study the report went forward to the library web committee that more users clicked through and followed further into the website when the category title was named Services As a result of this AB test the library homepage design was changed to include the Services category title 



Discussion

The AB testing process provides a structure to ask and answer UX questions about library products and services User behavior insights from this process can be unexpected and it is crucial that unexpected results remain welcome during the AB process In early discussions regarding the experiment detailed in this paper members of the library web committee favored Learn the category title that later resulted in the lowestperforming variation during the experiment period Had AB testing not been introduced to these design discussions decisionmaking regarding the category title would have suffered for its lack of direct user feedback This example AB test allowed the library to gather quantitative user data by testing 5 different variations of the website homepage simultaneously The highestperforming variation improved the library website homepage by creating a user experience that meets user expectations to a greater degree than the previous version of the homepage as measured by clickthrough rate dropoff rate and homepagereturn rate

The case study presented in this paper describes one websitefocused application of AB testing The central principles of usercentered experimentation may be applied in creative ways throughout a librarys range of products and services For example a library may wish to test the language or design of its email newsletters to improve subscriber engagement and event attendance Digital signage may also be a subject of AB testing in a way that reveals the optimal design for gaining the attention of users and communicating relevant information Mobile app notifications could also be tested with an experiment design that evaluates the effectiveness of various notification messages in generating app activity 

While the AB testing process offers a powerful and flexible research technique limitations exist that must be considered When employed in isolation AB testing can lead to incomplete conclusions Consider a UX research initiative that uses only AB testing in evaluating the effectiveness of a calltoaction button in a web application In a narrowlyfocused experiment that examines the design of the button and uses clickthrough rate as the metric results may skew in favor of a bright or otherwise conspicuous button variation at the expense of other UX problems such as poor information architecture or confusing web copy UX research into this calltoaction button will benefit from multiple and varied approaches that can together provide a wider scope for the UX problem As a quantitative evaluation of user behavior AB testing itself does not offer qualitative insights that would reveal the purpose or reason of user behaviors The fundamental value of AB testing lies in its ability to provide quantitative user insights into known UX problems problems which themselves must be identified through alternative UX research methodologies

For these reasons it is necessary to ground experimentation in a wider context by integrating AB testing into a comprehensive UX research program Controlled experimentation is most effective in providing user data in complement to additional UX research methods that may include usability studies paper prototyping ethnographic studies data mining and eye tracking An AB test for instance may indicate that users prefer certain library workshop descriptions within a promotional email as measured by inbound web traffic and subsequent workshop attendance Usability studies may then further reveal that users prefer those workshops due to the style of description but also because the topics are particularly relevant or interesting These alternative UX research methods respond to the limitations of AB testing and together constitute an effective constellation of UX research techniques 

UX research reaches its full potential when quantitative and qualitative methodologies are combined to provide a multifaceted view of user behaviors perspectives and expectations Such varied UX research programs help realize the concept of perpetual beta where the design of products and services undergoes a recurring usercentered process of building testing analyzing and iterating The AB testing process described in this paper provides one element of a UX research framework that allows for decisionmaking that is iterative and guided by user behaviors In sum AB testing proved to be an effective method for collecting user data and improving library user experience by offering a method for answering UX questions The AB testing process ultimately represents a valuable form of observation where known UX issues are productively informed by those users who interact directly with the librarys products and services 

References

	Allen J  Chudley J 2012 Smashing UX design Foundations for designing online user experiences Vol 34 John Wiley  Sons
	Arento T AB testing in improving conversion on a website Case Sanoma Entertainment Oy BA Thesis Available from Theseusfi database URN NBN fi Bachelors 201003235880
	Atterer R Wnuk M  Schmidt A 2006 May Knowing the users every move user activity tracking for website usability evaluation and implicit interaction In Proceedings of the 15th international conference on World Wide Web pp 203212 ACM
	Belanche D Casaló L V  Guinalíu M 2012 Website usability consumer satisfaction and the intention to use a website the moderating effect of perceived risk Journal of retailing and consumer services 191 124132 doi101016jjretconser201111001
	Bordac S  Rainwater J 2008 Usercentered design in practice the Brown University experience Journal of Web Librarianship 223 109138
	Borodovsky S  Rosset S 2011 December AB testing at SweetIM The importance of proper statistical analysis In Data Mining Workshops ICDMW 2011 IEEE 11th International Conference on pp 733740 IEEE
	Brooks P  Hestnes B 2010 User measures of quality of experience why being objective and quantitative is important Network IEEE 242 813
	Casaló L V Flavián C  Guinalíu M 2010 Generating trust and satisfaction in eservices the impact of usability on consumer behavior Journal of Relationship Marketing 94 247263 doi101080153326672010522487
	Cochran W G 1977 Sampling techniques New York Wiley
	Cox D R  Reid N 2000 The theory of the design of experiments New York CRC Press
	Connaway L S Hood E M Lanclos D White D  Le Cornu A 2013 Usercentered decision making a new model for developing academic library services and systems IFLA journal 391 2029
	Deininger R 1960 Human factors engineering studies of the design and use of pushbutton telephone sets Bell System Technical Journal 394 9951012
	Fernandez A Insfran E  Abrahão S 2011 Usability evaluation methods for the web A systematic mapping study Information and Software Technology538 789817 doi101016jinfsof201102007
	Finstad K 2010 The usability metric for user experience Interacting with Computers 225 323327 doi101016jintcom201004004
	Gross J  Sheridan L 2011 Web scale discovery The user experience New library world 11256 236247 doi10110803074801111136275
	Hájek P  Stejskal J 2012 Analysis of user behavior in a public library using bibliomining In Oprisan S Zaharim A Eslamian S Jian MS Aiub CA and Azami A Eds Advances in Environment Computational Chemistry and Bioscience pp 339344 WSEAS Press Montreux Switzerland Available at httpwwwwseasuselibraryconferences2012MontreuxBIOCHEMENVBIOCHEMENV53pdf
	Herman J 2004 April A process for creating the business case for user experience projects In CHI04 extended abstracts on Human factors in computing systems pp 14131416 ACM
	Höchstötter N  Lewandowski D 2009 What users seeStructures in search engine results pages Information Sciences 17912 17961812
	Johnson R A  Wichern D W 2002 Applied multivariate statistical analysis Vol 5 No 8 Upper Saddle River NJ Prentice Hall
	Kasperek S Dorney E Williams B  OBrien M 2011 A use of space The unintended messages of academic library web sites Journal of Web Librarianship 53 220248
	Khoo M Rozaklis L  Hall C 2012 A survey of the use of ethnographic methods in the study of libraries and library users Library  Information Science Research 342 8291
	Kohavi R Henne R M  Sommerfield D 2007 August Practical guide to controlled experiments on the web Listen to your customers not to the hippo In Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining pp 959967 ACM
	Kohavi R Longbotham R Sommerfield D  Henne R M 2009 Controlled experiments on the web survey and practical guide Data Mining and Knowledge Discovery 181 140181 doi101007s1061800801141
	Kohavi R Deng A Frasca B Longbotham R Walker T  Xu Y 2012 August Trustworthy online controlled experiments Five puzzling outcomes explained In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining pp 786794 ACM
	Lee S  Koubek R J 2010 Understanding user preferences based on usability and aesthetics before and after actual use Interacting with Computers 226 530543 doi101016jintcom201005002
	Lee Y  Kozar K A 2012 Understanding of website usability Specifying and measuring constructs and their relationships Decision Support Systems 522 450463 doi101016jdss201110004
	Liu S 2008 Engaging users the future of academic library web sites College  Research Libraries 691 627
	Lorigo L Haridasan M Brynjarsdóttir H Xia L Joachims T Gay G  Pan B 2008 Eye tracking and online search Lessons learned and challenges ahead Journal of the American Society for Information Science and Technology 597 10411052
	Lown C Sierra T  Boyer J 2013 How users search the library from a single search box College  Research Libraries 743 227241
	Marks H M 2000 The progress of experiment science and therapeutic reform in the United States 19001990 Cambridge Cambridge University Press
	McGlaughlin F Alt B  Usborne N 2006 The power of small changes tested Marketing Experiments Retrieved from httpwwwmarketingexperimentscomimprovingwebsiteconversionpowersmallchangehtml
	Nielsen J 1994 Guerrilla HCI Using discount usability engineering to penetrate the intimidation barrier Costjustifying usability 245272
	Nguyen T D  Nguyen T T 2011 An examination of selected marketing mix elements and brand relationship quality in transition economies Evidence from Vietnam Journal of Relationship Marketing 101 4356
	OReilly T 2009 What is web 20 OReilly Media Inc
	Ouellette D 2011 Subject guides in academic libraries A usercentred study of uses and perceptionsLes guides par sujets dans les bibliothèques académiques Une étude des utilisations et des perceptions centrée sur lutilisateur Canadian Journal of Information and Library Science 354 436451
	Rossi P H  Lipsey M W 2004 Evaluation A systematic approach Sage
	Sonsteby A  DeJonghe J 2013 Usability testing usercentered design and LibGuides subject guides A case study Journal of Web Librarianship 71 8394 doi101080193229092013747366
	Swanson T A  Green J 2011 Why we are not Google Lessons from a library web site usability study The Journal of Academic Librarianship 373 222229 doi101016jacalib201102014
	Stitz T Laster S Bove F J  Wise C 2011 A path to providing usercentered subject guides Internet Reference Services Quarterly 164 183198 doi 101080108753012011621819
	Tatari K UrRehman S  UrRehman W 2011 Transforming web usability data into web usability information using information architecture concepts  tools Interdisciplinary Journal of Contemporary Research in Business 34 703718
	Tang D Agarwal A OBrien D  Meyer M 2010 July Overlapping experiment infrastructure More better faster experimentation In Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining pp 1726 ACM
	Visser E B  Weideman M 2011 An empirical study on website usability elements and how they affect search engine optimisation South African Journal of Information Management 131 doi104102sajimv13i1428
	Wang J  Senecal S 2007 Measuring perceived website usability Journal of Internet Commerce 64 97112
	Wu S K  Lanclos D 2011 Reimagining the users experience An ethnographic approach to web usability and space design Reference Services Review 393 369389
	Multivariate testing A broad sample 2010 February 4 New Media Age 18 Retrieved from Academic OneFile


Notes



	httpmcfunleycomdesignforcontinuousexperimentation httpsblogtwittercom2013experimentstwitter httphbrorg200710theinstitutionalyesar1 httpgoogleblogblogspotcom200903makesenseofyoursitetipsforhtml

	 For Googles 10point company philosophy httpwwwgooglecomaboutcompanyphilosophy

	 This time period was chosen as a representative snapshot of library web traffic

	 Clickthrough rate is defined as the number of users who visit a page divided by the number of users who click on a specific link expressed as a percentage For example if a page receives 100 visits and a particular link on that page receives 1 click then the clickthrough rate for that link would be 1 

	 Such guerilla testing is an efficient and effective method for conducting rapid qualitative user experience research See Nielsen 1994 and Allen  Chudley 2012 p94 for a background and description of guerilla testing

	 httpwwwgooglecomanalytics httpwwwcrazyeggcom 

	 httpgoogleblogblogspotcom200903makesenseofyoursitetipsforhtml httpssupportgooglecomanalyticsanswer2844870

	For detailed descriptions of these settings see httpssupportgooglecomanalyticsanswer1745147hlenreftopic1745207rd1 httpsdevelopersgooglecomanalyticsdevguidesplatformexperimentsoverview

	 Due to a reporting limitation within Google Analytics Help category data was incomplete






Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS
























































The UX Moment A Weave Digital Panel Part One


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










The UX Moment A Weave Digital Panel Part One





Skip other details including permanent urls DOI citation information
Volume 1 Issue 2 2015



DOI httpdxdoiorg103998weave125356420001203



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













In midJanuary 2015 Weave reached out to a number of librarians who are doing user experience work with the hope of instigating and documenting the conversation they might have with one another Coming from not only academic and public libraries but also library and information science degree programs the assembled group of professionals is doing and thinking about library user experience in a broad set of contexts and by a variety of means

The conversation that resulted reflects that broad range of experience Some librarians are working inside user experience departments where others must find a way to do UX amidst other duties duties which also vary Some work in job descriptions emphasizing web development others focus on visual design and architecture and still others work primarily as ethnographers of library users If this feature is itself a modest documenting of what library user experience can look likeat least in 2015 and in these nine different institutionsthen library user experience is itself quite a large number of things

The conversation below unfolded over email between Tuesday January 20 and Friday January 23 2015 Because of the length of the conversation and the range of topics it covers the editors have decided to run it in two segments The first part featured here focuses on the definitions and institutional contexts for library user experience The second part to be featured in issue 3 will consider the UX moment that libraries are currently undergoing as well as tools and professional knowledge sharing

Participants

Jennifer Anderson Senior User Experience Designer New York Public Library

Rebecca Blakiston Associate Librarian User Experience University of Arizona

Heidi Steiner Burkhardt Head of Digital Services Norwich University

Georgina Cronin User Experience Librarian Cambridge University

Stephen Francoeur User Experience Librarian Baruch College City University of New York

Amanda L Goodman User Experience Librarian Darien Library

Eric Larson Web Architect and User Experience Analyst University of Minnesota

Craig MacDonald Assistant Professor and User Experience Concentration Coordinator Pratt School of Information and Library Science

Erin White Web Systems Librarian Virginia Commonwealth University

Moderators

Pete Coco Digital Learning Strategist Wheaton College Weave Editor

Matthew Reidsma Web Services Librarian Grand Valley State University Weave Editor

Questions

	Who is doing UX work in your library How does it fit into existing partnerships collaborations workflows and workloads
	Have any of you who are working on UX outreach outside of the library participated in ad hoc projects Trained or helped run usability tests for other departments


Who is doing UX work in your library How does it fit into existing partnerships collaborations workflows and workloads


Rebecca Blakiston

Last summer we formed a new User Experience Department which includes our web development team marketing and public relations content strategy instructional design and IT support Its a big group about twenty of us The content strategist and I lead most of our UX efforts as far as user research goes but our web development team also plays a significant role Were also trying to instill UX thinking across our organization Our department is still new and figuring out exactly how to manage and structure our work Strategic planning should happen in the coming month which will help with this

This is a great question to start us offespecially as weve undergone a recent reorganization of this work Im curious to hear from others




Georgina Cronin

I am primarily responsible for UX in my library I am a dedicated User Experience Librarian and I apply ethnographic approaches to my work I carry out userfocused research using various techniques and then feed these back to the rest of the team so that we can work together to alter our existing service or create new services as a direct result of the findings of my research Many members of the team that I work within help with UX research and occasionally do projects themselves so it really is a joint effort

As far as partnerships go by doing effective UX research with different groups and stakeholders around our institution we raise the profile of ourselves and library professionals especially with our academic colleagues who are often amazed that librarians do research at all Other library colleagues from around the rest of my university are often interested in what were doing and this results in collaboration opportunities training and also being asked to be involved with UXfocused projects elsewhere

Workloads and workflows can present a challenge While I do UX as part of my role it isnt all that I do and so I have to balance it with looking after my dedicated student group help the team run the library service and all the other bits and pieces that I look after




Heidi Steiner Burkhardt

Our entire library staff is smaller than Rebeccas UX department  so we definitely approach things a lot differently As much as I loathe the phrase build a culture I am also proud to say that we have made a lot of progress in that direction I have always had an interest in thinking more deliberately about user experience stemming from my initial role working with our fully online students When I took over our digital services it was definitely something I wanted to focus on though it is not in anyones job description here

All of our librarians have their individual job duties plus reference instruction collection development and whatever else our liaison roles throw at us Unfortunately doing any sort of significant user research is not really in the cards I have taken the lead on working with data and information we already collect by mining our various library statistics and institutional data as well as looking at broader studies in librarianship and higher ed to paint an informed picture of our patrons and create our primary personas This is all housed in a guide called Our Patrons for staff to refer back to and I remind everyone about it regularly I am also a big proponent of controlling what we can so a big focus in terms of our online presence has been promoting things like effective web writing through our web style guide and consistency of web presence in terms of header colors etc

In terms of workflows and workload at this point UX is a mindset and it fits right in for us because we all incorporate thinking about our users into our daily work This bleeds into everything from digital collections and interlibrary loan services to signage Our library historically is considered one of the most responsive and helpful on campus so this attitude already jibes It is really awesome to hear Georginas experience of their work translating into more collaboration across campus




Stephen Francoeur

A number of years ago when I was an information services librarian doing an equal mix of reference and instruction I was given the opportunity to create a new position of user experience librarian Since our chief librarian is also head of campus IT technically hes our CIO our systems and web development support came from campus IT and not from an internal library unit So one challenge was figuring out where a UX librarian position should live within the librarys organization The Collection Management division turned out to be the best fit as it would give me the chance to have admin access to the many databases and other library systems that were in great need of alignment with user expectations

As we move to new platforms for subscription services eg databases or begin our access to new ones eg our discovery service I lend a hand in customizing them and getting them set up on the library website For this work I am frequently collaborating with the head of Collection Management my direct supervisor our catalogers and metadata librarians and with the campus IT person who does web development for us In some instances I design usability tests to help with the launch of these new services and resources and can sometimes draw on the help of relevant colleagues to run the tests with me In other instances I draw on what Ive learned from past usability tests and from other research efforts such as query log analyses to make informed design decisions

Much of the UX work I do is instigated by our library starting something new and me being asked to be part of the team that launches it as in the case of our institutional repository which has a team just organizing now to plan a launch maybe by the end of this year I do though look for research projects that can help me make the case for redesign work Id like to see happen For instance this spring Im planning to use a variety of lenses to examine what our users expect from the multifunction search box on the library homepage If I can gather enough evidence about how misaligned user expectations are with their actual experience of our search box I can make the case to my colleagues that we need to invest the time in an overhaul of a very central piece of technology on the library site

Although there is no end of research projects I can dream up for myself finding the ones that will have the most impact that are doable and that are aligned with the librarys strategic goals is the tricky part Im still working on ways to balance the list of projects Id like to pursue with those that get dropped into my lap as we start to plan new services eg our institutional repository our discovery service etc Its become the new normal now that when our library is planning a new service on the web I get asked to be part of the team because of what Ive learned from my UX work

At the moment I am the only person in the college doing any UX work Ive been asked once by a colleague in a center elsewhere on campus for advice about UX work for a project he was working on Id like to think that there will be more opportunities for collaboration like this on campus




Eric Larson

I would say UX work at the University of Minnesota Libraries is widespread but not centrally coordinated in the grand gesture that its everyones responsibility but no single person or committee owns it

In the last six months I have led a team of librarians and web developers to begin monthly formal usability testing of our online services This work has improved our library homepage and engaged faculty researchers and deans as we launch a new librarymanaged data repository for campus This effort has also given renewed awareness and appreciation of the UX process within our library Each time we hold a testing session the number of staff in the observation room grows fuller

The momentum behind our online services approach has boosted public service staffs interest in adopting UX principles and design thinking to streamline physical services Discussions have begun to happily marry our efforts online and physical but its unclear how that will really take shape I imagine there will be much greater effort once some strategic hires and our new strategic plan is in place




Amanda L Goodman

We are a four member department assistant director system admin brand new UX ninja real titlehe takes care of hardware and UX librarian me Our UX department thinks of itself as a group of consultants so we help our colleagues realize their projects This means that most of our direct work is done internally Of course everything we work on then appears in front of patrons in some format

My job does not have a description so its been up to me to decide what I want to do Ive decided that training everyone to be usercentric is my main task Therefore I meet regularly with all departments often informally or in small meetings of 13 people to discuss their projects I help them think about

	How the patron is going to learn about their program
	How to manage the workflow of people moving through the space during the event
	How to get contact details if needed
	All the tiny details regarding patron interactions with the library


My fellow UXers are in charge of hardwarekeeping the building running so I have the primary job of working directly with people Most of my UX testing is through the guerilla method I also have a few goto patrons that I bounce ideas off of to get their feedback When I set up our touchscreen kiosk I then busied myself nearby to see how people interacted with it Then on the backend I checked Google Analytics to see what people were doing when I wasnt around

I have been pushing since day one for my colleagues to keep their eyes and ears open to patron feedback and behaviors While some of my colleagues will email me I know that facetoface is the best way to gather data from them So a few times each week I make a trip around the library to check in with people Then I keep a record in Trello of anything that I should look into My coworkers have seen the board and know that I will follow up with everything




Erin White

Wow so exciting to hear about everyones UX lives at their libraries It sounds like we have organizational cultures that would fall all over this UX thinking scale proposed by Coral SheldonHess Amanda Darien Library sounds like a 5

I walked into a lucky situation at Virginia Commonwealth University VCUmy former boss Susan TeagueRector had worked really hard to build a culture that supported UX thinking so I have been able to build on her work instead of starting from the ground up Theres no formal UX charge at our organization but Id put us at about a 3 on the UX thinking scale

We have a threeperson web team here that does webonly UX work I lead the web team and am the web UX goto person for the library our designer and developer both came from the private sector and bring some great perspective from outside the library bubble

No surprise here we dont do as much UX work as I want us to We developed personas in 2013 which continue to guide our decisions and we do occasional UX assessments for sites or apps Given the wide interest in UX across the library and the web teams workload my newest idea is to form a crossdepartmental crew that helps with UX assessments

Like Stephen I spend time helping make informed design decisions for vendor apps which I consider UX work as well Courtney MacDonald talked about this in her Weave interview and I think its something we often overlook when we talk about our work though its important

Hats off to Georgina for raising the profile of the library across campus I have also been meeting more and more with other web folks at VCU in libraries around Richmond and at web agencies to make connections and get fresh ideas and inspiration Its been good to have sounding boards outside of my organization and I like to think its helpful for the library too




Eric Larson


my newest idea is to form a crossdepartmental crew that helps with UX assessments Erin White



I want this too My campus has ten projects for every one that receives our official UX assistance




Heidi Steiner Burkhardt

Dittokinda We are small enough that big decisions are all made as a team and I can prompt UX considerations if others do not bring things up Still I am hoping to create a team with colleagues from a few different areas on the digitalweb and public services sides to help set a more strategic direction for how we approach UX and identify specific things we want to look at



Have any of you who are working on UX outreach outside of the library participated in ad hoc projects Trained or helped run usability tests for other departments


Matthew Reidsma Weave Editor 

Thats kind of an academic library oriented question so let me also bring in the public library and LIS education folks do you have the sense that stakeholders outside of your library see the library as a place where this kind of helptrainingservice is available

For Craig do folks come in to the Library and Information Science LIS program at Pratt already aware of UX and its place in the library world




Jennifer Anderson

The UX work in my organization is split up in a couple different ways First of all there are two teams doing the work of building digital experiences theres the main Digital Experience group of which I am a member and theres our Labs and Digital Collections crew who work on more experimental interface design projects as well as our digitized material discovery platform Digital Collections

Our group comprises three developers a content strategist our first were very excited to finally have this person on the team an information architect and myself the senior UX designer Im responsible mostly for the visual design I design the layouts and visual treatment create wireframes and write a little bit of code I work very closely with our information architect IA who runs our user testing Together she and I plan the site AB tests for which we use the product Optimizely

UX thinking has definitely evolved over the last couple years at the library I think thats due in large part to having an IA whose job it is to meet directly with the various stakeholders in the site Having her available to present wireframes get feedback and communicate with our content partners has done a lot to involve those folks in our process

I dont think our patrons necessarily think of the library as a place that does UX although that may be because library work is so closely aligned with UX that the distinction is quite subtle Like Amanda weve done a lot of guerillastyle UX testingour last big project involved testing prototypes with an iPad and a couple from our team grabbing folks as they came into the library  The more of that we do the more visible the UX work becomes

Incidentally that big project was an overhaul of our locations section That work was informed by a lot of testing including staff surveys card sorts and inperson user testing of prototypes It allowed us to reposition our locations section as a searchbased service for our patrons rather than a flat list of information So far the response has been mostly positive there are always a few who dislike any kind of change as Im sure you all well know from your own testing experiences 




Erin White

I dont think most of our users see us as a UX hub unless theyre active in the UX community in Richmond Other web folks at VCU and in Richmond know a little about what weve got going on Ive been brought in to talk to departments at VCU and a few area libraries about our processes and our user research

It really helps that Ive been involved in outsidethelibrary things like edUi Conference Richmondarea web organizations and the UX twitterverse More importantly my boss has supported me doing a good deal of this stuff during work hours




Rebecca Blakiston

Im happy to say that over the past couple of years our library web team has been building a reputation on campus as being the ones who know their stuff when it comes to UX Much of this is thanks to involvement in various campus groups We have a campuswide web developers group an informal group that meets monthly to talk web and our developers have been involved in it for some time Our UXDev work team leader Mike Hagedon is currently chairing the group for the second year in a row Weve delivered a few presentations on our work at this group and at campus events like our Mobile Matters Symposium and IT Summit as well as Drupal Camp up in Phoenix Thanks to this exposure weve been contacted for advice from other units I helped the Graduate College organize a card sort and they met with me several times as they did sessions and analyzed their results I gave feedback on a website survey to our campus IT folks and helped a recentlyformed UX group on campus develop personas as part of a new rebranding initiative Just last week the Desire2Learn coordinator D2L is our campus LMS Learning Management System ed contacted me about how to rearchitect their labeling to be more userfriendly




Jennifer Anderson

Weve also got a bunch of folks participating in outside groups such as Code4LibNYC and METRO the Metropolitan New York Library Council Our IA helps to run the Museum Computer Network conference as well Ive spoken at Pratt Institute to their UX group a couple times




Stephen Francoeur

I know that at NYU the librarys UX staff led by Nadaleen TempelmanKluit and some part or unit in NYUs campus IT put on a joint event every year for World Usability Day Heres a page about their 2013 event httpswpnyueduuxuxatnyu2013




Amanda L Goodman

I work individually with patrons to teach them how to buildmanage websites social media email marketing and graphic design So while patrons may not knowingly come to us for UX education they end up getting it anyways I lead patrons through the usual questions about who is your audience where can you find them how to watch analytics to see how your efforts are doing etc

In response to Stephen Francoeur ed Wow that youre in collection management Then again that makes sense as an alternative if youre not in an ITrooted background we used to be IT before we became UX I noticed that many library UX job listings focus solely on the websitedigital aspect The ads ignore the bigger components of physical space personnel interactions and just an overall holistic approach

In response to Erin White ed Ideally Id love to say were a 5 on the UX thinking scale by Coral We strive to always be considerate but in practice were probably more of a 35 we care and try Since we dont deal with a lot of red tape staff are encouraged to dream up projects and then immediately put them before patrons with little to no oversight Of course we generally bounce ideas off each other before we take them live

We just had a staff development day where everyone was invited to contribute any improvement comment or program idea Large print outs of the building were marked up with allhandsondeck observations For example we need water fountains on all floors While I doubt my colleagues would notice this was actually a UX exercise they were all contributors

Im also so jealous of content strategy and IA specialists within your departments Im a huge advocate for content strategy but thats an ongoing campaign




Craig MacDonald

From my perspective as an educator there are two separate but closely related issues working here First there is a definite hurdle to UX being seen as a part of librarianship Every semester at our new student orientation at Pratt I ask our incoming students if they know what UX is and its rare that more than a handful answer in the affirmative Id say it usually takes a full semester of coursework in UX before students can understand and articulate why UX is so important to the field so I think theres a definite gap between UX and LIS from an education standpoint but if you look at library school curricula I think that gap is slowly closing With that said I dont think this problem is unique to libraries or librarianship This is the second issue Ive noticed for a lot of peopleeven those who work directly with technology and are very smart and forwardthinkingUX is a foreign concept Ive spoken to some of our graduates who work as UX professionals in very progressive techcentric organizations and they all tell me that a big part of their job is arguing and fighting sometimes unsuccessfully to do something UXrelated usability testing user research analytics etc

The upshot for me and what Ive started emphasizing in all of my classes now is that UX is not about tools or techniques its about people and relationships




Jennifer Anderson

I agree Craig the relationships are very important Before we had a content strategist I cofounded with a colleague who oversees our blogs and other digital content a content strategy working group which brought together various stakeholders in the site from different departments We used our working meetings to figure out issues on the site from a UXcontent strategy perspective But I found that what was most important about those meetings was that the right people were in a room together discussing how their respective parts of the site fit together and informed each other We solved some issues one of the things that got off the ground was an editorial style guide but we also garnered empathy for each other That can go a long way toward getting buyin on projects especially in an organization where the departments can be pretty siloed




Rebecca Blakiston

CraigI love that and want to make a bumper sticker UX is not about tools or techniques its about people and relationships So true

This reminds me of an excellent talk I went to by Lisa Hubert awhile back called Want to sell UX Stop talking UX Her driving theme was that we need to take the UX principles of empathy for our users and use those in our relationships with our colleagues and stakeholders Only by truly listening and understanding to our stakeholders can we truly sell them on the whole idea of UX




Georgina Cronin

So far Im finding it interesting how many of you are involved in the traditional sense of UX ie tech usability while Im working on a more qualitative ethno model of investigating user needs and experiences of our service It is rather fascinating

So I have been involved in various projects outside of my library but mostly working with other libraries I am currently on the project board for a great Universitywide UX project which will be trialing different new services to try and improve the student experience of the multitude of different libraries and spaces around our university We have around 124 individual libraries so it is often a challenge connecting them all up at times

As far as running tests not really my area I suppose the closest things that I have been involved with is running minisessions on skilling up other librarians to do miniUX projects in their libraries using ethnographic techniques as well as helping colleagues test out new services such as better signage and other userrelated things




Heidi Steiner Burkhardt

Our scenarios are really diverse but I love that there are already a few common themes in the conversation standing out for me

Rebeccas note that we need to take the UX principles of empathy for our users and use those in our relationships with our colleagues and stakeholders feels spot on Trying to take into account where other people are coming from is something I have tried to work on personally over the last few years and it has really helped in terms of getting buyin and building partnerships with my colleagues in the library and partners on campus Honestlycannot say I ever thought of this as an approach to building buyin around UX but so much of the time improving services for our patrons has been the motivation things like working with campus IT to make things not broken participating in selecting and piloting a new LMS garnering support to change something on the website whatever

Related to that I find myself mulling the difference between people who have no awareness whatsoever of UX principles and those who are practicing UX in their daily work and do not even realize it Not sure where that goes it just stands out Amandas story about the water fountains and while I doubt my colleagues would notice this was actually a UX exercise they were all contributors brought this to the forefront for me I truly believe that everyone in the library can and should contribute to a more positive user experience but do we have to sell it as UX to make it happen

The last thing then I need coffee is again Amanda mentioning that many user experience librarian job postings are focused on the web aspect and completely ignore the public services physical space and more holistic pieces This crumbles my cookies




Georgina Cronin

Your last comment about the holistic side of things and physical space is almost exactly what Im doing in my role so really struck a chord with me but then my job is shiny new and really unusual More of the focusing on the user as a human being rather than a more removed abstract user who interacts with digital services




Heidi Steiner Burkhardt

I hope positions like yours become a trend Georgina Our library is eyeballs deep in a renovation right now and I am helping coordinate all of the technology as well as providing feedback on furniture etc So the physical space aspect has been particularly prominent for my colleagues and me lately as we work to advocate for how people are actually going to want to use the building




Georgina Cronin

You may find this interesting but to use an few examples of the work Im doing and am involved with as a direct result of studies such as our Graffiti Wall weve done things like get our doors to close more quietly provided comfy cushions and bean bags worked at getting our air con to hum quieter and installed new PCs in certain areas while removing some from others that werent being used All of this was based on feedback from students gained through ethno studies as opposed to anything we ever got from our annual survey Hugely useful and the best bit is that so many of our studies are quick and easy to set up so we get almost instant results that we can then implement almost overnight A powerful thing Im sure youll all agree






Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS



















































Improving the Library Homepage through User Research  Without a Total Redesign


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










Improving the Library Homepage through User Research  Without a Total Redesign




Amy Deschenes

Simmons College



Skip other details including permanent urls DOI citation information
Volume 1 Issue 1 2014



DOI httpdxdoiorg103998weave125356420001102



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













This paper was refereed by Weaves peer reviewers

Abstract


Conducting user research doesnt have to be difficult time consuming or expensive Your Library website can be improved through user research even if you have design restrictions because of a prescribed branding scheme content management system or any other reason At Simmons College in Boston we recently performed a user research study that took an indepth look at the content organization and wording of links on the Library homepage We conducted an inperson paper survey using paper prototypes to collect feedback from Library users Based on the research findings we made significant updates to the Library homepage that make it much easier for users to find the information they need




At Simmons College Library staff members regularly assess the content organization and design of the library website based on user feedback Our most recent user research conducted in July of 2013 was a smallscale study that focused on the organization wording and content of the library homepage and allowed us to make significant enhancements to the homepages usability without overhauling its design and layout Performing incremental user research enables the library to make small site improvements on a regular basis instead of waiting for a complete site redesign project By giving our study the precise focus of improving content labeling and organization on the homepage we made significant usability improvements to the most popular page on the library website without a major resource investment 

Simmons College mandates formal sitewide branding guidelines The library has limited control over the site design and architecture because the site is stored within a content management system shared by the entire institution There was no potential for a complete library site redesign for some time because the entire institution had recently began a campuswide website redesign project

These types of restrictions on the website are not uncommon in libraries especially when the website is under the umbrella of a larger parent organization Other libraries might find themselves restricted from using images or by the content management system settings but these are not reasons to forgo user testing Libraries can still improve usability by focusing on elements of the site that are within their control to change We decided to examine the potential for updating the content labels and organization of links on the library homepage because they were within our control

The Simmons College Library website was redesigned in 2010 by the Simmons Office of Online Communication and Design In early 2012 librarians performed significant thinkaloud usability testing with a variety of users this testing focused on the entire library sites information architecture and content organization As a result of the 2012 study we renamed pages updated the main navigation hierarchy and improved content organization While these changes were significant and did improve the site we still received feedback from patrons that due to a multitude of links and inconsistent labeling the library homepage and sidebar were cluttered and confusing For this reason we decided to focus the 2013 study on the usability of the library homepage The library homepage includes a tabbed search box which is unique to the homepage and a righthand sidebar that appears on each page of the website Fig 1 


Figure 1



For the tabbed search box we wanted to understand if the labeling and order of links should be updated Since most students access course reserves through the colleges learning management system the course reserves tab of the white box was potentially obsolete On the sidebar we researched the ordering grouping and labeling of links as well as the placement of the chat button and hours information The segments of the homepage we researched were items completely within our control to update via the campuswide content management system

The data we reviewed to inform the changes came from an inperson user research study we carried out using a paper survey instrument with large website screen captures to help illustrate the questions A small group of four library staff members constructed the survey carried out data collection and reviewed results over the course of a month The results were presented and changes were made during the following month The entire time investment was around 12 hours of staff time and 8 hours of student worker time The library spent a small amount on snacks as incentives for participation

After the most recent library website redesign we performed traditional usability testing in the summer of 2012 which focused on the information architecture of the site We received feedback that the homepage was overwhelming and unorganized as part of our usability test and from comments staff received at the reference desk Janice Redish 2012 writes in Letting Go of the Words Writing Web Content That Works If you try to give equal emphasis to all things for all people on your home page youll end up satisfying no one The library homepage was overwhelming and needed to be streamlined in order to become easier to use 

We were hesitant to take on another significant usability test but Erica Reynolds 2008 writes You shouldnt wait for an entire redesigntoimplementusabilitystudies the secretsto patroncenteredwebdesignaretotalktoyour patrons and staff members and test test test p6 And Steve Krug 2006 reminded us that user research is an iterative process and must be done on a regular basis p135 This approach of performing smaller tests on an ongoing basis would allow us to continuously improve the usability of the site

When creating this study we decided to focus on improving the labeling of links updating the organization of the sidebar quick links and reducing the amount of jargon on the library homepage We saw that we could greatly improve the usability of our library homepage by cutting out jargon that is unfamiliar to many of our users

Although reducing jargon is a smart goal for any library website determining how to replace the jargon can often be difficult and the basis for staff deliberation The research study we performed focused on collecting direct feedback from current students on their opinions of the elements of the library homepage This approach was our way of engaging in participatory design Participatory design as described in Participatory Design in Academic Libraries Methods Findings and Implementations is not limited to website testing but may be used in other areas of library service design or resource selection as well Rather than having library staff or other stakeholders determine design or content changes the users are asked directly what they prefer and expect Foster 2012 p1 This research is then used to inform the final decisions In our study we included options for users to select from rather than asking all openended questions This was to ensure participants could complete the survey quickly and easily The purpose of asking users to rank the importance of links on the homepage was so we could determine what was most important to users instead of making assumptions about user preferences This way we were able to use the information collected from users to develop clear reasoning for proposed changes to the homepage

In the study we used a paper survey supported by visual aids to collect user feedback about the content and organization of the library homepage This survey was distributed at the entrance to the library and participants were asked to fill out the survey on the spot it took about 57 minutes to complete rather than take it with them and return it later We chose to collect the survey inperson rather than online for two reasons First there are many feedback surveys distributed to the campus community via email and the community has been experiencing online survey fatigue evidenced by a decrease in participation in recent online surveys Second we had read about the positive results and ease of execution of walkup inperson user testing in recent professional literature like Adding Users to the Website Design Process by Megan Tomeo 2012 and The North Carolina State University Libraries Search Experience Usability Testing Tabbed Search Interfaces for Academic Libraries by TeagueRector Ballard  Pauley 2011 and were interested in trying this approach This method was a good fit for our library because it is not resource intensive and enabled us to collect user feedback quickly

We determined a goal of seeking feedback from at least 30 participants The staff group constructing the study examined guidelines for other inperson usability data collection methods such as card sorting for guidelines Although card sorting is a method for testing potential information architecture approaches it is similar in that it utilizes an inperson nontechnological approach to determine user preferences In his article Card Sorting How Many Users to Test Nielsen 2004 writes There is great variability in different peoples mental models and in the vocabulary they use to describe the same concepts We must collect data from a fair number of users before we candetermine how to accommodate differences among users and recommends a minimum of 15 participants but states more would improve the results correlation We doubled that minimum to 30 to ensure there would be at least 15 usable complete responses and allow for some variety in the types of participants In the end we collected 57 complete usable surveys

One weakness of the study is that we did not survey a representative sample of users Anyone entering the library when we were conducting the survey could participate The majority of students at Simmons College are graduate level As of 2013 there were approximately 1704 undergraduate students and 2325 graduate students  There are many library science graduate students at Simmons College and although we wanted them to be represented in this study we want the library website to serve all populations equitably so their opinions were not weighted differently than others However we dont see a wide discrepancy in how users describe library resources in questions asked at at the reference desk so we did not think this one weakness corrupted the overall survey results The major benefit of performing the survey in this way was that we saved a significant amount of time by not having to recruit students formally and schedule specific meeting times Because we engage in smallscale user testing on a regular basis we can construct our next method of inquiry to contain a representative sample to ensure we capture the opinions of those users that may have been missed in this survey 

Since one goal of the study was to clarify language used on the homepage we needed to ask participants about word choice Staff members who participated in the survey design determined the list of terms to include We brainstormed the most appropriate terms by reviewing smartly designed academic library websites which served similar user populations and by reviewing the most commonly used phrases that students asking reference questions used During a meeting of the survey design team we looked at academic library websites each participant suggested one or two to generate ideas for terms to evaluate A member of the team also looked through our reference desk statistics to determine the type of language students use We also referred to the article by Mark Polger 2011 Student Preferences in Library Website Vocabulary for guidance

The survey instrument consisted of visual aids with examples of potential updates to the language and order of links on the library homepage accompanied by questions about preferred language After the surveys were collected a student worker encoded the data using Excel to allow the staff committee to examine trends and to determine appropriate changes

The survey instrument was comprised of three components

	Preferred terms used on the library homepage
	Order of tabs on the homepage search box
	Order of links on the blue righthand sidebar


Section 1 Preferred Terms on Homepage

We asked participants to select which term was easiest to understand from a list of related terms Participants also wrote a short description of what they would expect to find under each choice It was important for this section to be first so that the rest of the survey questions did not bias the respondents answers 

The list of preferred terms from which to select included

	Books  Media OR Library Catalog
	Article Search OR Databases
	Library Guides OR Research Guides or Subject Guides
	EResources OR Online Resources
	Interlibrary Loan OR Information Delivery OR Materials Request


Section 2 Order of Tabs on Search Box

Participants then ranked links in order of importance from 14 with 1 as most important and 4 as least important We included a screen capture mockup of the search box on the library homepage with the tab labels removed as a reference point for the participants Fig 2 The topics included

	EResources 
	Library Guides 
	Books  Media
	 Articles



Figure 2



Section 3 Importance of Links on Sidebar

Finally participants ranked two sets of links by importance from 15 with 1 as most important and 5 as least important Participants viewed a picture of the Library website with a callout to the sidebar as a reference Fig 3 We broke the complete list of quick links into two setsone set for resources and one set for servicesalthough the participants were unaware of the designation We separated the list into two parts because it is an easier task to rank five items from most important to least important than it is to assign ranking to a greater number of items 

Resources links included

	Library Guides
	Refworks
	FullText Journals
	Library Catalog
	EResources


Services links included

	Chat with a Librarian
	Group Study Rooms
	Interlibrary Loan
	Library Hours
	Writing  Citing



Figure 3



Section 4 Open Feedback

Participants could then provide openended feedback about the library website The survey provided several prompts including

	I would like to see 
	I really love
	I can never find
	I dont understand
	Other


These prompts made it easier for participants to provide focused feedback rather than providing a single openended question at the surveys conclusion


Data Review  Outcomes

A detailoriented student worker organized the survey responses into an easytointerpret spreadsheet using Excel When examining the responses we used mode to calculate the importance of each link that participants were asked to rank Mode is useful for analyzing categorical data and allowed us to determine which value occurred most frequently in each set of responses Measures of Central Tendency 2013 For example in examining responses to questions about the tabs of the library homepage search box the label Books  Media was assigned a rank of 1 by 23 participants so according to our interpretation most respondents deemed Books  Media to be the most important tab 

Although Books  Media was deemed the most important search tab the term Library Catalog was strongly preferred over the wording Books  Media by participants The survey designers were surprised at this outcome because we assumed Books  Media would be more userfriendly which is why it was used throughout the survey when asking participants to rank links by importance Other terms the participants preferred included Article Search Research Guides Online Resources and Interlibrary Loan Fig 4   


Figure 4



When asked to rank the importance of the terms on the search box tabs from most important number 1 to least important number 4 the results were Fig 5 

	Library Catalog
	EResources
	Articles
	Library Guides 



Figure 5



When asked to rank the importance of resource sidebar links from most important number 1 to least important number 5 the results were Fig 6 

	Library Catalog 
	EResources 
	FullText Journals 
	Library Guides 
	Refworks



Figure 6



When asked to rank the importance of service sidebar links from most important number 1 to least important number 5 the results were Fig 7 

	Library Hours 
	Group Study Rooms 
	Writing  Citing 
	Interlibrary Loan 
	Chat with a Librarian



Figure 7






Other Observations

Survey respondents could discuss the library website via openended survey questions and terminology preferences Multiple survey respondents provided feedback that

	it is difficult to find a complete list of databases on the library website
	they dont understand what AZ List means
	they would like to see a list of databases organized by subject
	they dont understand what Library Guides means
	they expect the Library Catalog to be the main search option
	the Library Hours and Account Log In should be more prominent on the homepage





Recommended Improvements

The staff committee who created and carried out the survey met after the data collation and statistics were organized to review the findings The committee used a combination of the qualitative and quantitative findings from the survey to create a brief proposal that outlined recommended changes to the library homepage This proposal included mockedup illustrations of what the library homepage could look like after the changes Due to time constraints and the fact that summer classes were over there was no user testing for the mockup We wanted the changes to be in place for the fall semester and by the time the mockups were approved by library administration the summer semester had finished and there were no students on campus The majority of the changes could be made by the librarys staff CMS administrators because they were contentfocused The following changes were recommended to the librarys leadership committee

1 Update the order and simplify the list of links on the blue navigation sidebar Fig 8 The updated sidebar should include the following items in this order

	Todays Hours and a link to View Complete Hours and Access Restrictions
	Library Account Log In
	Resources
	Library Catalog
	Databases Note Although the term Article Search was preferred in the terminology section one of the repeated comments in the openended feedback was that it was difficult to find a list of Databases so the term warranted inclusion as a replacement for the link to the EResources AZ
	Journal Title Search
	Research Guides
	Refworks
	Services
	Group Study Room Reservations
	Writing  Citing
	Interlibrary Loan
	Course Reserves
	Chat with a Librarian


2 Update the white tabbed box on the homepage to better meet student research needs and usability expectations as well as to highlight appropriate library resources Fig 8 The changes to the white tabs should include the following

	Catalog  The basic catalog search box will stay the same but will be the default tab on the homepage
	Databases  This tab will contain the quick list of popular eresources and a link to the full list of eresources We found that students do not generally know the term eresources and the majority of survey respondents noted they were unable to find a list of databases We recommend using the term databases because we determined that is what users understand
	Articles  This tab will contain a search box that searches Academic Search Complete with relevant explanation text stating what kind of resource Academic Search Complete is
	Research Guides  This tab will contain links to the subject course career howto and faculty guides We found that students do not understand the term Library Guides and prefer the term Research Guides



Figure 8



3 Combine the EResources by Subject Guide and AZ List Guide into a single research guide entitled Databases Although reorganizing the database pages was not in the original scope of the research we received feedback that it was difficult to find a complete list of databases on the library website and participants also noted that they didnt understand what the AZ List was This new guide will contain dropdown menus of resources organized by subject on the first tab and resources arranged alphabetically on the other tabs Fig 9


Figure 9





Conclusion  Discussion

We made the recommended changes to the library website in August 2013 after receiving approval from library administration There were no reference questions or complaints about the changes to the library website in the first month of the changes We reviewed the Google Analytics for the library homepage and observed a decrease in the average time spent on the homepage after the changes were implemented In March 2013 before the changes the average time spent on the homepage was 457 After the updates this number dropped to 427 during March 2014 As usability is an iterative process we plan to reassess the homepage in 2014 after the debut and adoption of the new discovery platform 

The projects success is also due to the focus that we placed on the user preferences and understanding By grounding the studys survey design and proposed changes in a kind of participatory design process we were able to use concrete findings to support the changes proposed and eventually made to the site This minimized the influence library staffs opinions had on the site

We found that the paper survey is an easy and inexpensive way to collect student feedback It proved to be a great way to reach out to patrons and to find out what they are thinking about library issues and the visual aids made it easy to illustrate sections of the webpage A library doesnt need endless financial resources to conduct a survey like the one we didyou only need staff who are willing to develop and execute this kind of plan Although we did have small snack incentives for participants many users refused the incentive and were simply happy to provide feedback for free 

By focusing the study on changes we could easily make to the library homepage within the parameters of the campuswide CMS it was much easier to implement changes after the results of the study were analyzed Although it may be tempting to perform a usability test and use the results to try and convince the campus webmaster or whatever group is the gatekeeper of your site that a total redesign is needed it was much more useful to focus on attainable goals for the library homepage

The library staff at our institution is lean and we do not have any earmarked funding for usabilitytype studies Again in terms of resources and budget we looked to use what we had available so as not to place insurmountable constraints on the study The survey was completed during the summer term and staff volunteers who were interested in engaging in user research were members of the committee The snacks offered as incentives were funded from the librarys small marketing budget

Even if a library has minimal control over the design or layout of its website like at Simmons College Library there are almost always small changes that can be made to improve the user experience At our library although we dont have total control of the sites design and layout we still want to improve usability in the areas over which we do have control Although there may be limitations to the flexibility of some components of your librarys website you can use user experience research methods in order to collect feedback and transform user opinions into tangible changes that improve the website experience and ultimately the library experience

References

	Foster N F 2006 Introduction In Participatory Design in Academic Libraries Washington DC Council on Library and Information Resources 13 httpwwwclirorgpubsreportspub155pub155pdf
	Krug S 2006 Dont Make Me Think Berkley CA New Riders Measures of Central Tendency 2013 httpsstatisticslaerdcomstatisticalguidesmeasurescentraltendencymeanmodemedianphp
	Nielsen J 2004 Card Sorting How Many Users to Test httpwwwnngroupcomarticlescardsortinghowmanyuserstotest
	Polger M 2011 Student Preferences in Library Website Vocabulary Library Philosophy  Practice 6984
	Redish J 2012Letting go of the words writing web content that works second editionBooks24x7 version Available fromhttp0commonbooks24x7comlibrarysimmonsedutocaspxbookid51014
	Reynolds E 2008 The Secret to PatronCentered Web Design Cheap Easy and Powerful Usability Techniques Computers In Libraries 286 647
	TeagueRector S Ballard A  Pauley S 2011 The North Carolina State University
	Libraries Search Experience Usability Testing Tabbed Search Interfaces for Academic LibrariesJournal Of Web Librarianship52 8095
	Tidal J 2012 Creating a usercentered library homepage a case study OCLC Systems  Services 282 90100
	Tomeo M 2012 Adding Users to the Website Design ProcessPublic Services Quarterly84 350358





Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS






















































Book Review The Art of Relevance Written by Nina Simon


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










Book Review The Art of Relevance Written by Nina Simon




Review by Kristen Cardoso

MIDDLEBURY INSTITUTE OF INTERNATIONAL STUDIES AT MONTEREY



Skip other details including permanent urls DOI citation information
Volume 1 Issue 6 2017



DOI httpdxdoiorg103998weave125356420001605



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













When Nina Simon became the director of the Santa Cruz Museum of Art  History in California in 2011 the museum was on the edge of closing its doors Like many institutions the museum was faced with the question of whether or not they were relevant anymore Over her time there Simon has transformed the museum into a thriving community hub People not only come to the museum they come back again and again and they help shape what is there for other people to find Early on in her role as director Simon defined relevant experiences as those connected to the needs assets and interests of our community and to the art and history in our collection p 22 Over time she began to see relevance as a keyrelevance is the key to a locked door where meaning lives p 23 The metaphor of relevance as a key is used throughout the book and is a useful framework for libraries trying not only to improve the user experience but to create new doors to allow nonusers to enter the library and find meaning there too

In The Art of Relevance Museum 20 2016 Simon provides practical steps advice and insights into the participatory design she has implemented so successfully at her museum offering librarians a new perspective on user experience at our institutions The books many short chapters are divided into five parts What is Relevance Outside In Relevance and Community Relevance and Mission and The Heart of Relevance Each part consists of several short chapters some only two or three pages long The index of the book is equally short only indexing projects or specific organizations mentioned in the text For those looking for more detail Simon has one previous book The Participatory Museum as well as her ongoing Museum 20 blog 

In Part One Simon looks briefly at the relevance theory of cognitive scientists Deirdre Wilson and Dan Sperber and the connection between effort and positive cognitive effect Relevance theory may be a theoretical avenue worth more exploration by user experience librarians Part Two is about identifying and learning more about outsiders Outsiders are the people we want to bring into the library who either dont know that we exist or worse know that we are there but dont feel welcome This is one of the strongest parts of the book where Simon teaches us how to empathize with outsiders and help more people feel like insiders Part Three looks at understanding the needs and interests of our communities Simon outlines the museums community first program planning model p 99 which consists of four steps that are easily transferable to libraries In this part Simon also provides two case studies of libraries the Waukegan Public Library which was struggling to reach Latino adults in a community that was more than 50 percent Latino p 9091 and the Cleveland Public Library which found ways to connect with a community hit hard by the recession p 9698 Part Four looks at the effect of change on relevance and institutional missions Ultimately Simon argues that maintaining a solid core mission will help make an institution be more open to change She discusses proactive versus responsive relevance partnering with other institutions or individuals to cocreate relevance content versus form of programming and the everchallenging balance between entertaining and educating Part Five serves as the conclusion exploring the transformative power of relevant experiences on individuals and the necessity of measuring relevance and querying users and nonusers to truly be usercentered 

The Art of Relevance is not an academic text and although Simon explains in her introduction that she did not start with a single thesis but rather a set of questions she wanted to explore the book may not go indepth enough into the problem of creating relevance in cultural institutions for some readers On the other hand Simons short chapters numerous case studies from outside organizations and practical lessons learned from her museum offers high impact for low investment especially for public librarians for whom there does not yet exist much literature on user experience and those in academic libraries who do user experience on top of their regular duties Finally but no less importantly anyone suffering from the seemingly neverending charges of irrelevancy will find in this work the necessary dose of inspiration to keep experimenting and innovating with user experience in libraries






Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS


























































Start With an Hour a Week Enhancing Usability at Wayne State University Libraries


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










Start with an Hour a Week Enhancing Usability at Wayne State University Libraries




Maria Nuccilli Elliot Polak and Alex Binno

WAYNE STATE UNIVERSITY



Skip other details including permanent urls DOI citation information
Volume 1 Issue 8 2018



DOI httpdxdoiorg103998weave125356420001803



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	














Abstract


Instead of pursuing traditional testing methods Discovery and Innovation at Wayne State University Libraries settled on an alternate path to usercentered design when redesigning our library website running hourlong guerrilla usability tests each week for two semesters The team found immediate successes with this simple costeffective method of usability testing leading to similar redesign projects for other online resources Emphasizing the importance of iterative design and continuous improvement this article will detail the authors experience conducting short weekly tests suggestions for institutions looking to begin similar testing programs and lowstakes testing as a pathway to improved design for the library as a whole


In spring 2016 the Discovery and Innovation web team at Wayne State University Libraries began a redesign of our main library homepage making the first major updates to the site since 2013 After launching the initial design we wanted to improve the new website with feedback from real users following Jakob Nielsens decadesold assertion that redesigning websites based on user feedback can substantially improve usability Nielsen 1993 Instead of using remote and largescale testing options we chose a lean iterative approach and committed to two semesters of brief weekly guerrilla usability sessions with student users Not only did this method produce powerful results but its attainable iterative approach ultimately led to an increased user focus beyond the library homepage If you have an hour a week a laptop and at least one other colleague willing to help you can start usability testing guerrillastyle 

Though we found success with this method using such a strippeddown approach wasnt immediately obvious At the beginning of this project we didnt know a whole lot about conducting user testing having relied mostly on survey responses search logs and Piwik website usage data to inform our initial redesign Although we ran informal tests during the initial design process participation was limited to library staff or student workers only This feedback had been helpful early on but we suspected that testing only employees may have skewed our findings When compared to seasoned staff many users would likely not be as familiar with library resources and website structure 

The web team considered a host of research methods before embracing lean usability We considered running focus groups but discovered our budget rules prohibited us offering even small gift cards as compensation generally requisite for participation in such activities As we explored focus groups further we also realized that the amount of preparation needed to run a session would make it hard to get regular feedback on any changes we did end up making Hiring an expert to run the kind of largescale user test commonly outlined in literature or outsourcing testing to a website like UserTestingcom were other methods we eliminated We wanted a way to test users that would allow us to spend less time planning and more time testing so we could get feedback and deliver usability improvements as fast as possible The remainder of this piece will detail our experience conducting weekly tests and suggestions for institutions looking to begin similar testing programs

Go Guerrilla

We first discovered the concept of lean usability via Jeff Gothelfs 2013 book Lean UX Applying Lean Principles to Improve User Experience According to Gothelf the concept of lean UX relies on two concepts First research should be continuous meaning built into every step of the design process Second research should be collaborative meaning done by the design team not outsourced to specialists p 74 Further exploring research methods used by tech startups we found guerrilla style testing an incredibly lean doityourself process A similar method is also explored in Steve Krugs 2010 testing bible Rocket Surgery Made Easy though he never users the term guerrilla

Whatever you call it this type of research aims to identify usability issues and fix them as quickly as possible It can be successful with minimal planning minimal staffing minimal equipment and minimal time Just set up a table with devices for testing in a central location where your users are likely to be instead of recruiting representative users ahead of time for offsite testing guerrilla testers do it on the fly Once you find a willing participant you have them spend five to ten minutes completing a short series of scripted tasks while you observe and record the results Then you repeat the same test with four more participants enough to reveal most of your sites usability problems

The results arent quantitative but thats okay Informal observation like this is useful for design teams When we began our guerrilla testing process we decided to commit to an hour of testing every Thursday and soon found it to be the most productive hour of our week Krug puts it best It works because watching users makes you a better designer p 17 

Start Testing


Identify User Needs

We identified broad goals by first considering our users needs What should they be able to accomplish What type of experience should the interface offer We dug into our usage data to find the most heavilyused portions of our site This led to our initial goal to provide users intuitive access to information resources and services with minimal effort using both navigation and search Then we expanded our broad goal by exploring the details Specifically we wanted to support users in locating information about the libraries like hours and student printing policies We wanted them to be able to find and use resources like books article databases and research guides We also wanted users to be able to find help if needed These translated into measurable tasks for our initial tests such as have user locate the database Web of Science or have user contact a reference librarian

Though we first turned to our collected usage data to understand user needs we also collaborated with other library staff members during the task creation process By receiving input from circulation reference and liaison staff that regularly interacted with students we were able to test user tasks may have been overlooked Dont worry about figuring everything out at once and keep in mind that tasks are flexible The more you test the more tasks will change We generally make an informal list of areas we want to test the week before and consult it as we write the tasks


Figure 1 Turning your goals into a usable script





Devise the Script

Once youve identified user tasks its time to turn them into testable questions for your script When constructing these questions make sure to word them in a way that avoids leading the user to your desired action Rather than asking our participants to locate the 247 chat service well propose a scenario instead For example Suppose you had trouble accessing an article through a database Show us how you would get in contact with someone who could help you Because we want it to take no more than five to ten minutes we generally stick to six to eight questions per test

We also prepare a handful of scripted answers in case participants tried to ask specific questions This has been helpful because when we began testing we often found ourselves thrown off by participant questions after following a script for so long For instance in response to a question about what an interface is supposed to do well reply What do you think or explain that we can answer any questions once testing is complete If a participant seems stuck on a question we will also give them the option to move on to the next one

In our case the person who runs the test is the same person who writes the script However collaboration and feedback are still essential during this stage A day or two before our Thursday session we review our questions as a team to double check content phrasing and tone Once we approve the script one of us will type the questions into a new Google Forms document which well use for note taking during the sessions At this point its also good to script an introduction that youll read to each user who participates in your session We like to explain who we are the project were working on and the purpose of the test so the user has an understanding of the end goal You should also stress to the participant that there are no wrong answers you are testing the site not the skill of its users Its also important to encourage the participant to think out loud and express any confusion or notable impressions We keep this in our Google Forms document as well so its easy to reference during the test and each participant hears the same introduction




Run the Session

When its time to pick a location for the first test choose a place you know your users will be like near the entrance to your most visited library at a busy time Discovery and Innovation finds willing participants by setting up a table with two laptops or devicesone for testing one for recording resultsnear the entrance of our busy Undergraduate Library Weve tried other places on campus like the Student Center and the PurdyKresge graduate library without as much success The key for us was to find a place where theres a lot of traffic in and out of the library during a time of day when students may be free You want to make sure that it is a time and place that you can repeat regularly 	We run our sessions as a group of three one person recruits participants one person runs the test one person observes and records the results Once were set up for the session our recruiter approaches students with a friendly greeting asking for five to ten minutes of their time to help test a new website were working on If they seem interested our moderator explains the test further and with their permission starts the session We always offer a dish of funsize candy as an incentive but find that most volunteers are willing to help regardless Our designated observer takes notes on participant behavior using Google Forms where we have each script saved for easy access When were done with the test we make sure to thank users for their time and remind them to help themselves to a piece of candy 

After a session we have a quick web team debrief where we review the results of the test identify areas for improvement and propose solutions for bugs or design issues our users uncovered Over the next few days well make any necessary changes to the website that wed like to test reviewing them at our weekly web team meeting before our next testing session If possible dont go live with untested improvements We keep a separate test site for implementing changes so that were not changing the live site without running more tests Once our edits are live on the test site we restart the testing process to make sure our improvements are effective 

The concept of iteration has become the most important factor in our research and redesign Regular testing lets us make small changes incrementally instead of huge redesigns eliminating the risk of disorienting website users with abrupt unexpected changes One early success concerned the librarys 24hour chat reference branded as Ask A Librarian and consistently cited by staff members as an important service Though this service was accessible from the sites main navigation and a secondary Ask A Librarian page initial tests revealed that many students were unaware of its existence and also had difficulty finding it with the existing navigation If students were able to locate it they werent sure how to use it once they were there After testing several iterations of our navigation chat interface and the Ask A Librarian page we identified what worked Within a month of implementing the final changes we got word from our reference coordinator that use of the chat service was up by 70 percent This was an early measurable achievement that pushed us to continue with our testing plan 

The most major improvement weve made since redesigning the homepage involved our Millenniumbased library catalog which had gone untouched since 2006 In the spring of 2017 we began running user tests revealing several issues with the design wed had for over a decade long before any of the current web team members were hired In addition to upgrading our integrated library system to Sierra we redesigned the catalog to modernize the look added userfriendly features like citation and map tools and tweaked language to be more intuitive for users These changes wouldnt have been easy to approach as a single redesign project The small iterative changes added up over time

What makes this type of research easy to repeat is its informal approach Krug 2010 explains provided that youre still getting the answers you need theres no problem in testing fewer users altering tasks or even skipping a task if a participant is struggling and its obvious why The beauty of guerrilla usability testing is that its flexible the most important thing is that you do it early and often Some of the improvements we were able to make revealed further weaknesses within our current workflows Which brings us to our final pointthis commitment to usability starting with a mere hour of informal testing per week has had an important effect on our journey toward a librarywide culture of usability



References

	Gothelf J 2013 Lean UX Applying lean principles to improve user experience Sebastopol CA OReilly
	Nielsen J 1993 Iterative user interface design IEEE Computer 2611 3241
	Krug S 2010 Rocket surgery made easy The doityourself guide to finding and fixing usability problems Berkeley CA New Riders





Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS






















































Download EPUB file for Volume 2 Issue 1


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










Download EPUB file for Volume 2 Issue 1





Skip other details including permanent urls DOI citation information
Volume 2 Issue 1 2019



DOI httpdxdoiorg103998weave125356420002104



Creative Commons 40 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 40 International License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













Download an EPUB file of Volume 2 Issue 1






Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS






















































5 Lessons Library Websites Can Learn from Buzzfeed


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










5 Lessons Library Websites Can Learn from Buzzfeed




Christina Manzo

Boston Public Library



Skip other details including permanent urls DOI citation information
Volume 1 Issue 3 2015



DOI httpdxdoiorg103998weave125356420001302



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













Introduction

Since its 2006 launch Buzzfeed has become an Internet institution by recognizing and capitalizing on the insatiable lifecycle of viral media The idea behind the website is relatively simple bring together trending content eg news celebrity gossip entertainment quizzes from around the web and organize it into a format that is short and eyecatching

The venture capitalist firm Andreessen Horowitz estimates the net worth of Buzzfeed Inc at around 850 million And according to analytics website QuantCast the site saw 146 million visits in May 2015 alone accounting for both unique online and mobile visits For contrast the Library of Congressthe oldest federal cultural institution in the United Statesdrew in about 11 million visits in the same period

Buzzfeeds business model relies on shareability something it has in common with todays library which is why library website designers have the opportunity to learn from Buzzfeeds overwhelming success Here are the top lessons library website designers can learn from Buzzfeed

1 Formatting


What They Do

Statistically speaking if you clicked on this article you are perhaps subconsciously aware of one of Buzzfeeds most usable features its formatting For example the title for this article is exactly eight words long This is not accidental Studies report that eightword headlines have a CTR or clickthrough rate that is 21 higher than those that do not Additionally the use of an oddnumber in the headline is also statistically favorable as it increases CTR by 20

Once their statistically favorable headline is written Buzzfeedemploys the BiteSnackMeal method of information gathering to make sure that the user is not overwhelmed by content on their homepage see fig 1 Buzzfeed provides a headline the bite a thumbnail which increases CTR by 27 percent and a short colloquial description of the article the snack which is what a reader needs to make a decision about whether or not to read the article the meal


Figure 1 An example of BiteSnackMeal






How Libraries Can Use It

A library events calendar is the ideal litmus test for this method There is a large amount of information that needs to be conveyed in a very small amount of space however many times patrons experience information overload Ideally patrons will be able to skim through a large quantity of events to see what is interesting or applicable to them A good example of a library that does this well is the Salt Lake City Public Library see fig 2


Figure 2 This listing includes the bites of the short title time date and place and the snack of the short event description





2 Personas


What They Do

Buzzfeed has something for everyone because their articles are based on different personas In web design a persona is an individual with specific demographics and other characteristics Each persona is a composite of characteristics of real people in the group the persona represents Redish 2012


Figure 3 Examples of how the same website can appeal to opposite persona groups



Buzzfeed creates a large amount of personadriven content which is often contradictory as seen above however it gives the reader a more personalized experience with the website Even if the reader doesnt agree with every item on the list the personas are often general enough to ensure at least some measure of success




How Libraries Can Use It

Apart from their general utility in library web design personas are ideal for readers advisory because it groups patrons based on the books genres and authors they already like Traditionally this task has fallen to a single librarian during a reference interview but what is unique about Buzzfeeds method is that it allows for selfcategorization ie if I identify as a nerd I am likely to read an article titled 27 Books Nerds Will Love

Using personas for readers advisory is something that Buzzfeed itself is already doing For example between midMay and June of 2015 Buzzfeed has published the following readers advisorythemed listicles 23 Books All Soccer Fans Should Read 47 Books Every College Grad Should Read 9 Avengers Comics to Read Based on Your Favorite Characters 16 Perfect Books to Fill The Void Left By Mad Men 29 Books You Should Definitely Bring to the Beach This Summer and 26 Books to Inspire Your Next Epic Summer Road Trip



3 User Engagement


What They Do

Buzzfeed allows users to catalog their collection using folksonomic or freely chosen keywords by voting on their reaction to a story or list Although these keywords see fig 4 would be judged by any professional cataloger as junk tags they help involve the reader in the information gathering process and allow users to find the content they want quickly and easily 


Figure 4 These categories are colloquial enough to attract attention while maintaining some measure of effectiveness



Additionally Buzzfeed encourages users to vote on content that they later turn into articles For example todays poll on what books to read at the beach becomes tomorrows list of the 23 best summer beach reads This ensures that the key demographic sees relevant content that they might have had a hand in creating




How Libraries Can Use It

Folksonomies are surprisingly accurate In a 2015 study Manzo et al found that surveyed participantsboth librarian and laymanwere able to match professionally created metadata either exactly or extremely closely about 88 percent of the time However allowing for complete user control is not a realistic goal for many libraries Instead folksonomies should be used to supplement the professionallycreated metadata that already exists A great example of this juxtaposition occurs in the Bibliocommons catalog interface which allows usercreated lists and professional taxonomies to coexist in one easilysearchable interface

The next step for libraries that employ this type of mixed taxonomic model is to find new and innovative ways to turn this information into content exhibits and other engaging media Where Buzzfeed simply turns this usercreated data into content libraries have the potential to explore new and creative ways for users to interact with that data Great examples of this include the Chinese American Museums Origins Exhibit and the App Library at the Digital Public Library of America



4 Timeliness


What They Do

Another simple design choice that keeps Buzzfeed relevant is their chronological layout Their home page is specifically designed to show users what is buzzing at that particular moment This keeps content relevant and allows for more traffic as the website visitors see at 9 am will be different than the website at noon


Figure 5 Not only does Buzzfeeds front page rely on chronology but it also has an entire subpage devoted to whats hot now






How Libraries Can Use It

Timeliness can be a tricky subject with library websites Much of the information on a library home page must remain static for good reason eg the library location hours but by keeping the whole website static we are missing the chance to engage in a discussion with our patrons about the issues they care about

The good news is that many library catalogs are already using this feature by highlighting the books movies and other media in their collection that have been recently borrowed or reviewed The better news is that libraries have the opportunity to expand their use of this strategy to include other online content

Reference librarians are often some of the first people asked when patrons are researching a new issue or subject Many libraries already keep track of the number and types of questions asked but many libraries only evaluate said data every fiscal year or so If libraries allow for realtime data analysis librarians on the front lines can get a clearer picture of the issues that the public cares about in the moment better equipping them to answer the publics questions and to promote timely web content to preempt some of those questions



5 Shareability


What They Do

Seventyfive percent of all of Buzzfeeds traffic comes from people sharing their content on social media platforms like Facebook and Twitter Part of this is easy to account for they make it easy by incorporating direct social media plugins on every page making sharing a onestep process The more complex answer is that they have the content people inherently want to share This concept ties in to all four of the previous points Their content is shareable because it is usable interactive personalized and timely All four of these concepts are the proverbial table legs that keep Buzzfeed shareable Without the virality of the brand the whole operation would crumble


Figure 6 Buzzfeed accounts for any and all sharing options in one visually readable bar






How Libraries Can Use It

Shareability is another concept that can be difficult in terms of library content due to the fact that most of the librarys online life revolves around its physical one Because of this viewpoint many opportunities for online engagement tend to fall by the wayside There are two different solutions that can help a library engage more as an online entity one traditional and one slightly more contemporary The traditional method is to incentivize patrons to interact with the library digitally ie have them check in on Facebook for an event

The more contemporary solution is to have users interact solely with the library as a digital entity Great examples of this have been library hackathons where the public comes together over the course of a few days to design and build something like an app or fix a coding problem If you are interested in learning more about hackathons please refer to the DPLA howto guide



TLDR

Buzzfeeds business model relies on people wanting to share the sites content Libraries also rely on that model to promote the use of the media in their collections yet many times that concept is only applied to the library in a physical sense In order to make the library shareable on a digital level the content must first be usable interactive personalized and timely Currently library content often falls under the colloquial categorization of TLDR or too long didnt read common Internet shorthand for something boring To change this we need to rethink our online strategy from simply being an extension of the physical building to a separate yet related entity that allows patrons to interact with the library in innovative ways By acknowledging that there is something to be learned from the Buzzfeed business model libraries have the ability to tap in to what makes media viral and use it to their advantage




Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS






















































Great Library UX Ideas Under 100


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










Great Library UX Ideas Under 100





Skip other details including permanent urls DOI citation information
Volume 1 Issue 3 2015



DOI httpdxdoiorg103998weave125356420001304



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	














In June the LITAs Presidents Program Planning Team partnered with Weave to hold a contest for great affordable UX ideas for libraries The winner won some fabulous prizes but the committee had trouble choosing just one of the entries they received to get recognition And so we present the winner and first two runnersup for the 2015 Great Library UX Ideas Under 100


Winner Guerilla SketchAThon

From the Robert E Kennedy Library at California Polytechnic State University

	Conny Liegl Designer for Web Graphics and UX clieglcalpolyedu



As part of our efforts to redesign our website the Robert E Kennedy Library has solicited useful feedback from our users through quantitative analytics and surveys as well as qualitative usability studies and interviews But I also wanted to explore new methods for users to share their ideas

I partnered with our Student Library Advisory Council a volunteer group of students that are considered a think tank that advocates and consults the library on behalf of student needs and promotes the librarys integration of new perspectives The group puts out an annual survey with more than 800 participants and it included questions about the website The results provided information on what students consider the most important library web pages hours article search book locations and maps computer availability course reserves and printing guidelines

To further define user needs and to understand the ideal information flow for online visitors better I also designed a fun guerilla method for getting user feedback I printed 200 sketch papers and distributed them throughout the library prompting student visitors and library employees to Sketch your ideal Kennedy Library website Sketches were returned to a colored cardboard box at the checkout desk which allowed participants to return sketches anonymously if they desired As an incentive and motivation I purchased three gift cards for the library café that I raffled off to three different submitters totaling the costs of this project to 15 prints of the sketch papers were done inhouse on regular paper

One week later 20 papers with individual sketches were returned to the box 10 percent return rate all of them providing detailed insight and guidance for the website redesign Several participants stated that they had fun during the exercise

I reviewed the sketches with a librarywide committee Based on the content we decided to relabel and enlarge our search box add icons to navigation items use more colors of the university palette and declutter the marketing slider To make finding of library materials and resources easier the previous pages two search boxes were combined into one We made chat easily accessible on the main page and reorganized and restructured the massively condensed website content taking the proposed labels and information architecture into consideration




Figures 1  2 Sample sketches from the SketchaThon



Recent comparative analytics and usability studies show an overall increase in user interaction and mobile use when we compare academic years 2013 with 2015 We registered a 26 percent increase of pages per session 55 percent longer average sessions and 20 percent drop in the user bounce rate verifying the positive impact of the improved website on all users

Many students requested custom features and ways to tailor the library website to their needs a project the library web team will be working on during the summer We are planning more SketchAThons for our future web developments

First Runnerup Wayfinding in Main Library

From University of Arizona Libraries

	Rebecca Blakiston User Experience Librarian blakistoemailarizonaedu

	Shoshana Mayden Content Strategist smaydenemailarizonaedu

	Nattawan Wood Administrative Associate nattawanemailarizonaedu

	Aungelique Rodriguez Library Communications Student Assistant adr3emailarizonaedu

	Beau Smith Usability Testing Student Assistant beausmithcatworksarizonaedu



Editors note Shoshana Mayden is the copyeditor for Weave Journal of Library UX

For our visitors wayfinding in our fivestory Main Library has always been a challenge The issue comes up regularly in interviews with staff and end users and we often observe users wandering around the library with puzzled looks on their faces

In spring 2015 Rebecca led an initiative to fix this problemquickly and with minimal expense Our team did a complete audit of directional signage and discovered that directional posters and signs were mostly out of date or missing entirely Directions to study rooms were nonexistent and floor maps were only available online Aungelique and Beau conducted some wayfinding usability testing of our space which confirmed our fears finding books rooms and services in the building was next to impossible

Using these findings as guidance we implemented simple and inexpensive solutions to make things better for visitors We took down all outdated signage Aungelique created lowtech paper signs directing visitors to different call number ranges and collections and posted them in clearly visible locations on each floor This cost us only ten cents per sign Nattawan with feedback from our UX staff created a simple understandable digital floor map We put it up on the third floor by the elevators using a large monitor that wasnt in use We gathered feedback using a comment box and by conducting inperson usability testing with students asking them to locate books by call number and rooms by room number We made final changes based on our findings and then printed and posted a large floor map to replace the digital sign outside of the elevators This cost just 33 which came out of a signage budget managed by our marketing department

We also knew that other common questions visitors typically had were Where are the computers and Where do I checkout equipment We therefore created elevator directories on regular paper for ten cents a sheet We then did lightningstyle usability testing on these with students in the elevators made adjustments and finally laminated them for 3 each

When testing and feedback proved the third floor map successful we developed a process to do the same thing on the remaining four floors We now have tested laminated mounted maps on all floors This summer we are planning to do the same at our other fivestory building the ScienceEngineering Library

Followup wayfinding usability testing shows that visitors are finding it much easier to locate materials rooms and services throughout the buildings With millions of visitors through our doors each year this has a huge impact on our user experience

Second Runnerup Applying a Hierarchical Task Analysis Method to Discovery Tool Evaluation 

From Purdue University Libraries

	Tao Zhang Digital User Experience Specialist zhan1022purdueedu

	Marlen Promann Graduate Research Assistant mpromannpurdueedu



There is a large body of literature on usability tests of discovery tools in the libraries These tests focus primarily on the search interface and the testing tasks are often mismatches of users real search scenarios Understanding how well a discovery tool supports users search goals and workflows remains a challenge

In this project we conducted hierarchical task analysis HTA to evaluate how Ex Libris Primo supports eleven search cases The search cases involved different formats article print book and ebook and availability not available available in print available online and available both in print and online which present users with possible frustrations and obstacles

The HTA is a workflow centered analysis method without testing participants We two usability researchers used a desktop and a free mind mapping software XMind for our analysis hence the budget is zero if not considering the time cost

We broke the search cases into subtasks and actions allowing us to visualize the workflow and cognitive decision points All cases involved four subgoal processes

	start search
	find relevant results
	view the desired item
	retrieve locate or request the item


The first two subgoals offered nearly identical experiences across all search cases The third and fourth subgoals however presented different workflow issues depending on the item searched and its availability

Article search offered the least guidance from Primos interface and searching for an article not available in Primo involved a higher number of cognitive steps 13 than other availabilities in print 9 online 4 or both in print and online 8

For book searches it was challenging to verify the right book when there were many similar results or results in different locations The steps to place a request for a book in the interlibrary loan system Illiad from Primo were also a challenge The full task analysis cases and results are available on Purdue University Research Repository We have also published a detailed discussion of the HTA methodology Promann  Zhang 2015

Following our analysis the web team at Purdue Libraries redesigned the Primo interface by eliminating confusing information in search results and unnecessary actions For example users no longer need to click on the obscure multiple versions available link in the brief item description area to see different versions of the same book Instead they can consistently click on the book title in the search results to view the single or multiple versions It is much easier now to specify the exact publication date facet on a timeline than previously inconsistent time ranges For items that are not available the redesigned interface now displays possible search and request options like interlibrary loan UBorrow WorldCat and Google Scholar Our latest user tests showed better search workflow and improved user satisfaction with the redesigned interface

The HTA helped us identify potential workflow issues not typically found in usability tests and new user requirements that discovery tools need to support Our HTA analysis could also offer a comparable baseline and lowcost assessment for different discovery tools at other institutions

Reference

	Promann M  Zhang T 2015 Applying hierarchical task analysis method to discovery layer evaluation Information Technology and Libraries 341 77105





Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS





















































Meet Them in the Moment Engaging Public Library Patrons When It Matters Most


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










Meet Them in the Moment Engaging Public Library Patrons When It Matters Most




Deirdre Costello

EBSCO INFORMATION SERVICES

Cathleen Keyser

NOVELIST



Skip other details including permanent urls DOI citation information
Volume 1 Issue 4 2016



DOI httpdxdoiorg103998weave125356420001404



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













Introduction

In the winter and spring of 2015 EBSCOs User Research team conducted a largescale qualitative research project to learn more about how people feel and think about their public libraries as well as how they use them or dont

We found that people have strong positive associations with their public library whether or not they engage with it regularly However when people are looking for information to help them make a bigticket decision their librarys resources are not always topofmind 

We also identified patterns in the way people engage with public libraries over the course of their lives as well as how they find information about their communities inside and outside the library We believe this data has the potential help shape libraries outreach marketing and programming efforts to captivate different audiences and to make the library a topofmind resource for any information need

Takeaways

	By understanding what drives engagement public libraries may be able to tailor their marketing efforts to spark and deepen that engagement 
	People find out about whats going on in their community in all kinds of ways but word of mouth is still one of the most powerful influences whether its passed along digitally or facetoface 
	Inlibrary marketing is still the best way to tell people about whats going on at the library yes we understand the irony but even people who are in the library regularly are overlooking one invaluable resource their librarians Marketing librarians has potential to help people make personal connections to their library and deepen their engagement


Methodology

We used a version of Contextual Inquiry an ethnographic methodology that involves meeting participants where they interact with their public libraryin person or online This means that we met them not just in the physical library but where they were using public library resources We met in a lot of coffee shops


Sample

We met with twentyeight participants who varied in age geographic location employment and engagement with their public library 

We started by recruiting one to two users from each of Pew Research Centers Library Engagement Typology categories After an initial round of sessions we spoke to a group of public librarians to understand what user populations might be missing job seekers and ESL students getting resources and support from the public library and who we should recruit more of senior citizens and young parents We also sought out low and noengagement users of all ages especially those who selfidentified as readers who dont use their public libraries




Sessions

Sessions ran from one and half to two hours and started with one question Tell me about the last time you used your public library From there participants led an organic discussion about how they use the library or dont how they find out whats going on in their community and in the world and how they search for information online




Data Analysis

To analyze the large amount of data that comes from twentyeight qualitative research sessions we used Affinity Diagramming a process that allowed us to group data points based on participants underlying motivations The patterns that emerged reflected how participants want to interact with the library as well as how they want to read find information and engage with their community



Timeline

When we began to synthesize the data it didnt take long for a timeline of public library engagement to emerge fig 1 Although this timeline doesnt uncover new behaviors it does give us a basis for knowing when libraries are strong factors in peoples lives and where libraries can improve to increase the publics engagement


Figure 1 When do your patrons engage with the library And how Graphic by Suzanne Chapman




Early Childhood High Engagement

The library experience for many of us starts before we can even walk or talklet alone read The main driver of this experience is storytime Simply saying the word brought out a flood of nostalgia and fond reminiscences of family trips to the library and monstrous stacks of picture books for many of our participants Storytime is a clear driver in bringing people in the libraryand lots of people at that New York Public Librarys 67th Street Branch has 200 attendees per session during its summertime outdoor storytime The appeal of storytime is easy to see What better activity and place for parents to take their kids when it is rainingsnowingboiling hot outside Not only does this help with early literacy and kindergarten preparation but it is free which helps bring in parents at all income levels Parents can also get some social engagement as well as access to kids books 




Middle School High Engagement

We found that high engagement in the library continues through those awkward middle school years Outside of school the public library is one of the few places that tweens are typically allowed to go alone This newfound freedom and independence is very important for middleschoolers Kids get to cut the apron strings and parents get to have some freedom The library itself is also very important for ESL students It can be a safe place to go after school as well as get Englishlanguage resources 

Much of the strength of this engagement comes as a result from active work from educators and librarians One of our librarian participants mentioned how they order multiple copies of the same book in different languages so that their ESL kids can read it in both languages

Many librarians also work with local schools to form partnerships and to help fill any gaps from dwindling school budgets This can range from homework help and materials to support school curriculum to creative activities like a Minecraft club An interesting point we noticed was that even many participants who are nonusers of the library recognize the value of a tight relationship between local libraries and schools and see this as necessary in their communities 




High School Low Engagement

Independence is important and now the world is their oyster The library as a physical place to hang out has been replaced by places like coffee shops malls and other teen hangouts Beyond this many high schools also have their own libraries making the public library less of a need or destination As a result high school typically is a time where teens have very low engagement




College Low Engagement

Low user engagement continues through the college experience primarily due to a lack of need and lack of connection And why is this Meet the university library For most students the university library fills the gap Not only do these libraries have resources that directly support their studies but many of these have collections for pleasure reading and even book clubs

The university library is also near where they spend most of their time Additionally many students are also not from the community where their college or university is located and hence do not have a connection with their new citytown Many do not even know where their local public library is located let alone understand its services The college campus is their new community more than their new city or town Because of this lack of attachment many students continue without the public library


Many libraries specifically try to target this demographic with exclusivity programs like New Collection at Toronto Public Library and Young Lions at New York Public Library






Adulthood Low Engagement Unless Jumpstarted

The slump of library engagement continues after college unless it is jumpstarted by some action or need such as moving to a new community job loss or new parenthood see below Because the public library hasnt been top of mind for years many of these young users simply dont think about the public library Many participants noted that moving to a new community pushed them to seek out and use the public library Some of this came as a result of outreach efforts one participant started using the library after receiving a flyer in the mail




New Parenthood High Engagement

One major jumpstarter for library engagement is parenthood Restarting the cycle that started with storytime parenthood brings the user back into the library We found that when kids age out of storytime engagement can dip back again unless the parent makes a personal connection the library This connection could be a librarian or to one of the activities that the library facilitates like a book club

As a result some libraries are actively trying to create that connection Since many parents may not have time to pick out their own books Wake County Public Libraries has a pilot program that tries to lend parents a hand This program provides a busy parent with their own personalized bag of books that are ready to pick up at the end of storytime and are even prechecked out By anticipating the needs of new parents the library can build connections that parents may maintain as their children grow up 




Job Loss High Engagement

Although it is definitely not as happy as child rearing job loss was another jumpstarter we saw Not only do libraries provide computer and internet access but they often have resume or job resource workshops as well as online databases with career advice Aside from the actual resources a library offers its patrons sometimes the most utilized is the physical library itself Job searching can be an isolating and lonely experience and while coffee shops can be a place to turn to they generally require purchases of coffee which can add up Hello public library




Retirement High Engagement

Retirement is another time we see high engagement at the library Many seniors note that they saw retirement as an opportunity to learn and experience things they didnt get to in their careers Now with more free time seniors can take advantage of more of the resources the library provides One participant takes classes through a lifelong learning university and uses the library to help her with her coursework Another commented on utilizing the librarys travel section for trips

We also saw that many seniors use the library for help with technology Several of the public librarians we spoke with commented on how seniors make use of their librarys computer services such as training programs or onetoone tech help sessions



Marketingor How People Discover Whats Up


Im Social

Humans are social creaturesso it makes sense that we discover the majority of information that we see as relevant to us through social channels This includes social media primarily Facebook but for our participants it was just as likely to include email text and inperson interaction


Twitter vs Facebook At one library we spoke to the Marketing Librarian and Web Services Librarian work together to analyze data of all kinds including social media interactions Theyve found that Facebook is great for engaging with locals while Twitter allows them to engage in discussions about books and libraries on a national and international level



For the library this means word of mouth can be an essential form of marketing We met with several participants who serve as hubs for social information in their own communities the ones who know whats going on and provide a service by informing others formally or informally One such hub was a woman whose children were long grown and out of college but who had developed a strong personal connection with her library because of a book club she and her daughter had joined over twenty years earlier Because of this connection she is a strong advocate for her public library and is in a position to encourage others to engage more deeply as well




Im Online

For younger participants below 35 Google was the primary discovery tool for almost every kind of information When we asked how they found out about what was going on locally that might be of interest several participants demonstrated a strategy they use on a regular basis googling what to do this weekend my town

Users 35 tended to have trusted sources they turned to regularlya town events page a local news website or an email newsletter for parents in the area with listings of kidfriendly events often including library programming 




Im Traditional

We heard a lot about what might be considered more traditional news sources over the course of this study like radio often NPR and newspapers both physical and digital Interestingly these news sources were not necessarily more popular with any one age group participants from all age groups reported finding them valuable


Flyers  Mailings One participant talked to us about moving to a new community and receiving a welcome mailing from her new library including information like hours programming and how to get ebooks It jumpstarted her relationship with her new library and shes now an avid user 



The other traditionaland less expectednews source we heard about was flyers When it comes to things that come through the mail slot unrequested its easy to lump flyers in with realtors ads coupons and catalogs from companies youve never purchased anything from However participants reported finding physical mailings from community institutions like the library or an adult education center extremely valuable




Im in the Library

This one gets a gold star because inlibrary marketing is the most effective way of communicating whats going on in the library Its an obvious catch22 thoughthe people seeing inlibrary marketing are the ones that already come to the library

Participants talked about walking into the library to pick up their holds their dance cards already full and seeing something on a display table that was so tempting they couldnt help but pick it up They told us about seeing Ask Your Librarian About postersand then actually asking their librarian


Promote Books and Librarians Participants reported appreciating curated content like Staff Picks shelves and shelf talkers Libraries can use these materials to promote librarians and help people make connections with them



Which brings us to one of the most underutilized resources in the library the librarian Participants reported anxiety about bringing questions to their librarians because they perceive them as being too busy and were concerned about bothering them They werent exactly sure what their librarians were too busy doingseveral guessed taking care of the booksbut the point is they didnt perceive their librarians as available to them for help Participants who had formed a personal connection with their librarian via storytime a book club or even just sharing book recommendations at checkout were less likely to feel this way 



Conclusion 

People engage and disengage with the public library over the course of their lives Its an organic process a part of the way people relate to and invest in their communities Public libraries more than many other kinds of institutions understand those communities and work tirelessly to offer a rich array of resources to meet their needs However raising awareness about the availability of those resources is a huge obstacle and means that people truly in need may be going without something thats actually easily available to them

We hope that by sharing the ways engagement can shift over a persons life we can help public libraries overcome that obstacle by understanding how to target their efforts based on specific audiences needs as well as how to deepen existing engagements We want to encourage readers who want to know more or who are doing their own kind of experimentation to be in touch




Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS
























































The UX Moment A Weave Digital Panel Part Two


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










The UX Moment A Weave Digital Panel Part Two





Skip other details including permanent urls DOI citation information
Volume 1 Issue 3 2015



DOI httpdxdoiorg103998weave125356420001303



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	














In midJanuary 2015 Weave reached out to a number of librarians who are doing user experience work with the hope of instigating and documenting the conversation they might have with one another Coming from not only academic and public libraries but also library and information science degree programs the assembled group of professionals is doing and thinking about library user experience in a broad set of contexts and by a variety of means


The conversation that resulted reflects that broad range of experience Some librarians are working inside user experience departments where others must find a way to do UX amidst other duties duties which also vary Some work in job descriptions emphasizing web development others focus on visual design and architecture and still others work primarily as ethnographers of library users If this feature is itself a modest documenting of what library user experience can look likeat least in 2015 and in these nine different institutionsthen library user experience is itself quite a large number of things


The conversation below unfolded over email between Tuesday January 20 and Friday January 23 2015 Because of the length of the conversation and the range of topics it covers the editors have decided to run it in two segments UX


Participants

Jennifer Anderson Senior User Experience Designer New York Public Library

Rebecca Blakiston Associate Librarian User Experience University of Arizona

Heidi Steiner Burkhardt Head of Digital Services Norwich University

Georgina Cronin User Experience Librarian Cambridge University

Stephen Francoeur User Experience Librarian Baruch College City University of New York

Amanda L Goodman User Experience Librarian Darien Library

Eric Larson Web Architect and User Experience Analyst University of Minnesota

Craig MacDonald Assistant Professor and User Experience Concentration Coordinator Pratt School of Information and Library Science

Erin White Web Systems Librarian Virginia Commonwealth University

Moderators

Pete Coco Web Services Librarian Boston Public Library Weave Editor

Matthew Reidsma Web Services Librarian Grand Valley State University Weave Editor

Questions

Are libraries in a UX moment If so why right now What opportunities and hazards does such a moment present

How can libraries share stories of their UX success in a way that actually helps other libraries implement meaningful changes Weave is a great start as is the increasing popularity of UX sessions at library conferences but how can we take this further

Are you guys following the Agile methodology All our UX and web development staff went through Agile training a couple years ago and its been really helpful for organizing all the work we have on our plates


Pete Coco Weave Editor

I hope I wont stall momentum here by introducing another topic In a way the conversation is already edging in this direction anyhow



Are libraries in a UX moment If so why right now What opportunities and hazards does such a moment present


Georgina Cronin

Well speaking purely from personal experience and especially from a UK funded perspective libraries are often perceived as struggling against the all dominant nature of Google everything being free on the Internet and the usual myths that hound our profession While we know that a lot of this is simply not true it has certainly had a huge impact on the public perception of the value and relevance of libraries and their services As a result and again I am speaking a lot from personal experience librarians are being made to prove their worth While this is by no means a bad thing this worth also has to be backed up by data and fact which is where UX comes in Through indepth study and analysis of what our users want need and use we can highlight our value in ways that are far richer than simple statistics

On the flip side of this ensuring that our services are flexible adaptable and relevant to our users also requires insight so that they keep using what we offer and are finding value in that especially with the recent soar in fees in UK universities Through good UX research underpinning services and justifying the investment of time money and effort into these services we are hopefully ensuring that we are more sustainable and reactive as a profession as opposed to relying on our status as people who know stuff which unfortunately is simply not enough any more

The opportunities of this moment should be clear and Ive mentioned some of them above but the hazards are more difficult to quantify I always encourage librarians to do UX as part of their workflows as opposed to a oneoff project that never gets repeated or built upon It has to be sustainable and kept going If UX is seen as some sort of trend then it may not be given as much respect as more traditional aspects of the library professional role I really believe that UX is for everyone users and professionals alike so it is key that this moment becomes absorbed as part of a wider skill set rather than as something special and other




Amanda L Goodman

In the six years Ive been paying attention to libraries Ive only noticed an increased chatter about UX and libraries for the past two years Aaron Schmidt Amanda Etches and Nate Hill of Influx were my first introduction to any library UXers However my boss had founded our UX department in 2008 So clearly someone was talking about this

From podcasts I know that UX information architecture content strategy etc really got going in the midtolate 90s I came online in 2000 I now have 15 years of web experience Ive watched my dad drown in a sea of popups sites that were red text on black backgrounds all the way to being pleased when a websites input fields are properly set so that when I enter my zip code my phone keyboard switches to numbers This is huge However even as a semiprofessional reader of the big web designers I did not note a serious uptick in accessibility until Responsive Web Design RWD burst upon the scene Thanks Ethan Marcotte The roots of RWD as noted by Marcotte started a decade earlier but werent really heeded

Therefore from my admitted limited historical perspective I think best practices of the web have pushed UX into all other domains Other wellknown factors competition from the Internet convenient the Great Recession threatened budgets so we needed to push the public to seeing us as community hubs useful and the Americans with Disabilities Act ADA Theres quite a bit of pressure to feel ashamed if your website and building arent accessible so thats a motivating factor

Opportunities

	Better signage
	More accessible websites
	Friendlier libraries


Hazards

Oops gotta go on desk More later




Eric Larson

I think Amandas comment that best practices of the web have pushed UX into all other domains is spot on At least thats been my experience I think libraries are in a web moment with UX principles coming along for the ride Why The web has gotten better and easier People have greater expectations for their web services

At University of WisconsinMadison and here at the University of Minnesota Ive seen two large institutions substantially invest in the number and talent of their library web development teams The more web professionals you get in a room the more youll speed the adoption of best practices for accessibility usability design patterns testdriven development frontend frameworks analytics etc And finally when the team begins to write better software as an organization you quickly begin to appreciate how UX can improve and inform that work Its all very natural When the web team grows more opportunity exists to take ownership of our largest usability issues the discovery system our opensource and inhouse web applications

The opportunities are vast now Youve hired a lot of great people aboard so you decide to make the next great thing It might be a catalog it might be a data preservation tool it might be a visualization of squirrel femurs no joke hello old friends It doesnt matter The point is you have become a library with much more than just a web team You now own a software development shop and you only have so many applications you can create and maintain The hazard is how do you choose what to make and what to buy At least thats been my experience

When the web matures the web team becomes a model for AB testing success stories and datadriven decision practices Libraries are very habitual so its easy for those good habits to cross over into interlibrary loan practices and borrowing privileges Everyone wins




Amanda L Goodman


The point is you have become a library with much more than just a web team You now own a software development shop and you only have so many applications you can create and maintain The hazard is how do you choose what to make and what to buy At least thats been my experience  Eric Larson



This Thanks to my boss we have our own catalog and servers Since were located in a small town we also host community nonprofit sites and are building a closer relationship with the local public access TV station With the arrival of the sysadmin two weeks ago were pushing to act more like a startup This means a white board and standing meetings on Mondays Now if we could add a couch to go along with our mini fridge




Rebecca Blakiston

HaI like that Amandas hazard was that she had to run off to the desk Thats actually perhaps one of the hazards of our work in generalbeing pulled in many different directions and often not having clear priorities about what we should be focusing our efforts on Im pretty sure most librarians feel this way no matter what their position is

But are libraries in a UX moment I agree with what others have said UX isnt all that new but it has gained more prominence over the last few years as libraries are challenged to prove their value Libraries cant take for granted anymore that we are a requirement or a necessity We have competition now and our future as a profession is not at all clear Users can help guide our directions and sustain us over time Weve got to listen to our users to avoid becoming irrelevant

Usercentered decisionmaking allows us to improve and demonstrate our value provide exceptional services that improve student retention and success improve faculty productivity and better our communities Hazard is a bit strong of a word but some of the challenges are prioritizing and staffing to get the most impactful work done and done well




Heidi Steiner Burkhardt

I concur with the rest of the conversation so far and my brain went in a very similar direction to Rebeccas At least in academic libraries it definitely feels like as the Value of Academic Libraries initiativemovement has geared up and grown so has discussion around user experience and usercentered decision making along with the inherent assessment piece

Getting back to what Georgina mentioned about ensuring UX becomes part of workflows and not just a oneoff thing I see a potential hazard in UX becoming more of a trend than a best practiceit is definitely trendy right now




Craig MacDonald

Wow it sounds like some of you are working in really advanced and sophisticated UXwebdev teamsa great sign for the future of libraries But it also points to one of my biggest worries which is the increasing gap between the UXhaves and the UXhavenots Ive spoken to librarians who work with or lead fully staffed UX departments and do amazing things for their users but Ive also talked to librarians who are one of a handful of staff members and can only do UX work when time permits or dont have a strong relationship with their web development team and need to fight to get their voice heard or are just making up UX as they go along because they havent received formal training in the toolsmethodsetc but they know its important so they do whatever they can It reminds me of something I read a few months back about an organizational UX maturity model

To bring this back around to the discussion prompt I think this is very clearly a UX moment for libraries but in my mind the biggest hazard is and will continue to be the lack of UX expertise among a large chunk of the library profession Were trying to address this at Pratt by offering a UX concentration within our MSLIS program but I dont think it goes far enough yet and theres only so much a recently minted MSLIS graduate can accomplish

Some of you work for libraries that are clearly at the forefront and are pushing the boundaries of what UX can do for libraries but what about everyone elsethe UX Teams of None To me this leads to a critical question



How can libraries share stories of their UX success in a way that actually helps other libraries implement meaningful changes Weave is a great start as is the increasing popularity of UX sessions at library conferences but how can we take this further


Jennifer Anderson

NYPL is definitely one of the UXhaves but we werent always  I was the first person hired to what has become the Digital Experience group way back in 2007 My title has always been UX Designer which I thought was a little trendy at the time because if you dont inherently care about UX what kind of designer are you but ultimately Ive been glad its visible in my title When the group was in its infancy we struggled to get stakeholders throughout the library to understand what we were trying to do Ive found that the thing that intrigues people and makes them want to know more is something they can see and touch And it doesnt have to be a sophisticated mockup It can be paper prototyping using Postits You could take a series of photos moving the Postits around and turn it into a short video It can be anything visualso long as its a compelling illustration of the concept youre trying to express It really works

I once saw UX guru Leah Buley speak at Adaptive Paths UX Week conference and she gave a talk called A UX Team of One Since then shes written a book here it is in our catalog and here it is on Amazon and if you Google her talk you can find her website as well as a video on YouTube She talks about a lot of good ways to do much with not much




Eric Larson

True story found this classic over my lunch break


Figure 1 Library UX find




How can libraries share stories of their UX success in a way that actually helps other libraries implement meaningful changes Weave is a great start as is the increasing popularity of UX sessions at library conferences but how can we take this further Craig



We could share more of our tools

A big piece of my job is analytics Weve put a good deal of time into monitoring user activity on our homepage We systematically record web form events and link click events to inform future design decisions We capture this data using a jQuery  Google Analytics plugin I wrote

We keep the data cleansed of any identifying features usernames IP addresses etc

At the end of each month we aggregate these event data in a business intelligence database and run reports to better understand trends and patterns We can see things like which are the top used links and sections of the homepage what types of queries people perform on the library catalog versus a collectionscoped search form eg the Upper Midwest Jewish Archive We use this data to better identify what common queries cause problems in our discovery service and make changes to our relevancy rankings

This might sound beyond reach for a UX team of one or zero but even at a large university developer time is pretty scarce The more data we have to back UX recommendations the greater chance we have to see them come to fruition




Georgina Cronin

One word blogging

Through sharing techniques times when things went well and times when they didnt so much we can peer support our colleagues Im a coeditor of the UKAnthroLib blog where weve encouraged people to write up their UX studies and share their experiences with others always looking for new content by the way

Consistent sharing and communicating is key and something that we can sometimes be amazing at as a profession but also sometimes awful at it too By isolating projects away to a local level other professionals never stand a chance of learning about new options to learn new things about their users Publishing in journals is ace but it isnt for everyone and I quite like the free flow offered by blogging and documenting things in a shared space that anyone can add to




Erin White

Discussions like this and our push to move conversations into the free web rather than academic journalland have been great Weave and Michael Schofield and Amandas LibUX initiative podcast mailing list active tweeting really upped the ante for all of us and have provided somewhat of a starting point for library folk ready to get into UX

Future steps to fostering UX awareness in the profession I think its coming slowly and will gradually become a thread that weaves timely pun throughout the curriculum in library school It sure seems like UX and CXcustomer experience are peaking in the private tech sector And we are already seeing more conversation about assessment in libraryland which is a perfect complement to UX But itll take time I would love to hear others ideas




Amanda L Goodman

I think the way to increase UX awareness is just keep talking about it Make demands that libraries should do better While I loathe to bring up stereotypes we all need to work hard to get rid of the image of the nastytempered librarian I know someone who went to give a talk about creating a better user experience for staff and patrons The audience became outright hostile The barrier was a refusal to adapt and to change They preferred doing things their own way




Heidi Steiner Burkhardt

My library probably falls more or less into Craigs UX Teams of None category As I mentioned early in the conversation it is not in anyones job description hereso all work has been out of individual initiative The suggestions so far of sharing tools we create blogging and moving conversations out on to the free web are awesome but the folks who find that stuff are most likely going to be the ones actively looking for it

Obviously I do not have a solution to this but I do believe in the insideout grassroots approach which echoes what Amanda just mentioned about simply continuing to talk about it If we build consensus and inculcate a UX mentality in our organizations hopefully that eventually bleeds out into the world I also think it is good practice to start with little chunks I feel like if we can get people to bite on pieces of user experience for me it has been web writingand Rebecca was a great teacher maybe they slowly get on board with the whole shebang After my writing for the web presentation at last years Vermont Library Conference the State Librarian invited me to give it again to all of the State Library and Department of Libraries staff Win




Stephen Francoeur

Id like to build on Heidis comment about the insideout grassroots approach I just got back from a committee meeting with librarians from each of the 24 colleges in the CUNY system The committee is comprised mostly of reference librarians and is tasked with the job of making sure the look and feel of shared systems the catalog our new shared discovery system and our forthcoming IR meets with everyones approval Today we were focused on a redesign of the discovery service that goes live next week

First major thanks go to Erin for sharing her code for the redesign of Primo at her school After I saw Erins post last fall I passed it on to the CUNY central folks who manage and develop these shared services for us and was happy when they decided to reuse her design

Second as we wrestled with some relabeling we wanted to do I was pleased how quickly debates over the best label for this or that could be tabled after I announced that in my imminent usability tests for Primo that Id try to create tasks to address these thorny labeling issues I was even more pleased and a bit surprised though when a colleague at another school spoke at length about how great usability tests were in finding solutions and how her school would also be doing lots of testing this winter

At my own library Ive seen colleagues changing their tune about what they know to be best for users after theyve watched screen recordings of usability tests Its so hard for us to truly see our systems from the hapless users perspective watching a test live or as a recording can often shift dramatically the perspective of librarians about whats best Im not saying that showing screen recordings or watching live tests is going to change libraryland into UX enthusiasts overnight but it can be one of many useful ways to nudge us into a pointofview that is more empathic toward users

I think Erin is onto something when she suggests that conversations in academic libraries about assessment complement our work In a large academic library which isnt my situation I can imagine that if you had an Assessment Division it would be a good home for your UX people instead of having them in a divisionoffice that is all about systems or digital strategies or digital initiatives etc

I also would like to think that just as its preferable for an academic library not to have an information literacy librariancoordinator but instead weave information literacy responsibilities into all aspects of reference services and instructional services itd be better if UX were something that becomes baked in to the ethos of all of our services




Erin White

Wow Stephen talk about a daymaker Im happy CUNY found the customizations useful Cant wait to see how youve usedimproved on our code

This idea of UX being something that becomes baked in to the ethos of all of our services is where I see us going as a profession I dont necessarily think it should mean the end of UXfocused staffingif anything it should mean more staff

I agree we should spend time doing the work Heidi and Stephen describe using evidence to get people across the organization to think beyond as a user I and toward our users It inspires UX thinking and helps spread UX work across the organization

During our last web redesign I asked our task force yep a temporary web committee to sit in on or lead indepth interviews with individual students and faculty so we could develop personas The librarians got information that confirmed some things they already thought but also heard things that challenged their assumptions Theres nothing like seeing the light bulb go on over a colleagues head when they participate in user research After the interviews the members of the task force were really sold on the UX process and also advocated for these ideas with folks in their departments



Jennifer Anderson Are you guys following the Agile methodology All our UX and web development staff went through Agile training a couple years ago and its been really helpful for organizing all the work we have on our plates


Rebecca Blakiston

Our web team has been using an agile approach for about a year now and has morning standups 842857 am We started with Scrum but found after a couple of months that the twoweek time boxes were too restrictive and demanding in our current environment when there are always new priorities coming up and its very hard to focus on one specific thing Were now using Kanban which emphasizes justintime delivery We have a great big whiteboard that tracks progress on sticky notes Its been working really well so far to manage various project work track progress  share progress with stakeholders We also use Redmine as our ticketing system which works really well for us Where things get tricky are how to bring in design and contentmuch of the ticketing system related to development work bringing in the work that my content strategist and I do into this process hasnt really been figured out yet Were closer with the designers work but its a different type of work than the development side which is more clearly defined and clearly done Im curious what other tools and methodologies everyone is using




Amanda L Goodman

At the moment were not using any particular method Weve been swamped trying to keep up with all the demands we get as the designershardwarepublicity arm of the library I think the addition of our fourth member will change this as hell help redistribute our workload




Eric Larson

Also our team follows a Kanbanish management style Specifically we use Trello boards to track our activity on projects and department milestones




Amanda L Goodman

I can also attest to the amazing powers of Trello Ive been using it to track my work since they launched My attempts to get my colleagues on board with Trello havent worked out though

Sample boards

	Website redesign
	Work tips eg what paperwork I need to turn in at the first of each month
	To do lists
	My projects eg touch screen kiosk special web pages
	UX ideas columns Ideas Doing Done Rejected Ideas Observations





Erin White

I would love to see folks Trello boards if youre willing to share screenshots or links




Amanda L Goodman

Im attaching a screencap of a public friendly portion of my Website Redesign board


Figure 2 Darien Library Trello board






Eric Larson

For an example heres my departments academic year at a glance Trello board This board helps us think broadly about the University Libraries main initiatives color coded our larger division goals and the department work upcoming already in queue or complete

Our boards that get into the specifics of any given project are not this clean Theyre full of local jargon and discourse so no example would be easy to share and intuit They mainly follow the Kanban process of having at least three lists todo doing done plus any number of other reminder type lists

Weve had a lot of Trello adoption throughout the libraries Its great at keeping track of action items assigning them to people and setting deadlines Some committees have really become insistent about it


Figure 3 University of Minnesota Trello Board








Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS





















































Collecting Space Use Data to Improve the UX of Library Space


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










Collecting Space Use Data to Improve the UX of Library Space 




Shelley Gullikson

Carleton University Library

Kristin Meyer

Grand Valley State University Libraries



Skip other details including permanent urls DOI citation information
Volume 1 Issue 5 2016



DOI httpdxdoiorg103998weave125356420001502



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













This paper was refereed by Weaves peer reviewers

Abstract

Collecting data about where people are and what they are doing is an easy entry point into exploring the UX of library space This article examines projects at two academic libraries where space use data was collected multiple times per day for several months The two projects were designed and carried out independently but had the same purpose to better understand how students were using library spaces so that we could improve student experiencesCollecting space use data provided a baseline understanding of user behavior in these spaces Similar to web analytics this baseline can be useful on its own or used in conjunction with other forms of user research

Introduction

Librarians can better understand user behavior and subsequently improve user experience within physical library space by choosing to capture what we call space use data Space use data is simply information about how and where people are using library space The data can be very detailedspecific seats occupied conversation levels tools or materials in useor quite general such as areas labeled mostly full or half full Collecting space use data can be useful because it can answer very basic questions about how students use the physical library environment and prompt librarians to further explore why students do the things they do within our spaces This understanding can subsequently be used to improve user experience within an existing space or inform design decisions for new spaces 

Librarians can also use space use data as a baseline against which to measure the effects of changes made to physical space In this way space use data is similar to web analytics Just as its useful to conduct user research beyond web analytics Casden  Davidson 2013 improving the user experience within physical spaces will require more than space use data alone However both web analytics and space use data provide an important baseline that can both support and drive other forms of user research

This article examines separate space use data collection projects conducted at our respective libraries MacOdrum Library at Carleton University and Mary Idema Pew Library at Grand Valley State University These projects represent only one aspect of user research that weve conducted in our libraries but we consider this data collection to be a useful starting point for librarians interested in improving UX within their physical spaces The methodology is flexible and can be customized to work at any institution It can be modified to examine entire libraries or selected spaces specific time frames or longterm trends and it can be used to gain an understanding of new or existing spaces 

While we designed and carried out these projects separately the purpose of both projects was to better understand how students are using our library spaces and to use that knowledge to improve student experiences Our individual methodologies were driven by priorities that were also similar gathering data over a full semester or more minimizing disruption to students and getting our projects off the ground quickly There were also notable differences in our results demonstrating that libraries should examine how people use their own particular library spaces rather than relying on conclusions drawn from user research done at other libraries

This article details each project individually and concludes with a shared reflection Comparing the two projects sidebyside demonstrates that

	there are multiple ways to collect and apply space use data
	results can vary even among similar institutions
	collected data can be used to drive library policy and
	this work can be conducted regardless of organizational structure


Literature Review

The purpose of space use data collection is consistent with a concept prevalent in library UX literature user behavior should drive decision making Amanda Etches states that bringing user research data to bear on the decisions you make about your services spaces and interfaces elevates the discussion from one based in staff opinion to one based on the actual behavior of the people you serve your users 2013 p 14 Aaron Schmidt similarly notes that working with facts about the library and the behavior of users elevates the discussion from being a collection of peoples opinions to one thats grounded in reality Schmidt 2016 p 26

Although Etches and Schmidt advocate for studying user behavior to improve user experience within the physical library the authors of the studies that laid the framework for our projects do not explicitly situate their work within the context of UX Given and Leckie 2003 seem to have been the first to use what they call seat sweeps to gather information about use of library space where people are in the library and what they are doing They situate their work within behavioral and social geography as well as environmental psychology seeking to document and understand user behavior not to improve spaces or user experiences Ramsden 2011 and Harrop and Turpin 2013 used observational sweeps and other methods to explore academic libraries as learning spaces and the learning behaviors within them Holder and Lange 2014 looked to the fields of urban planning and architecture to contextualize their mixedmethods study of library space Khoo Rozaklis Hall and Kusunoki 2016 examined shifting paradigms of the academic library building using sweeps and surveys As UX practitioners we believe that explicitly situating space use data within UX contributes to a growing understanding and practice of UX in libraries

Most studies that have examined use of library space through these kinds of sweeps have focused on short periods of time Given and Leckie 2003 collected data three times per day over six days but only analyzed three days worthnine sweeps Holder and Lange 2014 did eleven sweeps of one space under study and ten sweeps of another Ramsden 2011 conducted many more sweepsfour times per day every weekday in Novemberbut data gathering was still limited to a single month Even studies that collected data over a longer time span covered only a small window within that time Harrop and Turpin 2013 collected data four times per day on single days in December January and March for a total of twelve sweeps Høivik 2008 did sweeps once per hour on six days spread out over seven months May to November Fox and Doshi 2013 gathered data four times per day every day for one week in 2008 and again in 2010 Clark amassed a huge amount of data over two academic years consisting of almost 40000 patron observations 2015 p 146 but his paper focuses almost exclusively on survey and focus group data The recently published study by Khoo et al 2016 gathered 114 seat counts over nine months but data was captured irregularly varying from one sweep in a month to thirtyfour sweeps We wanted a more complete picture of how our spaces were used so chose to collect data multiple times per day over several months Much as you would not want to limit your web analytics to the busiest week we saw value in both observing the rhythm of the year and in examining the highs and lows

Any discussion of space use data in libraries is not complete without mentioning North Carolina State University Libraries and their Suma project Since 2011 they have been using Suma a mobile webbased assessment toolkit for collecting and analyzing observational data about the usage of physical spaces and services North Carolina State University Libraries 2014 The team has not shared their experiences in the library literature but has given many conference presentations and perhaps more importantly has shared their code Suma is open source available on GitHub and in April 2016 their website stated there are over 100 implementations at other academic libraries However similar to our own experiences Thompson 2015 found that adapting Suma for use at her library was going to be more work than creating a new solution

It should be noted that data on space use was only one component of many of the studies cited here Holder and Lange 2014 used a survey and comment boards to solicit opinions on furniture and satisfaction with space Harrop and Turpin 2013 asked students to take part in a coordinate or photographic mapping exercise to demonstrate and explain their space preferences Clark 2015 used a survey and focus groups to determine user preferences Fox and Doshi 2013 administered a survey to ask how well the space met student needs and Khoo et al 2016 also conducted a survey on user perceptions In addition to both a survey and focus groups Ramsden 2011 had students complete learning logs take photos of favorite and least favorite spaces and complete short inperson interviews to examine the impact of space on learning behavior This kind of triangulation certainly gives a more complete picture than raw data alone going beyond what users do and attempting to discover why they do it As useful as a mixed methods approach can be starting with space use data is an easier less timeconsuming way to begin user research relating to physical library space Space use data can then generate questions to explore in subsequent user research projects

Carleton University Case Study


Background Carleton

Carleton University located in Ottawa Ontario has a single library for its student population of 28000 86 percent of which are undergraduates By the end of 2013 the library had been extensively renovated to add

	More space at the front of the building a lounge space with a variety of soft benches and carrels on the main floor and a mix of carrels and group study tables on the other floors
	A floortoceiling glass facade replacing its previous bunkertype exterior
	Two floors on a previous extension of the building one adding silent study space primarily for graduate students the other creating the Discovery Centrea flexible space with a mix of furniture to facilitate and encourage undergraduate student collaborative research The Discovery Centre is not operated by the library but through the Office of the Provost



Figure 1 New lounge space




Figure 2 New glass facade with group study space



There was interest in evaluating use of the new Discovery Centre space but a formal evaluation of library space was not planned As a web librarian I do a lot of work on the UX of our web interfaces but have no formal responsibilities regarding physical space However I felt strongly that we needed to assess the library space as well as the Discovery Centre space I spoke to our assessment librarian and to the associate university librarian responsible for the building and got their support to pursue a space use study on my own At the outset the goal of the study was to gain broad insights into how students were using our space 

Most random sampling of library space use tries to hit busy times which makes sense you dont want to spend time collecting data that show your library is not used Harrop and Turpin collected their data at peak assignment hand in dates and examination periods 2013 p 62 Ramsden collected at peak times of day 2011 p 456 However during peak times students may be sitting wherever they can find a seat not necessarily where they want to sit Nonpeak times show where students really want to be when they have their choice of space Collecting data to span both peak and nonpeak times would help us better understand the differences in use throughout the academic year




Methodology Carleton

I had planned to do seat sweeps similar to those done by Given and Leckie 2003 to find out where people were and what they were doing in the library However because of our librarys configuration I wasnt able to stand in a few spots and gather information about a large number of spaces many of our carrels are arranged in long lines with a narrow aisle separating them from the stacks so sightlines are poor see fig 3 I tried a test sweep of a section of the building with these kinds of carrels to see how much information I could capture It became readily apparent that students were unnerved by someone walking slowly down the aisle beside them making notes on a clipboard It was better when I picked up the pace and simply counted them but when I took even a small amount of time to glance at what they were doing they would notice me and look up I didnt want to break student concentration or make them feel uncomfortable Because of the limited sightlines in narrow spaces seat sweeps became head countscheckmarks in the places people were sitting


Figure 3 Narrow sightlines by single carrels



The librarys stacks staff were recruited to do the data gathering Stacks staff are responsible for shelving as well as the general wellbeing of the building and the people in it Theyre often on the floor helping students find materials answering basic questions responding to noise complaints and more My test sweeps of the whole building took about fifteen minutes Stacks staff could split up the building each covering one or two floors in about five minutes They conducted the sweeps three times per daygenerally at 10 am 230 pm and 830 pmMonday through Friday

I updated our floor plans with the furniture layout so it was easy to mark where people were For each sweep stacks staff wrote in the date and time made checkmarks where people sat and circled the marks where people were actively working together From that relatively small bit of data I could then analyze the relative popularity of renovated spaces versus older spaces silent spaces versus those that allowed quiet conversation various kinds of furniture in the library and window spaces versus interior spaces I could see where and when people were doing group work I could look at patterns over the course of the term or by time of day By using detailed floor maps if the data showed that particular seats were never used I could follow up to find out why were there problems with power outlets Drafts Excessive noise Using detailed floor maps also made it easy for the staff gathering the data to keep track of which sections had been completed The downside was that I had to keep the maps up to date when furniture was shifted


Figure 4 Sample floor plan used for data collection



This was a manual systemmarking paper floor maps with pens or pencilsand an automated system could have been more efficient But the time taken to automate would be time not gathering data The project was about getting the data not finding the best way to collect it After collection the floor map data was manually entered into Excel It was timeconsuming and awkward But instead of spending time solving my data entry and analysis problem before I could even start I could start gathering the data right now and do the data entry whenever I had a spare moment We collected data from November 1 to December 22 2014 and again from January 5 to April 17 2015 for a total of 292 sweeps




Analysis Carleton

The Excel file used for data entry was structured and colorcoded so that it looked like the floor maps Because of the way the data was collected and entered I was able to see patterns emerging early on in the project which helped me identify potentially interesting areas for analysis


Figure 5 Excel sheet matching floor plan in Figure 4



The base for my analysis was to look at how many seats were occupied and divide that by the number of seats that were available resulting in an occupancy rate If eight out of ten carrels had check marks it would be an 80 percent occupancy rate Space described as more popular had a higher occupancy rate fewer seats went unused

This was not a perfect measure in some cases people pulled up chairs from other spaces and the occupancy rate would exceed 100 percent This often happened when people took chairs from carrels to use for group work at computers The computers would then have an occupancy rate of above 100 percent while the nearby carrels would show as unused when really they were unavailable But since the computer space was obviously more desirable than the carrel space I was comfortable showing artificially low occupancy rates for carrels The point of collecting the data was not to get exact measures but rather to identify trends and gain an overall sense of how the space was used 

Another area that was problematic was when students moved soft seats from the windows into carrels so the carrel space was counted but the soft seating was not I knew this was happening because some of the stacks staff were making notes on their data collection sheets when this happened and others simply told me this was the case This lowered the occupancy rate of the soft seats by the windows but again the carrel space was clearly valued more than a soft seat with no desk space The data demonstrated that the soft seats in their original position were not popular Staff observed that students wanted a soft seat in conjunction with a carrel So combining data with staff observation the lesson was not that soft seats arent used it was that these seats need desks or tables

I created heat maps based on overall occupancy rate to get a quick visual of areas and furniture that were most and least popular with our students This showed a few things very clearly Although one area was extremely popular certain kinds of furniture in that area were never used Single carrels against the wall were very popular but single carrels in the open were not In blocks of carrels the seats right beside the wall were occupied much more often than the other carrel seats in the same block see fig 6 Seeing the data in this way led to more questions Can we fit more carrels beside existing wall space What do students like so much about sitting next to a wall Is there any way we can replicate that feeling in open spaces


Figure 6 Section of heat map showing popular carrel seats by wall






Results and Impact Carleton

Since windows were such a significant part of our renovation I looked at whether seats beside windows were more popular Surprisingly they were not Because of the known issue with soft seats beside windows I looked at the data without the soft seating and still window seats were less popular This seemed odd so I expanded the analysis to look not just at seats immediately beside windows but seats that were close to natural light as opposed to seats that were not This showed a bit more popularity but not as much as expected Did seats by walls have better access to power Not in all cases Carrels that were near windows and had power outlets were still used less than carrels beside walls As I was doing this analysis Cha and Kims 2015 article was published showing their findings that window views were less important to students choice of study space than other factors  In a survey done in my library about use of study space students commented about the desirability of space by windows In a recent meeting of our Student Library Advisory Committee most students said their favorite place in the library was beside the windows This may well be a case of people saying one thing and doing another but this rather large discrepancy between data and opinion bears closer examination 

One of the goals of the renovation was to increase collaborative study space primarily within the Discovery Centre but also with more tables for group work The vast majority of observed group work was two people working together 81 percent of all groups noted were pairs and only 6 percent had four or more people Often one or two people occupied a group table so it was unavailable for a larger group but this doesnt entirely account for the very low number of larger groups working together since sometimes there were open tables nearby that larger groups could use Sometimes a larger group will be sitting at a table but not working togetherwhat Crook and Mitchell call ambient sociality 2012 p 136 and what Medaille et al more prosaicallyand perhaps more accuratelylabeled just sitting together 2015 p 6 Group tables are not used as often as expected for collaborative group work but are clearly desired by our students

Study room use was also less than expected Group study rooms are managed through a central university portal and we have little control over this system but the library manages study rooms assigned to graduate students Library staff had noticed that the grad rooms seemed empty but thought they might be busier in the evenings Seeing the data confirm the low use of these spaces has prompted a more indepth evaluation of our graduate students needs

As the project neared its completion a new phase of library renovations was announced and new study space will be added on one of our silent floors The data from this project can be used to help plan this new space given what we now know about space use in silent areas

As the web librarian Ive found it very interesting how much this project resembles web analytics We now have a baseline for how people actually use our library study space This baseline has answered simple but important questions What kind of space are students likely to use at night in the middle of term Is an event in this area more likely to be disruptive in the afternoon or the evening The baseline also triggers other questions Would use change if we put different furniture in an area Why are people reluctant to share a round table when they will squish together at a long table against a wall Why are the window seats less popular This is exactly what happens when I look at web analytics they prompt questions about the why of our users behavior that I then use other methods to answer

Another similarity with my use of web analytics is in doublechecking the information that we get from other research methods Do those findings match up with what we have observed people actually doing When survey results show that students prefer study space near windows but our space data show that window seats are less popular than seating beside walls we know there is a bigger picture beyond what either method is showing us 



Grand Valley State University Case Study


Background Grand Valley

Grand Valley is located in Allendale Michigan and has a student population of about 25000 85 percent of which are undergraduates Grand Valley has five library locations across two campuses The largest busiest library is the newly constructed Mary Idema Pew Library Learning and Information Commons that opened in 2013 this facility primarily serves undergraduate students The space was designed to be studentcentered and flexible enough for students to manage their own learning there are few formal rules for the space signage that dictates behavior is avoided and furniture is mobile and can be easily reconfigured to meet individual needsAbout sixty mobile whiteboards are interspersed throughout the building and were designed to be used for writing and drawing but also to partition space in public areas creating what we call roomsonthefly Moving from the traditional academic library design of the highest floors designated as the quietest spaces floors two through four are similar the west side of each floor features furniture and other design elements that are conducive to collaborative group work while the east side houses book stacks furniture and spaces that are meant to be quieter and individual in nature Overall twothirds of the library was designed for collaborative work while onethird was intended for individual study

The library includes a variety of unique spaces including the following

	An Innovation Zone featuring floortoceiling whiteboards and toys meant to be used for problem solving and the expression of abstract ideas
	A Knowledge Market where students can get oneonone assistance from peer consultants in the areas of research writing and public speaking
	Two event spaces
	Two reading rooms designed for quiet study
	Public computers that are positioned on serpentineshaped desks to allow extra space for group interaction



Figure 7 Collaborative space




Figure 8 Quiet study spaces



In many ways the building design was experimental and we were curious how students would use it Would they use spaces the way they were designed to be used Was flexibility as important as we thought it was Did we get the mix of individual and collaborative spaces right Which spaces do students use most frequently Do students use spaces differently during the day than they do in the evening Are they moving furniture and whiteboards Finally and perhaps most importantlyif students are using the library differently from how it was designed to be used then can we change something to improve their experience We designed our methodology specifically to answer these questions

As the user experience librarian I have direct responsibility for understanding and improving the student experience of physical library space and lead a team of staff and students who are involved in this type of work Our UX student assistants take the lead in staffing the single service desk and their role includes roaming the library to assist patrons at the point of need and to ensure that the library is running smoothly from an operational standpointThis team of students was intentionally created to help us improve the student experience of the library their role and responsibilities help us identify pain points implement solutions and better understand the student perspective This group was excellently positioned to help us collect space use datathey were already roaming the library each hour and the very nature of their work is meant to help us better understand student needs




Methodology Grand Valley

Collecting space use data was our first UX project focused on physical space in the Mary Idema Pew Library and although we have since conducted several other user research projects regarding physical spaces this was a useful starting point When the building first opened my position was new the UX team of students was new and the library was extraordinarily busy As a result we were well into our first semester in the building when we first started to think about collecting this data While we considered utilizing Suma we decided it wouldnt work for us we wanted to start collecting the data as soon as possible and needed to choose a technical tool that could be up and running quickly and customizable onthefly Since we had limited time for prototyping we wanted to use something that would be easy to change if we discovered a way to make it better any time throughout the collection process While our digital initiatives librarian could have potentially made Suma work for us it would have taken too much time to customize and implement 

We created a simple Google form and asked our UX students to fill out the form on an iPad every day during their hourly roams during the peak and nonpeak hours of 8 am 10 am noon 2 pm 4 pm 6 pm 8 pm and 10 pm Similar to Carletons project we wanted to understand which library spaces students would use when they had their choice of seating during nonpeak times 

The Google form worked well for our original purposesit was easy to create and modify and because we were not collecting private or individual information data security was not a priority The form divided the library into zones and asked questions aimed at discovering what we wanted to know about how the building was being used The first question asked students to indicate how full each zone was While we initially designed the form to use exact numbers or headcounts here after testing the instrument we decided to instead include the following options totally full mostly full half full a few students and empty Because the library often has six hundred to nine hundred students at once in the building this decision significantly reduced the time it took our student employees to complete the form and in turn minimized disruption to student patrons Additional fields included the following

	
Conversation volume levels with scaled answer choices ranging from Low the area is mostly quiet to High It is loud in here Many noisy conversations are happening
	
Type of study with the following choices groups actively collaborating groups sitting together but working alone and individual study Our groups sitting together but working alone description is similar tothe just sitting together label used by Medaille et al 2015 p 6 For each of these choices our students would choose an approximation of how many students in the zone were engaged in this type of studyall most etc
	
Groups using the computers with yesno answer choices
	
Whiteboard Roomsonthefly with exact counts



Figure 9 Grand Valley data collection form



When UX students were trained to collect this data they were paired with another student or staff member for normalization purposes However interrater reliability was not tested In later semesters we discovered that normalization could be improved and have since worked to develop additional training components including a normalization guide The guide includes photographic depictions of each zone as well as photos of what we mean by values such as mostly full and groups actively collaborating The guide only took a few hours to develop and I would recommend creating one at the outset of data collection 

We started collecting data during the last two weeks of the fall 2013 semester and collected it through the winter 2014 semester While data was collected the majority of the scheduled times it was occasionally skipped if operational challenges arose Overall 654 observations were collected throughout this period 

Around the same time that we started collecting this data we decided that we wanted to learn more about how students were using our nineteen group study rooms that are designed to accommodate groups of three to twelve students We wanted to determine how often the rooms were being used if students were using the reservation display screens appropriately how often they were utilizing the technology available in the rooms and how many students were typically using the rooms 

We decided to create a Google formsimilar to the larger space use formthat specifically focused on study room use We employed a similar methodology and had our UX students collect this data multiple times per day on their hourly roams during hours that the space use data was not scheduled to be collected 




Analysis Grand Valley

We used Microsoft Excel to analyze data in the springsummer 2014 semester We calculated and created visual representations of fullness by zone noise level by zone overall type of study and type of study by zone


Figure 10 Grand Valley resultstype of study by zone



We were also able to break down the sound level results by peak versus nonpeak times and by time of day This analysis was important to usif no one is talking in a space that is fairly full that indicates that most students are using that zone as quiet space which is more meaningful than if no one is talking in a space that only has a few people in it Similarly the time of day analysis allowed us to get a more accurate understanding of how the library changed throughout the day We also broke down fullness levels and type of study by time of day


Figure 11 Grand Valley resultsconversation levels by time of day



Using Excel wasnt ideal With so much data and no easy way to limit the data by peak times this was an involved process This partly contributed to our decision to utilize a more sophisticated data collection instrument in subsequent semesters Our digital initiatives librarian and a student programmer constructed a dashboard that we now use for analysis The dashboard allows us to view the data much more quickly and efficiently While it wouldnt have been worth creating the dashboard for one semesters worth of data it has been extremely useful for ongoing data collection 




Results and Impact Grand Valley

Some results have led to changes in how we use certain spaces For example the data demonstrated that the third floor was the busiest floor of the library while the space outside instructional classrooms in the Atrium level was underutilized Knowing that the third floor is the busiest floor has prompted us to use this area for occasional marketing purposes and we now consciously avoid using the third floor for events and special activities that would take away space from students Data about the space outside the classrooms helped us identify that as an area that could benefit from furniture reconfiguration When we had the opportunity to try a new line of furniture we purposely chose that space to see if alternative furniture choices would improve the popularity of the space While we cannot prove causation there has been correlation since the furniture was reconfigured the data indicate that the space has been more popular

While a significant benefit of collecting space use data is identifying opportunities for improvement this data can also be used to confirm good design decisions Our data as a whole demonstrated that for the most part students used the new library the way that it was designed to be used For example the zones meant for collaboration were noisier and used by groups more frequently than the spaces meant for individual study and students frequently used the whiteboards to create roomsonthefly 

The data also made it clear that the flexibility built into our spaces was perhaps our greatest design success Library employees had observed that the library was used differently during the day than at night We could describe an increased energy in the building but could not articulate what that energy was The data confirmed that the library is indeed used differently based on time of day In particular individuals were recorded more frequently during daytime hours while groups were recorded more often in the evenings than throughout the day Likewise conversation levels were higher in collaborative areas in the evenings than they were during the day The energy that staff noticed is likely the result of more groups actively collaborating in the evening 

This difference in how the library is used throughout the day coupled with insight relating to group and individual use has made it clear that the flexibility of our spaces is very important The data indicate that students sat individually slightly more often than they sat in groups Also 60 percent of the students who sat together were actively collaborating while 40 percent of the students sat together but appeared to be working on their own These are significant results because twothirds of the library was designed to be collaborative in nature while onethird of the library was designed for individual use which may indicate that we overestimated the amount of library space needed for collaboration Because most furniture is mobile however individuals can easily modify a collaborative environment to meet their own needs they can break apart tables pull chairs from a group cluster or use mobile whiteboards to create a room onthefly Going forward student needs and behaviors could change and again the flexibility of this space would likely minimize the impact of this change 

Some of the data have raised additional questions and have helped us identify opportunities for further study For example individuals frequently sat in collaborative areas which is a trend identified in several other studies Bryant Matthews  Walton 2009 Crook  Mitchell 2012 Holder  Lange 2014 Additional inquiry could help us better understand what factors our students consider when making this choice Do some students make this choice simply because other space is not available Is it because they need large table space Do some students choose these spaces because they like to study with some noise Is it because of the brighter color scheme and plethora of natural light Ultimately this increased understanding could help us ensure that our spaces meant for individual study offer the furniture and resources that students want and need That our project data identified areas for future study reinforces our assertion that this type of data is a useful starting place for user research regarding physical library space 

We continue to collect space use data Initially we found value in the results and wanted to continue to collect the data to see if space use would change over time Eventually however we identified what I consider one of the most significant outcomes of this project displaying this data can be helpful to student patrons Digital displays throughout the library now show data on how full each library zone is which allows students to quickly identify open seating reducing a known pain point in their experience This feature has been useful to students and is an example of how our data has allowed us to both directly and indirectly improve the student experience of the physical library


Figure 12 Digital display



Finally our group study room results illustrate how this data can inform policymaking decisions Shortly after the building opened we placed signs featuring Study Room Tips for students by students on the outside of the study rooms The tips included limiting the study rooms to groups of three or more when the library is busy Library employees often observe instances of one or two people using study rooms and because the library is often busy some staff have perceived this to be problematic and have suggested tightening restrictions to actively ensure that these spaces are being used by groups of three or more Because we had collected this data we were able to determine that in the vast majority of instances when we recorded only one or two people in the study rooms there were other study rooms free at the same time When all of the study rooms were full the rooms were overwhelmingly filled with groups of at least three people The only purpose of limiting room use to three or more people is to ensure that larger groups requiring a study room have access to one If one person is using a room but there are other group study rooms available then that individual is not preventing a larger group from using a room and there is not a problem to solve In this case data helped demonstrate that what some library employees had perceived to be a problem was not actually problematic and we were able to maintain an approach that is consistent with our overarching philosophy of allowing students to manage their own learning 



Reflection on Both Projects

We pursued these projects separately although they both served as a starting point for user research relating to the physical use of our libraries We undertook these projects for similar reasons we had new or newlyrenovated libraries and wanted to better understand how our students were using these spaces and ideally use that understanding to improve student experiences Both of us were more interested in gathering space use data as soon as possible rather than waiting for a perfect methodology We also wanted to ensure that our methodologies would include minimal disruption to students studying in our spaces and we prioritized this over collecting more robust data Essentially we did not want our goal of improving future user experiences to involve methods that would negatively impact the current user experience This seems especially important when collecting data over a long timeframe 

Student employees at both libraries had job duties that included roaming the building and were already in a position to help gather the space use data without much advance planning or notice This helped us get our projects up and running quickly and we both learned a great deal from this quickanddirty approach After two terms Grand Valley was able to develop a more sophisticated data collection instrument that better balanced our requirements for easy data gathering with our needs for data analysis When or if the project at Carleton continues well take the time to automate and streamline our processes based on what we have found most useful 

Our results both show higher individual use of space and less collaborative work than we were expecting For Grand Valley this demonstrates the importance of the flexibility weve built into our spaces our students are able to modify library space to meet both individual and group study needs For Carleton this shows that despite the popularity of the new areas many of the older and more traditional spaces remain in high demand

Being able to rely on data rather than anecdotes or opinions to drive policy is a great benefit of collecting space use data It is important however to analyze that data within an institutional context The data at both our libraries showed instances where study rooms were sparsely occupied Grand Valley found that it was not problematic to have study rooms sometimes occupied by only one or two people whereas Carleton found that empty study rooms were an issue that needed to be addressed This difference reinforces the benefit to collecting and analyzing space use data at your own institution rather than relying on results from other libraries

One rather large difference has been the impact of our projects and we believe that this may be directly related to the difference in our respective positions At Grand Valley Kristin has been able to use her data to make specific changes to processes and policies Her institution has been deliberate in creating an employment model that can maximize the impact of this kind of work At Carleton Shelley has no responsibilities for space or staff and so although she has passed on her findings and has seen some impact from them she is not able to directly makeor even formally recommendchanges At first glance this may seem to be a good reason not to pursue projects like this unless you have the authority to act on your findings there is little point in gathering the data We reject this view We believe that user perception is based on their interactions with both the physical and the digital library and we should examine the holistic user experience of libraries Even if our organizations are not yet taking that holistic view those of us who are passionate about UX should be advocating for improvements to the full user experiencewhether its physical digital or some combination The first step is doing user research and we can do that without waiting for our organizations to create a specific position or structure 

Finally its important that we dont downplay our differences The goal of this kind of user research is to develop and deepen the understanding we have of our own librarys users and their needs not to create a theory of user behavior that covers all academic libraries Our two libraries have similarities in terms of student population served high percentage of undergraduates and new library spaces to support collaborative work We have differences in terms of geography mobility of furniture how studentfocused our spaces and services are how our services are offered and staffed and more How much does this context matter to how our students use our spaces We cannot possibly know until we go out and capture the data that shows what our students are doing in our spaces Its not so important that our methodologies are perfect or that our results are statistically significant What is important is that we make a choice to do this work Space use data increases our baseline understanding of user behavior we can use this baseline to improve the UX of physical space in the library and to drive new questions that other forms of user research will help us answer Something as simple as walking around noting where people are and what theyre doing can start this iterative cycle of researching and improving UX within your library

References

	Bryant J Matthews G  Walton G 2009 Academic libraries and social and learning space Journal of Library and Information Science 411 718
	Casden J  Davidson B 2013 April The Suma project Integrating observational data assessment into space and service design Presented at ACRL 2013 Cyber Zed Shed trackIndianapolis IN Retrieved from httpsspeakerdeckcombretdavidsonthesumaprojectintegratingobservationaldataassessmentintospaceandservicedesign

	Cha S H  Kim T W 2015 What matters for students use of physical library space Journal of Academic Librarianship 413 274279
	Clark J C 2015 Library as place What students value in a performing arts library Music Reference Services Quarterly 1834 139156
	Crook C  Mitchell G 2012 Ambience in social learning Student engagement with new designs for learning spaces Cambridge Journal of Education 422 121139
	Etches A 2013 Know thy users User research techniques to build empathy and improve decisionmaking Reference  User Services Quarterly 531 1317 Retrieved from httpswwwjournalsalaorgrusqarticleview28822939

	Fox R  Doshi A 2013 Longitudinal assessment of userdriven library commons spaces Evidence Based Library and Information Practice 82 8595 Retrieved from httpejournalslibraryualbertacaindexphpEBLIParticleview1954415214

	Given L  Leckie G 2003 Sweeping the library Mapping the social activity space of the public library Library  Information Science Research 254 365385
	Harrop D  Turpin B 2013 A study exploring learners informal learning space behaviors attitudes and preferences New Review of Academic Librarianship 191 5877 Retrieved from httpshurashuacuk7710

	Høivik T 2008 Count the traffic In World Library and Information Congress 74th IFLA General Conference and Council Quebec Retrieved from httparchiveiflaorgIVifla74papers107Hoivikenpdf

	Holder S  Lange J 2014 Looking and listening A mixedmethods study of space use and user satisfaction Evidence Based Library and Information Practice 93 427 Retrieved from httpsejournalslibraryualbertacaindexphpEBLIParticleview21810

	Khoo M J Rozaklis L Hall C  Kusunoki D 2016 A really nice spot Evaluating place space and technology in academic libraries College  Research Libraries 771 5170 Retrieved from httpcrlacrlorgcontent77151fullpdfhtml

	Medaille A Beisler M Radniecki T Ressel H Slater H Cooper D  Foster N F 2015 Exploring group study at the University of Nevada Reno Retrieved from httpsrithakaorgp274115

	North Carolina State University Libraries 2014 Suma Retrieved from httpswwwlibncsuedureportssuma

	Ramsden B 2011 Evaluating the impact of learning space Reference Services Review 393 451464 
	Schmidt A 2016 Datadriven design Library Journal 1416 26 Retrieved from httpljlibraryjournalcom201604opinionaaronschmidtdatadrivendesigntheuserexperiencehttpljlibraryjournalcom201604opinionaaronschmidtdatadrivendesigntheuserexperience

	Thompson S 2015 Using mobile technology to observe student study behaviors and track library space usage Journal of Access Services 1212 113





Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS





















































Ethnographish The State of the Ethnography in Libraries


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










Ethnographish The State of the Ethnography in Libraries 




Donna Lanclos 

J Murrey Atkins Library UNC Charlotte 

Andrew D Asher

Indiana University Libraries



Skip other details including permanent urls DOI citation information
Volume 1 Issue 5 2016



DOI httpdxdoiorg103998weave125356420001503



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













Ethnography has recently experienced a series of visible moments in libraries library practice and library schools While interest in ethnographicallyoriented studies began to increase in libraries by the late 1990s eg Mellon 1990 Fidel 1993 Bradley  Sutton 1993 and Julien  Duggan 2000 this visibility largely begins with a series of successful and influential studies of libraries in the mid2000s the University of Rochesters Undergraduate Research Project which began in 2004 under the guidance of Nancy Fried Foster Foster  Gibbons 2007 Foster 2013 and drew particularly on usercentered and participatory design research techniques to understand how library spaces are used how students engage with technology and how undergraduates go about their academic work the 20082009 Library Study at Fresno State Delcore et al 2009 which focused on the practices and experience of student life and students approaches to assignments the 20082010 Ethnographic Research in Illinois Academic Libraries project which studied undergraduates research processes at five Illinois universities based on firsthand accounts of how students obtained evaluated and managed information for their assignments Duke  Asher 2012 and the 20092011 Undergraduate Scholarly Habits Ethnography Project which explored the information and communication technology use of undergraduates at six colleges at the City University of New York Smale  Regalado 2014 In the wake of these studies library ethnography projects conducted by a variety of library practitioners increased dramatically see Khoo Rozaklis  Hall 2012 for a recent literature review and most recently the potential of ethnography and other qualitative approaches to library policy has been the focus of the UXLibs conference and community Priestner  Borg 2016 

As professional anthropologists we have each been engaged in fulltime work as library ethnographers at our respective institutions at UNC Charlotte since 2009 Lanclos and at Indiana University since 2013 Asher What is striking to us within these positions is the lack of concurrent support that this visible moment of ethnography in libraries has had in the form of fulltime employment for ethnographers or embedded ethnography expertise in teams across the library staff particularly in contrast with increasing numbers of assessment and user experience oriented positions see Triumph  Beile 2015 Passonneau  Erickson 2014 In this article we explore some of the reasons why we think libraries are stuck in a relatively unfinished ethnographic moment one more accurately characterized as ethnographish Ethnography can serve as an effective antidote for the problematic reliance in higher education including libraries on analytics and quantitative measures of effectiveness We offer ethnography as a way not only to engage with users but also to tell the story of that engagement as a form of evidence of success

We want to explore briefly what the barriers might be to more widespread and deeply practiced adoption of ethnographic approaches and suggest reasons why it is important to persist in trying to expand their reach In particular we argue that constructing longterm views of student behavior gained via ethnography is good and necessary practice for effective engaged and innovative libraries and indeed education generally Remaining at a stage that is primarily concerned with shortterm data collection and utilizing prepackaged offtheshelf methods or that alludes to ethnographic methods without fully engaging with or trusting them does not allow for the transformative moment made possible via fully engaged ethnography wherein libraries can actually be thought about and experienced differently not just rearranged

Ethnographic vs Ethnographish

We define ethnography as the art and science of describing a group or culture see Fetterman 1998 p 1 Ethnography is a collection of qualitative methods that focus on the close observation of social practices and interactions that deeply examine the context in which activities occur Asher  Miller 2011 p 3 Ethnographic research involves the interpretation of the meanings metaphors and symbols of the social world Asher  Miller 2011 p 2 and its data is typically composed of unstructured observations texts images or audio and video materials as well as physical artifacts which the researcher uses to create an interpretive understanding of social and cultural processes In this way ethnographic methods are excellent for elucidating rich descriptions of peoples experiences as well as for answering why and how questions about social and cultural processes and practices While there are many approaches to conducting ethnography almost all ethnographers agree that it involves detailed study and longterm engagement with a research site typically at least a year or more which provides a basis for analytical and interpretive authority for deriving theories and conclusions Stocking 1992 pp 55591

The work in libraries that has been labeled ethnographic often drifts from this tradition into what we describe as ethnographish This work is distinct from ethnography in a few ways but often these projects are shortterm and narrowly contextualized whereas ethnography projects have openended timelines and aim to understand the full context of the subjects lives Moreover ethnography projects do not always produce definitive outcomes Shortterm projects done in libraries and isolated from other contexts can borrow ethnographic methods and still not be ethnography 

This distinction is important because some of the potential of ethnography is not achievable if we only do ethnographish work Few librarians are able to devote a year or more to a single study Ethnographish projects can also focus on the methodology as a means of gathering more data but without necessarily taking on the larger perspective on insight and meaning that is inherent in particular to anthropological approaches to ethnography 

Ethnographish projects in libraries often repeat or closely replicate those done at other locations This is a failure to leverage anthropological perspectives around ethnology that is recognizing that the comparative approach can reveal patterns of common practice as well as unique situations The importance of ethnology emerges as does ethnography from the field of anthropology rooted in the conviction that comparative work not just deeply descriptive work is crucial to building understanding Both ethnology and ethnography are necessary for effective analysishow can we know that a problem is unique if we have never tried to see where else this might occur or how else it might look How can we talk about gender constructs for example if we only observe and describe them in one culture How can we talk about student work if we only observe it in our university How would we reimagine libraries and librarianship in the absence of comparative data

The critical comparative approach that anthropologists call ethnology helps not just to triangulate sorting the unique from the widespread and the structural from the individual but can also help libraries realize they are not alone that there are solutions and suggestions to be gathered from the experiences of other institutions For example the Ethnographic Research in Illinois Academic Libraries Project was explicitly designed with the ethnological intention of comparing students academic experiences across five universities Asher Miller  Green 2012 Project Information Literacy while not an ethnographic project per se engages from a North American context in a comparative analysis of lifelong learning practices starting with the student experience Ethnography plus ethnology yields networked and collective data such that insights can be then be considered critiqued added to refined and acted upon by a larger group The resource crunch that means many small libraries dont have the staff to dedicate to fulltime ethnographers doesnt mean that they cannot from a policy perspective draw on ethnographic insights to inform change It does mean that they have to be capable via a comparative perspective of recognizing the potential of those insights to be valid whether it was done with their particular student body or not

Ethnographish projects have yielded real insights into student and faculty behavior They have led to policy discussions around the configuration of library space and the deployment of digital tools and places such as institutional repositories and websites They have in many cases led to better libraries What they have not led to is widespread dedication of fulltime staff hours to ethnographic data collection and analysis or an overall decrease in reliance on quantitative methods of data collection They have not led to a different way of seeing Wolcott 1999 one generated by ethnography as a theoretical perspective more than a cluster of methods

Seeing Like a Library Seeing like a University

Fulltime ethnographers dont really exist in libraries Even those of us with training as ethnographers do not devote all of our working time to ethnographyanthropologists in industry rarely do either Fulltime ethnography would be totally dedicated to exploratory fieldwork grounded analysis attention to emerging themes and far less programmed around problems and how to fix them This would be a massive amount of time and energy devoted to openended processes that are not a great fit for the ways libraries and many other institutions currently operate In this sense we have not really achieved ethnography in libraries yet



Ethnographic practices in libraries have never been given the time or resources to be ethnography in the longterm sense Generally ethnographic work in libraries is represented by shortterm projects done by outside contractors While this approach can seed methods unless the work is taken up by staff whose primary or at least secondary responsibility it is to follow through and continue the work is unlikely to achieve the longterm deeply observed insight that is possible with ethnography This should not be seen however as an indictment of ethnographic approaches but rather about the limitations of using such an approach to try to learn new things and revise previous impressions when the project team is only active for three four or six months at a time How can longterm insight be gained if the work is not tied to a larger more broad institutional agenda not just carved out of the work of individuals with a particular affinity for the work independent of their job description

So while it is clear that libraries are providing a series of limited scope ethnographic projects and results that are certainly better than nothing we appear stuck in this ethnographish moment and unable to move fully into embracing openended ethnography Some answers to why this is the case might be found in the structure of libraries and additionally in the priorities of libraries particularly around problem solving and assessment When libraries have ethnography or UX teams they tend to be asked to focus on shortterm projects and can also be reluctant to share their results outside of their organization Preater 2016 Shortterm projects also tend to have finite and concrete goalsfor example they can result in a tutorial or a completed article reporting on the results of the project for example Building an understanding of users through longterm ethnography research yields a different less swift and containable kind of payoff that can be difficult to argue for among cashstrapped resultsoriented libraries and library directors The perception that ethnography is not just timeconsuming but difficult to do can be a barrier to adoption UX work has more examples of lowinvestment highyield projects eg Duke Libraries approach to UX This may be part of the reason for the appeal of UX qualitative work and why fulltime people are being hired to do UX work in libraries UX is often focused more on applied problem solving than ethnography

We frequently hear from librarians in response to the question Why arent libraries doing more ethnography variants of We dont have the training to do that kind of work Such a response reflects a gap in library school research methods training and also ignores that collaboration with people who do have this training is a legitimate way forward The fact is that people get training in these methods by doing the workethnographers often say the only way to learn ethnography is by doing ethnography and this is reflected in methods courses in anthropology graduate schools that are practicefocused rather than finely structured methods training When people who work in libraries stop working in isolation and dont pin all of their preparation on their professional credentialing experiences more can get done

Another response to questions about the lack of longterm projects is We dont have the full time staff for this kind of work This is the no time for that argument that actually reflects that this kind of work isnt a priority not necessarily that theres no time or staff for it

Libraries like the rest of higher education rely more and more on the kind of student data provided by learning management and enrollment systems Big Student Data the vendoroffered promises of learning analytics including predictive analytics and increasingly marketcentered language around higher education are rising in an environment where legislative bodies suspicious of the work of education and higher education in particular are asking for metrics of particular kinds of success and value But such quantifications tell us very little about the lived experience of being a student or a researcher or an instructor who participates in the academic processes of a university If our systems cant respond to what our users are actually trying to do or the realities of their daytoday lives it matters little how much better we make them if the underlying disconnects are not identified and addressed

A great deal of time and effort in library assessment is devoted to attempting to measure things that at least appear to be readily quantifiable Libraries routinely track and report figures for collection holdings circulation reference and instructional transactions gate counts electronic usage measured by downloads page views etc and expenditures These proxies for engagement tell us very little about actual user behavior and experience For example a circulation or usage number tells us almost nothing about why a resource is needed how its used and what its impact is on a student or researchers work Similarly there is a heavy reliance on quantitative methods such as surveys done by outside companies to measure things like satisfaction such as LibQual behaviors such as ITHAKA or skills such as SAILS This can be either because libraries dont have resources to do their own locallysourced assessment or because libraries comfort with these methods and procedures appear to make the complex organization of a library more rational even though they reveal very little about the meanings of their findings or why they occur and can even obfuscate understanding real daytoday practices Nevertheless the overarching perception around assessment in libraries is that quantitative work gives effective occasionally easy benchmarks and is generally a way to measure success and satisfaction

Libraries and Risk 

Libraries are notoriously risk averse This default conservative approach is made worse by anxiety and defensiveness around the role of libraries and pressures to demonstrate value Within this larger context where the value of libraries is already under question openended exploratory ethnographic work can feel risky Engaging in ethnography when its not well understood isnt something many libraries feel they can do given the wider context of anxiety and defensiveness around the role of libraries

Much of the explanatory power of ethnography is devised from empirically building evidence over time This often entails longterm projects or projects that dont have a hard stop at all Interpretations can be revised updated changed as more information is gathered more context becomes clear and larger patterns of behavior are revealed to illuminate some of the specific things visible in library spaces Ethnographic approaches build a body of evidence gradually over time enabling questions to be addressed that often were unknown when the research was begun and the exploratory nature of ethnography often means that its benefits are sometimes realized years in the future once a critical mass of observations can be synthesized Embarking on research with unknown outcomes is understandably uncomfortable but it is incumbent on leadership to work to provide the space for risks to be taken or even better for exploration and notknowing to no longer be framed as risky but as constructive and necessary because the yield from ethnographygenerated insights can be great We would argue that it is in fact higher risk to forgo these types of insights

Ethnography doesnt offer the possibility of giving a way to measure a librarys value directly but it does give a way whereby the library can enact and engage with its own values Drabinski  Walter 2016 and those of higher education Undertaking this approach reveals connections meaning and patterns and can become an integrated part of how the library becomes and remains valuable because it has insight into student and faculty behavior that does not exist elsewhere on campus

What if an ethnographic approach fails We would suggest that anything interpretive is risky in the sense that interpretations can be wrong Moreover we should also ask this question of any method including quantitative methods which routinely fail by providing nonactionable or nonsignificant results In the case of quantitative work the failure tends to be hidden by the success involved in producing a number of measurement however meaningless But when data is collected where there arent resources to change time and energy are wasted

It might also be useful to ask what does failure mean in this context Is the goal to simply have something measurable to report Or to generate information that allows discussion of meanings motivations and yes values

We are arguing therefore for ethnography as praxis as a transformative practice emerging from particular theoretical perspectives that value emergent insights over simply identification and fixing problems Providing a space for ethnography in libraries has profound implications for the nature of libraries for definitions of work and practice for imagining the connections that libraries have within their larger contexts for holistic considerations of student and faculty experiences actions and priorities Examples of this approach to ethnography outside of academic or activist anthropology can be found in the practices of the community of anthropologists organizing themselves within EPIC Ethnography Praxis in Industry Conference Moving beyond ethnographish into ethnography requires shifting thought away from it as a method and towards a mindset This is once again Harry Wolcotts definition of ethnography as a way of seeing 1999

Practices for Libraries and Ethnography

What would we two anthropologists like to see

We are calling here for more collective action on the part of libraries rather than the fragmented landscape we see now How can we make the transition from finite problemsolving ethnographish and UX projects to openended ethnography that allows for acquiring an intuition based on the grounded experience of extended research This is not just about the notion of cumulative expertise but of using the evidence you collect to inform change and transform library policy and practice Can we get libraries to pay for that expertise How does that job description become part of the larger work of the library Should we in fact be advocating that some of the new hires that libraries get to do be social scientists devoted full time to exploratory ethnography

Its more likely that your library isnt going to hire a fulltime ethnographer or indeed be able to hire anyone new at all So perhaps what we should advocate for would be making increasingly visible not just the kind of workflows that are involved in ethnographic practices but the very broad potential of them rooted in the longterm amorphous processes of ethnography to go beyond finite problemsolving 

How do we build a collective and collaborative ethnographic praxis that doesnt duplicate work unnecessarily What would get us unstuck from this ethnographish moment into one that contains more ethnography

We would like here to encourage a series of actions Firstly alongside the shortterm problem identifying and fixing leave space for longterm less directed more broadlybased contextual investigations that can yield a holistic picture of context into which the more specific projects can be situated Generate a space for true ethnography for longterm ongoing exploratory work 

Second learn the lesson of ethnology embrace a comparative approach More and mindful attention to the longterm work being done by other institutions and backing away from special snowflake assumptions can allow libraries without fulltime ethnographers on staff that is almost all of them to still benefit from the insights of this work in their own contexts This in turn requires cultivating a trust in qualitative methods so that they dont have to be replicated at your institution and so that they are perceived as actionable 

Our third recommendation is collaboration Work in partnership with colleagues at your institution or elsewhere who do have this experience and training in ethnography Partnering with colleagues in other academic departments using student research projects as a way to expand the methodological and theoretical approaches to library spaces policies and librarianship can make this wider range of perspectives possible even if this expertise is not currently within your library In addition conferences such as UXLibs weave together a community of practice around ethnography exposing newcomers to the approach as well as allowing more seasoned practitioners to share what does and doesnt work and to collect their insights together This open transparent practice and focus on collaboration is a useful model to turn to and to proliferate 

Finally we would point to the crucial role of leadership not just topdown but from the middle of library organizations outward Bryant 2016 to provide and protect a space for the insights gained via ethnography to be valued as much as if not more than quantitativelygathered data Encouraging engagement with conferences and networks that showcase encourage and dive deeper into ethnography and ethnographic approaches as well as facilitating and supporting wideranging conversations about practice and potential across institutions at all levels have to be central strategies to making ethnography fundamental to libraries and their ways of seeing

Ethnography should not be engaged in simply as a method that gives us more buckets of data to be sorted visualized and put into a report Ethnography should be core to the business of the library As praxis practice informed by theory and ideology it has the potential to transform libraries librarianship and indeed higher education

References

	Asher A D  Miller S 2011 So you want to do anthropology in your library Or a practical guide to ethnographic research in academic libraries Retrieved from httpwwwerialprojectorgpublicationstoolkit

	Asher A D Miller S  Green D 2012 Ethnographic research in Illinois academic libraries The ERIAL project In L M Duke  A Asher Eds College libraries and student culture What we now know pp 114 Chicago American Library Association 
	Bradley J and Sutton B 1993 Reframing the paradigm debate The Library Quarterly634 405410  
	Bryant P 2016 From the middle out making pedagogical change happen in a complex messy world Web log post Retrieved from httppeterbryantsmegradiocomp600

	Delcore H Mullooly J Scroggins M Arnold K Franco E  Gaspar J 2009 The library study at Fresno State Retrieved from httpfresnostateedusocialsciencesanthropologydocumentsipaTheLibraryStudyDelcoreMulloolyScrogginspdf

	Drabinski E  Walter S 2016 Asking questions that matter editorial College and Research Libraries 773 264268
	Duke L M  Asher A D Eds 2012 College libraries and student culture What we now know Chicago American Library Association
	Fetterman D M 1998 Ethnography Stepbystep Thousand Oaks CA SAGE Publications
	Fidel R 1993 Qualitative methods in information retrieval research Library and Information Science Research 153 219247
	Foster N F 2013 Studying students A second look Chicago American Library Association
	Foster NF  Gibbons S Eds 2007 Studying students The undergraduate research project at the University of Rochester Chicago Association of College and Research Libraries httphdlhandlenet18027520

	Julien H  Duggan L 2000 A longitudinal analysis of the information needs and uses literature Library  Information Science Research223 291309 httpdoiorg101016S0740818899000572

	Khoo M Rozaklis L  Hall C 2012 A survey of the use of ethnographic methods in the study of libraries and library users Library  Information Science Research342 8291
	 Mellon C A 1990 Naturalistic inquiry for library science Methods and applications for research evaluation and teaching New York Greenwood Press
	Passonneau S  Erickson S 2014 Core competencies for assessment in libraries A review and analysis of job postings Library Leadership  Management284 119 httpsjournalstdlorgllmindexphpllmarticleview7080

	Preater A 2016 Why dont libraries share the results of UX Work Web log post Retrieved from httpswwwpreatercom20160611whydontlibrariessharetheresultsofuxwork

	Priestner A  Borg M Eds 2016 User experience in libraries Applying ethnography and humancentered design New York Routledge
	Smale M A  Regalado M 2014 Commuter students using technology EDUCAUSE Review Online Retrieved from httpwwweducauseedueroarticlecommuterstudentsusingtechnology

	Stocking G W 1992 The ethnographers magic and other essays in the history of anthropology Madison University of Wisconsin Press
	Triumph T  Beile P 2015 The trending academic library job market An analysis of library position announcements from 2011 with comparisons to 1996 and 1988 College  Research Libraries766 71639 httpdoiorg105860crl766716

	Wolcott H F 1999 Ethnography A way of seeing Walnut Creek CA Altamira Press


Notes



	 For a detailed historical account of the development of ethnographic conventions and the fieldwork tradition in anthropology see Stocking 1992 pp 159






Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS




















































Meaningfully Judging Performance in Terms of User Experience


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










Meaningfully Judging Performance in Terms of User Experience



Michael Schofield 


Skip other details including permanent urls DOI citation information
Volume 1 Issue 4 2016



DOI httpdxdoiorg103998weave125356420001403



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













Much about user experience design is concerned with subjective improvements to language and structure style tone The bulk of our quantitative data is used toward these purposesand of course being usercentric is precisely what that data is for The role of the user experience designer connotes a ton about the sorts of improvements at the surface of our websites at the obvious touchpoints between patron and library Unfortunately this approach can neglect deep systemic or technical pain points to which design is wrongfully oblivious but which are fundamental to good user experience 

Speed is a major example Website performance is crucial enough that when it is poor the potential for even the best designs to convert is diminished The most usable website can have no effect if it fails to load when and in the way users expect it to

One thing we can be thankful for when improving the performance of a website is that while more speed definitely has a strong impact on the user experience it is also easy to measure Look feel and the oomph of meaningful quality content navigability usability each have their own quantitative metrics like conversion or bounce rate time watched and so on But at best these aspects of the web design are objectiveish the numbers hint at a possible truth but these measurements only weather scrutiny when derived from real very human users 

 

A fast site wont make up for other serious usability concerns but since simple performance optimization doesnt necessarily require any actual users it lends itself to projects constrained by time or budget or those otherwise lacking the human resources needed to observe usage gather feedback and iterate The ideal cycle of tweak test rinse and repeat is in some cases not possible Few user experience projects return as much bang for the buck as site optimization and it can be baked into the design and development process early and with knownnot guessedat nor situationalresults 

When it comes to site optimization there are no shortage of signals to watch There is a glut of data right in the browser about the number of bytes in script or style file size network status codes dropshadow rendering frames per second and so on Tim Kadlec author of Implementing Responsive Design broke a lot of these down in terms of meaningful measurements in a series of articles throughout the last couple of years oriented around the performance budget 


A performance budget is just what it sounds like you set a budget on your page and do not allow the page to exceed that This may be a specific load time but it is usually an easier conversation to have when you break the budget down into the number of requests or size of the page 



Such a strategy really took root in the perfmatters movement spurred by folks repulsed by just how fast the web was getting slower Their observation was that because the responsive web was becoming increasingly capable and high pixel density screens were the new norm developers making cool stuff sent larger and larger file sizes through the pipes While by definition responsive websites can scale for any screen they were becoming cumbersome herkyjerky mothras for which data was beginning to show negative impacts 

In his talk in 2013 Breaking the 1000ms Time to Glass Mobile Barrier and later his book High Performance Browser NetworkingIlya Grigorik demonstrated users reactions to even millisecondslong delays

	Delay	User Reaction
	0  100ms	Instant
	100  300ms	Feels sluggish
	300  1000ms	Machine is working 
	1s 	Mental context switch
	10s 	Ill come back later 


Since then the average page weight has grown 134 percent 186 percent since 2010 Poor performance is such a drag on what might otherwise be a positive user experienceencapsulated by a July 2015 article in The Verge The Mobile Web Sucksthat the biggest players in the web game Facebook and Google have dramatically reacted by either enforcing design restrictions on the SEOsensitive developer or removing the devs influence entirely 


Figure 1 Comparison of average bytes per content type in November 2010 left and November 2015 right



Selfimposed performance budgets are increasingly considered best practice andas mentionedthere are different ways to measure its success In his writeup on the subject Tim Kadlec identifies four major categories 

	Milestone timings
	Rule based metrics
	Quantity based metrics
	Speed index


Milestone Timings

A milestone in this context is a number like the time in seconds until the browser reaches the load event for the main document or for instance the time until the page is visually complete Milestones are easy to track but there are arguments against their usefulness Pat Meenan writes in the WebPagetest documentation that a milestone isnt a very good indicator of the actual enduser experience


As pages grow and load a lot of content that is not visible to the user or off the screen below the fold the time to reach the load event is extended even if the uservisible content has longsince rendered Milestones are all fundamentally flawed in that they measure a single point and do not convey the actual user experience 



Rule Based and Quantity Based Metrics

Rule based metrics check a page or site against an existing checklist with a tool like YSlow or Google PageSpeed to grade your site Quantity based metrics on the other hand include a lot of the data as reported by outlets like the HTTP Archive These include total number of requests overall page weight and even the size of the CSS file Not all these metrics indicate poor performance but they are useful for conceptualizing the makeup of a page and where efforts at optimization can be targeted If the bulk of the page weight is chalkedup to heavy image use then perhaps there are imagespecific techniques you can use for steppingup the pace


Figure 2 Example of a library web page graded by YSlow



Speed Index

Speed Index is set apart by its attempts to measure the experience there is an algorithm to which Pat Meenan referred by determining how much abovethefold content is visually complete over time then assigning a score This is not a timing metric but Meenan explains 


the area above the curve calculated in ms and using 0010 for the range of visually complete The calculation looks at each 01s interval and calculates IntervalScore  Interval   10  Completeness100 where Completeness is the percent visually complete for that frame and Interval is the elapsed time for that video frame in ms The overall score is just a sum of the individual intervals




Figure 3 View of a web page loading over time in milliseconds



Basically the faster the website loads above the fold the faster the user can start to interact with the content A low score is better which is read as milliseconds A score of 1000 roughly means that a user can start to use the website after just one second So if other metrics measure the Time To Load TTL then Speed Index measures Time To Interact TTI which may be a more meaningful signal

TTI encapsulates an important observation even by quantitativedata nerds that web performance is just as much tied to the psychology of time and the perception of speed as it is by the speed of the network If we look at page speed as a period of waiting then how the user waits plays a role in how that wait is experienced As Denys Mishunov writes in an article about Why Performance Matters the wait is either active or passive  


The period in which the user has no choice or control over the waiting time such as standing in line or waiting for a loved one who is late for the date is called a passive phase or passive wait People tend to estimate passive waiting as a longer period of time than active even if the time intervals are objectively equal 



For example during my recent involvement with an academic library homepage redesign our intention was that it would serve as thin a buffer as possible between the students or faculty and their research This not only involved bringing search tools and content from deeper in the website to the forefront but also reducing any barrier or ugh factor when engaging with themsuch as time Speed Index has a usercentric bias in that its measurement approximates the time the user can interact withthus experiencethe site And it is for this reason we adopted it as a focal metric for our redesign project 


Figure 4 Example report from Google PageSpeed



How to Measure Speed Index with WebPagetest

Google develops and supports WebPagetest the online opensource web performance diagnostic tool at WebPagetestorg which uses virtual machines to simulate websites loading on various devices and with various browsers throttling the network to demonstrate load times over slower or faster connections and much more Its convenience and ease of use makes it an attractive tool Generating a report requires neither browser extensions nor prior experience with inbrowser developer tools WebPagetest like alternatives incorporates rulebased grading and quantity metrics but it was also the first to introduce Speed Index which can be measured by telling it to Capture Video


Figure 5 Screenshot of WebPagetest interface



WebPagetest returns a straightforward report card summarizing the performance results of its tests including a table of milestones alongside speed indices The tool provides results for First View and Repeat View which demonstrates the role of the browser cache These tests are remarkably thorough in other ways as well including screen captures videos waterfall charts content breakdowns and optimization checklists 


Figure 6 WebPagetest report card



Its worth noting that these kinds of diagnostics can be run by other tools on either end of development Google PageSpeed Insights can be generated in the same way type a URL and run the report But folks can also install PageSpeeds Apache and Nginx modules to optimize pages automatically or otherwise integrate PageSpeedor YSlowinto the buildprocess with grunt tasks The bottom line is that these kinds of performance diagnostics can be run wherever it is most convenient at different depths whether you prefer to approach it as a developer or not They can be as integrated or used expostfacto as needed

Keep in Mind The Order in which Elements Load Matters

Of course the users experience of load times is not only about how long it takes any interactive elements of the page to load but how long it takes certain elements to load Radwares recent report Speed vs Fluency in Website Loading What Drives User Engagement shows that simply loading a page faster doesnt necessarily improve users emotional response to the page They outfitted participants with neuroimaging systems and eyetrackers mounted on monitors in an attempt to objectively measure things like cognitive load and motivation In the study the same web page was loaded using three different techniques

	the original unaltered loading sequence
	the fastest option where the techniques used provided the most demonstrably fast load times regardless of rendering sequence
	a version where the parts of the page most important to what the user wanted to accomplish were loaded first



Figure 7 Results of Radwares study on how users process web pages during rendering



In six out of ten pages the sequence in which elements loaded based off their importance toward a primary user task affected overall user engagement measured by total fixation time



While not overwhelming the results suggest that depending on the type of website rendering sequence can play an important role on the emotional and cognitive response and at which order users will look at different items Radware makes no suggestions about which rendering sequences work for which websites 

Still the idea that cherrypicking the order in which things load on the page might decrease cognitive load especially on an academic library homepage where the primary user task is search is intriguing 

The Bottom Line Earmark a Performance Budget

There are all sorts of improvements that can be made to library websites that add value to the user experience Prioritizing between these involves any number of considerations But while it may take a little extra care to optimize performance its worth the time for one simple reason your users expect your site to load the moment they want it This sets the tone for the entire experience




Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS



















































Anticipatory Design Improving Search UX using Query Analysis and Machine Cues


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










Anticipatory Design Improving Search UX using Query Analysis and Machine Cues




Jason A Clark

MONTANA STATE UNIVERSITY



Skip other details including permanent urls DOI citation information
Volume 1 Issue 4 2016



DOI httpdxdoiorg103998weave125356420001402



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













This paper was refereed by Weaves peer reviewers

Abstract


This article looks at how inferred and contextual aspects of a search query can offer new ways of thinking about the search results page Data mining for user context requires using techniques to understand the intentions behind search queries and the physicalnetwork locations of our users By applying the residual machine cues inherent to the search act and using semantic query analysis we can improve user experience to anticipate user needs and introduce personal context This is anticipatory design in practice In the article I define the components of anticipatory design consider the privacy implications of anticipatory systems examine how our search interfaces as a primary interaction model lend themselves to anticipatory design and look at how inferred and contextual cues can be brought into a search prototype to improve the search user experience 


Introduction


Our evolution into a searching culture requires a fundamental shift in how we think about the user experience well beyond simply accommodating search engine optimization

Vanessa Fox Former Product Manager Google Search Console Fox 2012



When Larry Page and Sergey Brin engineered the backrub algorithm and the concept of an index of web pages Page et al 1999 they couldnt have known how the act of searching would become the dominant model for interacting with the web In the short time since the search engines invention we have become a searching culture People search to check facts learn concepts get directions find other people decide on what to eat learn how to cook what they want to eat etc This interaction pattern is a primary means of navigation for the twentyfirst century 

For libraries and cultural institutions our evolution into a searching culture brings with it a number of opportunities including rethinking the user experience of search To date library discovery systems have focused on search and retrieval around explicit queries and matching string patterns They can and have matched on these explicit strings to much success Take for example a typical search interaction a user searches for Yellowstone National Park and a set of results is returned based on that string pattern match coupled with relevancy and occurrences of that pattern of words as measured against the complete search index For every query matches are chosen by comparing items in the index to the defined literal words of the query We can keep doing this in library search as we have for the past few decades But there is another possibility here if we turn toward a more nuanced semantic interpretation of search queries1 Speech acts are made up not only of the words being usedthe messagebut also the context Search interactions can also be viewed this way where the message is the search query but the context for the search is largely ignored Consider this simple formula and example of the search act

	search query  literal aspect  inferred aspect
	yellowstone national park
search query		yellowstone national park
literal aspect		iPhone user on MT highway
tacit inferred aspect



I believe that the most interesting work involving the future of search is going to revolve around figuring out how to use the inferred aspects of searching not just the literal search to enhance and improve the search act for users2 

Within libraries and cultural heritage institutions our interest in being like Google has focused more on the unified set of results that Google queries allow but search and search result pages are evolving into something else entirely Search is a calorie counter Search is a person directory It is the home page of the web Once we start to unpack the contextual bits and pieces around a search act or a query there are all kinds of possibilities for enhancing discovery and our search user interfaces


Figure 1 Google user interface inviting natural language question Calories in cranberry sauce




Figure 2 Google search engine results page showing images contact information latest news Wikipedia data etc



Studies are starting to confirm this idea of search as a students or a researchers home page A 2010 study of higher education website usage reported on the findings of an environmental scan showing that 


Search engines continue to dominate topping the list of electronic sources most used to find online content 93 percent followed closely by Wikipedia 88 percent The key difference in usage between search engines and Wikipedia is the frequency75 percent of students who use search engines do so daily compared to 20 percent of those who use Wikipedia OCLC 2011 p 523



In a more recent study from Ithaka SR Roger Schonfeld 2015 writes about how researchers expectations are being set by consumer internet services and that our library discovery services account for a relatively minor share of searchdriven discovery and do not provide even a substantial minority of content accesses to major content platforms In contrast he writes Google and Google Scholar are comparatively important discovery starting points Each provides not only search but also various types of anticipatory discovery including reading recommendations and keyword author and citation alerts Schonfeld 2015 By focusing on the contextual bits and pieces around a search act we might improve our users experience of the library website Khodabandelou Hug Deneckere and Salinesi 2013 came up with the term intention data mining when speaking of the goals as one interprets these contextual bits and pieces of a search query Intention mining is a useful frame for the activity we will conduct as we work through how to apply anticipatory design to our search interfaces4

Given our searching culture and expectations I will look at a series of research questions and possibilities for library search interactions in this article First I will establish the history of anticipatory design and how it has and will shape our library search interfaces Second Ill take a practical look at an implementation of anticipatory design principles that use intention mining in a generic library search prototype And finally I will look at the implications of this anticipatory model in relation to privacy and utility in hopes of understanding where we can introduce value to library search interactions and how tolerant our users are in accepting enhancements that depend on inference and knowledge of their contextual patterns and behavior

Literature Review

Since search has become the primary interaction pattern on the web understanding what a typical search act entails is the first step in thinking about how to improve on search design In the terms of the search act we have a system that allows a query interprets the query and then returns potential answers Within this systems model one can imagine a role where anticipating the needs of the searcher is possible But before integrating anticipatory design into this model we need to know exactly what anticipatory design is In his coining of the term Aaron Shapiro 2015 calls anticipatory design design that is one step ahead of you Shapiro moves on to offer a more detailed definition 


Anticipatory design is fundamentally different decisions are made and executed on behalf of the user The goal is not to help the user make a decision but to create an ecosystem where a decision is never madeit happens automatically and without user input The design goal becomes one where we eliminate as many steps as possible and find ways to use data prior behaviors and business logic to have things happen automatically or as close to automatic as we can get Shapiro 2015



Shapiro coined the term for the web age but there are previous studies in the computer science philosophy information science and interaction design literature which discuss anticipation and the prediction of future actions as essential and inherent components of systems design Loet Leydesdorff 2004 emphasizes that In order to generate and process meaning a communication system has to entertain a model of itself A system which contains a model of itself can function in an anticipatory mode Leydesdorffs formulation is a later version of what Robert Rosen the natural scientist and pioneer systems design theorist introduced in his Anticipatory Systems noting that anticipatory behavior is one in which a change of state in the present occurs as a function of some predicted future state and that the agency through which the prediction is made must be in the broadest sense a model 1985 p 8 At any given moment a systems model built with anticipatory design principles is speculating about user needs and attempting to fill in the blanks correctly

Given these ideas of speculation and prediction anticipatory design is not without its critics Many have pointed to how the model could lead to less empathy for the mental models of our users A number of researchers Dubois 1998 Jansen et al 2008 Kruschwitz et al 2013 Zamenopoulos  Alexiou 2007 note that when we enter into modes of prediction we introduce constraints to understanding And these constraints have led to some Busch 2015 Sene 2013 calling anticipatory design practice presumptive design Others have moved beyond the presumptive label to look at the challenges to privacy inherent to anticipatory and predictive systems design In her consideration of the limits of personalization Maria Andersen 2014 suggests that anticipatory design practice has similarities to the uncanny valley of human robotics in seeming to cross the line into familiarity that machines cant be expected to have She discusses the ways that personalization can become invasive and notes that for personalization to be accepted widely it is necessary to find ways where users trust the designs and accept the added value personalization affords without feelings that a system knows too much about them In writing about Search 20 and commercial search engines Michael Zimmer traces the implications of these systems that know too much


In their quest for Search 20 web search engines have gained the ability to track capture and aggregate a wealth of personal information stemming from the increased flow of personal information made available by growing use and reliance on Web 20based applications The full effects and consequences of the emerging Search 20 infrastructure are difficult to predict but potentially include the exercise of disciplinary power against users the panoptic sorting of users and the general invisibility and inescapability of Search 20s impact on users online activities Zimmer 2008



In her reflection on Shapiros foundational essay Anne Quito 2015 points out that anticipatory design presents new ethical checkpoints for designers and programmers behind the automation as well as for consumers Can we trust a system to safeguard our personal data from hackers and marketersor does privacy become a moot concern In libraries and cultural institutions privacy is never a moot concern but there is some potential middle ground here Michael Schofield 2015 alludes to a form of anticipatory design that might meet the privacy requirements of libraries while maintaining or establishing user trust when he writes about The lowfat flavor of anticipatory design without the personaldata part in which context inferred from device or browser information is usually optin by default and this would do most of the heavy lifting In the next section well take a closer look at these middle ground methods that dont require the ability to track capture and aggregate a wealth of personal information Zimmer 2008 to discern context and user intention

Anticipatory Design Using Query Analysis and Machine Cues

In his account of the rise of Google John Battelle 2006 introduces the concept of a database of intentions to analyze the role that search engines play as the collectors of humanitys curiosity exploration and expressed desires Battelle is speaking about the search terms that we use and how these terms are recorded analyzed and then mined for insights by Google The analysis of intention that Battelle mentions is where we can start to apply anticipatory design to our search systems There is an evidentiary residue to the search act and our analysis of this residue allows us to introduce predictions context and relevance into the search interaction Even a simple anonymous recording of search terms can add value as I noted in an earlier article for the Code4Lib Journal on making patron data work harder in applying user search query terms as browsable access points within a search system Clark 2008 Interpretation and anticipation of contextual user data enables even more potential improvements within a search user interface such as

	Watching for semantic cues within search queries to suggestshow facets related to generic questions about library collections and services
	Determining device of access to establish the need for more directional or locational facets
	Using global variables to establish client IP and presearch location identity to show a facet that invites a user to run a local search query based on their physical location
	Determining the day of the week using global variables to suggestshow facets around featured services for the day and hours for the day
	Determining time of day using global variables to suggestshow facets that might feature relevant library news or specials matching the times


In this section well unpack some specific methods for determining the inferred aspects of the search act or a query that can allow us to improve search UX


Cues from within the Literal String

Words within a string can give us a clue as to intent Appendix 1 includes an example list of words that might indicate a natural language questiontype query Think of the five Ws and One H of journalistic inquirywho what where when why howand how one could use the intentional semantics of these words to monitor whether a question is being asked within a search query The next step would be to build recognition with code for this type of query and watch for the pattern match on these words5 In terms of the search user interface if a match is made a different facet is presented to the user This new facet might be focused on knowledgebase factual andor FAQ content As you can see the goal here is recognizing context6 In this case the context is derived from intention mining search query cue words to discern if a person is asking a question or searching based on a traditional keyword string In the context of a realworld example imagine someone typed weather in bozeman into a search box Figure 3 shows an example of the type of information that could appear in a result facet if weather was picked out of that explicit search string as a query requiring a contextual answer 


Figure 3 Possible weather display facet based on pattern match of weather in search query



Appendix 2 shows how one might make this facet appear using two different code samples Intent pattern matching gives us a few options to display contextual information but there are additional cues from the act of calling and loading a web page that we can use 




Cues from the Machine

A missing piece in our methods so far has been a lack of trying to understand context or intention in time and space There are lots of means to try to pick up these cues One of the first places to start is with the HTTP headers found inside of a web browser request when a link is clicked and a page is returned Figure 4 shows screenshot of a search interface with HTTP header data and various global system information showing for demonstration purposes7  


Figure 4 Screenshot of desktop view of search interface with HTTP header and global system variables showing



These HTTP headers8 and related system information provide bits of data that we can use to infer context Just consider for a moment what I can glean from the above HTTP header information

	Useragentdevice
	Useragentoperating system
	Web browser
	Web browser rendering engine
	Language
	Previous sites visited inside the cookie information


More specifically here are some inferences from the HTTP header above

	Desktop
	Mac OS X 1075
	Google Chrome Web Browser
	AppleWebKit Browser Rendering Engine
	English
	Google


One can also use certain serverside variables to pull out additional information So in addition to the Headers information we have information that includes

	Page URL
	Referring URL
	Client IP address
	Timestamp


And even further we can find a number of pieces of information using clientside JavaScript as a page is rendered in a web browser Among the information that we can mine from a page loaded into the browser using the native JavaScript windownavigator or Date methods

	Screen heightwidthcolor depth
	Platform and operating system
	A list of installed browser plugins
	Time zone
	Whether a user allows cookies or tracking


With all of these pieces on the page and available as variables to a programming script we can start to think about some enhancements we might bring into a search interface 


Figure 5 Screenshot of search interface with HTTP header and GLOBAL system variables showing from mobile device view



Some of the immediate enhancements might include

	Using the timestamp to determine day of week and showing a note about research assistance hours or library hours for that day
	Using the timestamp to determine time of day and if it is around 8 am or 2 pm suggest stopping by the cafe for a coffee
	Using user agent to infer device and ask if refinement around facts of place would be helpful
	Using the IP address to do a preliminary lookup about geolocation
	Applying the geolocation to check local weather and then suggest an action based on that data point For example Hey it is sunny out Stop by the cafe for a lemonade
	Coupling the geolocation data point and the seasonal data point to suggest additional reading For example Its summertime and the living is easy Here are this summers best beach or camping reads 
	Using the referring URL value to provide a set of search suggestions for a returning internal or new user


Take for example if we find a match within the user agent value on ipod or iphone If this match occurs we could introduce a location facet or a streamlined user interface designed for a tablet or smartphone All of these enhancements are just based on the useragent device and operating system See Appendix 3 for an example of PHP code that would build those enhancements We can also perform a preliminary scoping on the location using the client IP address There are many services that can do an IP address to location lookup9 By passing the IP address to an API like this

httpwwwtelizecomgeoip153901705callbackgetgeoip

httpfreegeoipnetjson153901705 

You can get a returned set of structured data as JSON see fig 6 


Figure 6 Screenshot of JSONLint view of values returned from Telize API



Using a number of the returned values city line 9 or the longitude line 2 and latitude line 3 we can now suggest a new facet within the search user interface Imagine an invitation in the sidebar that asks Hey it looks like you are in Somewhere USA Do you want to filter these results based on your location10 



Applying Anticipatory Design to the Search Experience

In the interest of bringing all of these possibilities into focus Im going to work through how a live search prototype uses these semantic and machine cues in applying anticipatory design principles to improve the user experience The anticipatory search prototype11 works best when applied to generic largescale search settings such as unified discovery systems a library catalog a library or university website search etc But there is no reason that with the properly designed facets or refinements that the anticipatory design model couldnt work within even a smaller digital library collection search The anticipatory design implementation is compelling because when I speak of search experience I am talking about any time a user could have a Did you mean anticipatory design treatment At times it is a conversation and a mediation moment with similarities to the reference interview As we mentioned earlier the model for a search interaction is fairly simple someone asks a question query and a system tries to provide a series of answers search results In this section well try to illustrate how anticipation can be applied to these interactions and systems

The first design goal is providing a clean and intuitive interface that communicates the primary action The prototype borrows from the design conventions of commercial search engine interfaces in showing a single search box with a call to action fig 7


Figure 7 Screenshot of the inert search interface



After query initiation we start to see the potential benefits of anticipatory design models with the introduction of facets and filters to draw out the intention behind the query fig 8


Figure 8 Screenshot of initial facets for a standard query



The goal is to show only necessary facets until the user has selected and communicated a more complex informational need which requires an additional refinement And there are other anticipatory nuances of the prototype that arent part of Figure 8 For example smaller query set results  30 have a smaller number of facets that appear fig 11 actually shows this limited number of facets based on a   30 query set result The reasoning is that if a users query is already refined enough to produce a smaller set of results it is not necessary to add complex facets and additional browse points The system has been successful Conversely a larger query set  30 might indicate ambiguity in searcher intent or a broad query so extra facets appear to aid in refining and specifying the query Building on the idea of only introducing complexity when a user requires or asks for it note how the facets remain closed fig 8 until a user interaction opens the information into view fig 9 


Figure 9 Screenshot of initial facets for a standard query with facet open



And there are still other ways to build anticipation into the system design model As we noted in the previous section watching for intentional cues like natural language questions in the query itself can lead to a different set of facets focused on facilitation moments such as connecting with a librarian or being able to look at the organizational FAQ knowledgebase to see if a similar question has been answered Figure 10 demonstrates how a natural language question query makes a question facet appear along with an invitation to talk to a librarian


Figure 10 Screenshot of initial facets for a conversational query



Even further we can look to introduce local context by situating and locating our user within a certain time and place fig 11 


Figure 11 Screenshot of facet noting time in semester and pushing a library browse collection



This facet brings an offer to search the library browsing collection based on recognition of where we are in the semester calendar but there are all kinds of possibilities here Depending on time in the semester we could look to surface writing help or citation and research services Depending on time of day we could push hours or an event that is happening later tonight On a lighter note we can even offer a cup of coffee at the library cafe based on the current weather The prototype is an exercise in building a dialogue with a user and trying to realize anticipatory design possibilities

Future for Anticipatory Design

I would argue that anticipatory design within our interfaces and spaces has a strong future In the context of search its future may be the brightest Any time we have a routine pattern of interaction such as search there is an opportunity to streamline and introduce new patterns of use or modes of access and discovery A challenge for us will be learning where these enhancements truly add value for our users Even more importantly the challenge will be in understanding how privacy and the rights of individuals can be preserved in the face of predictive anticipatory systems You can see this question playing out in the earlier literature review when authors were pointing to the uncanny valley Andersen 2015 or presumptive design Busch 2015 Sene 2013or even the rhetorical question asking if we can trust the system Quito 2015 These questions about privacy are essential to ask And they might be even more important for us to solve if we are to compete and participate in the searching culture of our time12 In many ways this is the crux of this research and the reason to continue to try to understand anticipatory design in the library context It is a huge question and one that can involve our whole organization public services librarians with expertise in search and learning behaviors developers and designers looking to provide recommendation systems instructional librarians and staff who are planning learning spaces in anticipation of use even library administrators asking for systems and spaces that inscribe and encode library values such as privacy and helpful intermediation With a nod toward these broader implications of the anticipatory design model the next steps for this search UX project will be more extensive user testing and analysis with very specific goals First we are interested in observational and taskbased testing to see how searchers work through our system Findings here will be applied to refine and finalize the search interaction model that we have Second there is a need to understand the intentions and attitudes of our users more clearly We are looking to conduct user interviews and live walkthroughs of the anticipatory search interface to determine users attitudes related to predictive systems and where anticipation crosses the line into feelings of surveillance And finally well look to analyze our search query logs to understand what are the most common queries and when natural language queries are appearing with the goal of applying this data to provide an even smarter interface

Conclusion

Search and discovery remain a core service of libraries We are working in many ways to make sure our indexed data is discoverable and we can continue to refine our search UX for our local search interfaces In this article I have presented a way forward by introducing the idea and process behind enhancements of context and location within our search interfaces Mining these contextual bits and pieces requires our using data techniques that look to understand the intent of search queries and the physical and network locations of our users As we have noted this practice does creep into issues of privacy for our users but it is a practice that if done responsibly will lead to our next possibilities for searchinferred context and search as landing page There are efforts to use this information for good Libraries and cultural institutions can take heed of projects such as Am I Unique where browser fingerprinting is applied as a point of education To move forward into systems that can apply predictive analytics recommendation facets and text mining we need to figure out how to use this information responsibly and win the confidence of our users The additional path forward is to gather this data transparently communicating our goals and framing it as an improved service for our users as they work through our library systems

References

	Andersen M H 2014 The invasive valley of personalization Retrieved from httpbusynessgirlcomtheinvasivevalleyofpersonalizatio

	Anthony T 2013 From keywords to contexts The new query model Retrieved from httpsmozcomblogfromkeywordstocontextsthenewquerymodel

	Battelle J 2006 The search How Google and its rivals rewrote the rules of business and transformed our culture New York Portfolio
	Busch L 2015 What you need to know about anticipatory design Retrieved from httpwwwsmashingmagazinecom201509anticipatorydesign

	Clark J A 2008 Making patron data work harder User search terms as access points Code4Lib Journal 3 Retrieved from httpjournalcode4liborgarticles78

	Dubois D M 1998 Computing anticipatory systems with incursion and hyperincursion AIP Conference Proceedings 437 330 
	Fox V 2012 Moving beyond the SEO silo Integrating search with user experience for better audience acquisition and engagement Retrieved from httpwwworeillycompube2179

	Jansen B J Booth D L  Spink A 2008 Determining the informational navigational and transactional intent of web queries Information Processing  Management 443 12511266 Retrieved from httpswwwresearchgatenetprofileJimJansenpublication222824696Determiningthe
InformationalNavigationalandTransactionalIntentofWebQuerieslinks02e7e51f8ad2a3e54c000000pdf

	Khodabandelou G Hug C Deneckere R  Salinesi C 2013 Supervised intentional process models discovery using hidden markov models In R Weiringa S Nurcan C Rolland  J L Cavarero Eds Seventh International Conference on Research Challenges in Information Science pp 111 Paris IEEE Retrieved from httpshalparis1archivesouvertesfrfileindexdocid803875filenameRCISV26pdf

	Kruschwitz U Lungley D Albakour M D  Song D 2013 Deriving query suggestions for site search Journal of the American Society for Information Science and Technology 6410 19751994 Retrieved from httprepositoryessexacuk72481kruschwitzjasist2012preprintpdf

	Leydesdorff L 2004 Meaning anticipation and codification in functionally differentiated systems of communication Luhmann SimulatedComputer Simulations to the Theory of Social Systems Retrieved from httpwwwleydesdorffnetluhmannsimulated

	OCLC 2011 Perceptions of libraries 2010 Context and community Retrieved from httpwwwoclcorgcontentdamoclcreports2010perceptions2010perceptionsallsinglepagepdf

	Page L Brin S Motwani R  Winograd T 1999 The PageRank citation ranking Bringing order to the web Retrieved from Stanford InfoLab website httpilpubsstanfordedu80904221199966pdf

	Quito A 2015 The next design trend is one that eliminates all choices Retrieved from httpqzcom429929thenextdesigntrendisonethateliminatesallchoices

	Rosen R 1985 Anticipatory systems Philosophical mathematical and methodological foundations Oxford Pergamon
	Schofield M 2015 Does the best library web design eliminate choice Retrieved from httplibuxcobestlibrarywebdesigneliminatechoice

	Schonfeld R C 2015 Meeting researchers where they start streamlining access to scholarly resources Retrieved from httpsrithakaorgp241038

	Sene P 2013 Beyond responsive design discover Context First Retrieved from httpwwwcreativebloqcomwebdesignbeyondresponsivedesigndiscovercontextdrivendesign8134226

	Shapiro A 2015 The next big thing in design Less choice Retrieved from    httpwwwfastcodesigncom3045039thenextbigthingindesignfewerchoices

	Zamenopoulos T  Alexiou K 2007 Towards an anticipatory view of design Design Studies 284 411436 Retrieved from httpwwwidaliusedivisionshcsixsmaterialDesResMeth09Theoryanticipationpdf

	Zimmer M 2008 The externalities of Search 20 The emerging privacy threats when the drive for the perfect search engine meets Web 20 First Monday 133 httpdxdoiorg105210fmv13i32136



Appendix 1 List of natural language question pattern words in a programming array

cueWords  array about above across after afterwards again against all almost alone became because become becomes becoming been before beforehand behind being below beside besides between beyond by call can cannot cant could couldnt cry describe do either except few fill find found from front full further get give go had has hasnt have how however hundred if in indeed interest into is keep might mine more moreover most mostly move much must my myself name never nevertheless nor not nothing now nowhere of off often on once one only onto or other others otherwise our ours ourselves out over own part per perhaps please put rather see seem seemed seeming seems should show side since so some somehow someone something sometime sometimes somewhere still such system take temp temperature than that the their them themselves then thence there thereafter thereby therefore therein thereupon these they this those though three through throughout thru thus to together too top toward towards under until up upon us very time were weather what whatever when whence whenever where whereafter whereas whereby wherein whereupon wherever whether which while whither who whoever whole whom whose why will with within without would yet you your yours yourself yourselves

Appendix 2 PHP and Python code to process the natural language question pattern words in a search query

We can use an if conditional operator code expression for this logic using the cueWords array we defined above would look like 

 PHP example
query  weather in bozeman
qToken  strtokquery 
if inarraystrtolowerqToken cueWords 
    echo Current Conditions 


OR 

 python example
cueWords  about above   weather 
query  weather in bozeman
querylower
if query in cueWords
    print Current Conditions

Appendix 3 PHP code that could provide enhancements around user agent strings

cueUserAgentWords  array android  iphone ipod 

userAgent  Mozilla50 Macintosh Intel Mac OS X 1075 AppleWebKit53736 KHTML like Gecko Chrome3802125122 Safari53736

if inarraystrtolowerquery cueUserAgentWords 
    echo Are you interested in local facts about this place


Notes



	Note that Im taking my cues here from Tom Anthonys excellent post on the new query model httpmozcomblogfromkeywordstocontextsthenewquerymodel

	 I have spoken about locational context before in 2011 httpswwwlibmontanaedujasontalkscil2011libapplocationpdf and have even prototyped an app that tries to convey context about a place httpswwwlibmontanaedujasonfilesgeolocate 

	 A digest of these OCLC findings is also available at httpwwwoclcorgcontentdamoclcreports2010perceptionscollegestudentspdf

	 More specifically Khodabandelou et al express their definition as The main objective of Intention Mining is to extract sequences of actors activities from an event log to evaluate and predict the actors intentions related to those activities 2013 p 1

	 We are doing pattern matching on likely questiontype words there are advanced tools that can do more nuanced analysis around classification tokenization stemming tagging parsing and semantic reasoning See Pythons NLTK library for one of these examples httpwwwnltkorg 

	 Another good source for query intent cues is your list of smartphone voice commands  httpstechrankernethowtousesirisiricommandslistquestionstoasksiriapp 

	 Im using PHP in these examples but many of these HTTP header values and SERVER global variables can be derived from modpython if that is your programming language of choice httpmodpythonorglivemodpython331dochtmlpyapimprequestmemhtml

	 For a list of HTTP header fields see httpenwikipediaorgwikiListofHTTPheaderfields

	 For example Telize httpwwwtelizecom an opensource GeoIP JSON API is one that allows you to host your own IP resolving API

	 At this point we can apply the HTML5 geolocation API to verify our latitude and longitude values httpsdevelopermozillaorgenUSdocsWebAPIGeolocationUsinggeolocation 

	 The prototype is available at httpswwwlibmontanaedujasonfilessearchux and the code for the prototype is available at httpsgithubcomjasonclarksearchux

	 The search prototype does have a Privacy page that discusses the intentions behind the project and provides some transparency by listing the sources used to anticipate user actions httpswwwlibmontanaedujasonfilessearchuxprivacyhtml






Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS




















































Speed Matters Performance Enhancements for Library Websites


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










Speed Matters Performance Enhancements for Library Websites




Scott W H Young

MONTANA STATE UNIVERSITY



Skip other details including permanent urls DOI citation information
Volume 1 Issue 4 2016



DOI httpdxdoiorg103998weave125356420001401



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













This paper was refereed by Weaves peer reviewers

Abstract


For a user speed matters A quickloading web page facilitates a positive and pleasant user experience In this article I discuss the performance of 129 library websites and detail a practical plan for addressing common performance issues


Introduction and Context


Save the time of the reader 

                             Ranganathan



To the user speed matters The principle of saving the time of the reader was codified in 1931 as one of S R Ranganathans Five Laws of Library Science Ranganathans defense of the users time finds new expression today through the web where a fast library website can save the users time  In this paper I discuss the web performance of 129 library websites and detail a stepbystep performance enhancement plan that I implemented successfully for my librarys website

The technical performance of the web has been a subject of study in the field of humancomputer interaction and other computer science subfields for some time The phrase endtoend was one of the earliest terms of inquiry for web performance studies used to describe the network process of routing information packets across the web Bolot 1993 Krishnamurthy  Wills 2000 A landmark study arrived in 1997 when Paxson investigated the nature of slow network connections and their impact on the end user In examining network connections between different web servers across the country over two study periodsonce in 1994 and again in 1995Paxson found that the likelihood of a user encountering slow page load time more than doubled yeartoyear concluding that different sites encounter very different network routing characteristics that can affect the users experience with a web page 1997 p 614 Paxsons study demonstrated two fundamental and related aspects of web performance networked systems such as the World Wide Web are increasingly complex and will consequently over time tend to become slower 

Barford and Crovella described the situation in 1999 simply One of the most vexing questions facing researchers interested in the World Wide Web is why users often experience long delays in document retrievalThe question that motivates our work is a basic one why is the web so slow 1999 p 27  Others at the time pointed a wry finger at the web remarking that WWW is often associated with World Wide Waiting Charzinski 2001 p 37 Though not operating strictly within the context of user experience UX these early studies recognized that perceived slowness could affect the users satisfaction with a website In a 2002 study of website usability design and performance Palmer proposed that speed could serve as a success metric for websites noting that the performance factors of a website are relatively simple to measureand have a significant linkage with site success 2002 p 164 Palmers suggestion can be readily applied to todays UX environment with web performance emerging as a key measure of the users experience Stated directly if your website is slow your users experience will suffer  

More recent publications have reiterated the essential importance of speed Hogan in an excellent new book from OReilly1 asserts that speed affects experience especially in the context of the web where page load time and how fast your site feels is a large part of this user experience and should be weighed equally with the aesthetics of your site 2014 p 1 Hogans book echoes Paxson and others whose earlier research illustrated the growing complexity of the web and its resulting impact on performance 




Collectively we are designing sites with increasingly rich content lots of dynamic elements larger JavaScript files beautiful animations complex graphics and more You may focus on optimizing design and layout but those can come at the expense of page speed Hogan 2014 p 8



As web content continues to grow in size and complexity three key measures can reveal basic performance impact page weight page requests and page structure 

	
Page weightThe combined file size of all the resources used to build a page including markup styles scripts images and fonts 
	
Page requestsThe total number of resource files used to build a page When a user loads a web page the web browser requests various resources from a web server and each request is transferred via HTTP to the browser which then incrementally assembles the page content for the user 
	
Page structureThe markup configuration that defines the sequence of steps used by the browser to assemble page resources also known as the critical rendering path2



Trend analysis of data from the HTTP Archive shows that the average page weight for the World Wide Web has grown from 705 kB in 2010 to 2194 kB in 2015 an increase of 211 percent The average number of page requests has also increased 33 percent over that same time period from 74 to 99 In general terms the web is getting bigger andwithout performance optimizationwill likely get slower 

To counterbalance the growing complexity of the web weweb developers web designers librarians user experience designersmust prioritize performance in our workflows by continually evaluating and optimizing for speed This optimization work can be categorized into three primary areas frontend optimization focusing on web browser enhancements backend optimization focusing on web server enhancements and network optimization focusing on network connection speeds General best practices and techniques for web performance optimization across these three areas have been well documented such as Steve Souders 14 Rules for FasterLoading Web Sites Entire websites in fact have been created strictly for web performance educationand with clever names too like browserdietcom One of the best performance walkthroughs Ive found is a presentation from Ilya Grigorik a member of Googles Make the Web Fast team whose Crash Course on Web Performance provides a clear and extensive overview of factors affecting web speed today As an employee of Google Grigorik articulates a crucial aspect of web performance in this overview Treat performance as a business metric not a technical one Grigorik 2012 With this statement Grigorik appeals to a broad and inclusive vision of web performance where the details of page load times are not the sole domain of web developers but are instead relevant throughout an organization The business metric is in essence the basic measure of success for any organization For userfocused libraries key measures of success include user satisfaction and frequency of use A fast website benefits online users by saving time ultimately creating satisfying experiences that lead to return visits Brad Frost expresses this nicely Performance is about respect Respect your users time and they will be more likely to walk away with a positive experience Good performance is good design Frost 2013 Hogan reiterates this point in calling for an organizationwide culture of performance The largest hurdle to creating and maintaining stellar site performance is the culture of your organization 2014 p 135

By creating cultures of performance and prioritizing speed many organizations have affirmed the value of speed to the user Twitter for example published a blog post recognizing that to connect you to information in real time its important for Twitter to be fast Twitter 2012 In 2009 Google Research shared an experiment showing that a reducedspeed search results page had a measurable impact on the number of searches conducted Brutlag 2009 This theme has remained constant for Google whose Chrome team reasserted in 2015 Speed is one of the founding principles of Chrome As the web evolves and sites take advantage of increasing capabilities Chromes performance becomes even more important Schoen 2015 Google Search also counts site speed as a signal in determining link placement in the search engine results page noting Faster sites create happy users and weve seen in our internal studies that when a site responds slowly visitors spend less time there Sighal  Cutts 2010 By recognizing the importance of speed Mozilla generated a 154 percent increase in download conversions by improving the performance of its landing page by 22 seconds Cutler 2010 The user experience of web performance can produce other realworld effects as with the Obama 2012 campaign fundraising website which generated a 14 percent increase in donation conversions after launching with a 60 percent speed improvement over its previous iteration Rush 2012 A panoply of other public and private organizations have also prioritized web performance including National Public Radio GQ Microsoft and the New York Times Cooper  Bachorik 2015 Moses 2015 Web Performance Inc 2010 Konigsburg 2013 In service to their users and their bottom lines these companies have achieved and documented a faster web in effect providing answers to the researchers of the 1990s who asked Why is the web so slow

As for library websites web performance has not yet been treated at length in the library literature In reviewing past publications I found that performance is inconsistently applied as a principle of usercentered design or as a measure of user experience In establishing a checklist of usercentered design principles for library websites Raward includes a few items relating to speed such as Home page displays within 10 seconds with a 336 modem and Is each page size under 70k 2001 p 134 While these performance standards are now outdated Raward effectively positions the principle of speed within a broader and more enduring context of usercentered design Subsequent work however has not maintained a focus on performance best practices In a study of the usability and design of nearly 1500 public and academic library websites researchers adapted a number of previous studiesincluding Rawards checklistin evaluating dozens of design criteria but chose not to include any aspect of performance in their evaluation Chow 2014 In a similar analysis of Indiana public library websites researchers evaluated over 100 different design elements but performance was likewise not included Thorpe  Lukes 2015 

Where performance has been included the topic typically appears briefly or indirectly within discussions of website usability and design In a study of the factors affecting university library website design Kim found that a majority of user survey respondents agreed that a library website is successful when it lets me finish my project more quickly 2011 p 99 The scope of Kims study however does not allow for an exploration into the details of this important performancerelated finding In a study of mobile website usability Pendell and Bowman identify five primary problems encountered by users in mobile environments including unusually long page loading time 2012 p 54 But a discussion of exactly how to address long page loading time is beyond the scope of their work In another study investigating the mobile user experience Seeholzer and Salem found that users were not very concerned with sites that were unformatted for mobile devices as long as the sites loaded quickly 2011 p 19 Methods for developing quickloading websites also fall out of the scope of their study And Brown and Yunkin in examining the history of website design at the University of Nevada  Las Vegas Libraries report that the homepage was once described as graphicsheavy and slow to load 2014 p 25 While recognizing specific issues such as slow page load Brown and Yunkin ultimately offer only broad recommendations for library website design such as keep the user in mind 

So in keeping the user in mind and with many other industries and disciplines examining and writing about the specifics of web performance I wonderedhow well do library websites perform How widely are industry performance standards implemented in library websites How can libraries prioritize and address performance issues With this paper I want to return to Ranganathans law by asking and answering the question Do library websites save the time of the user 

Developing a Library Web Performance Enhancement Plan

The central research question of this project revolved around the performance of library websites and I aimed ultimately to create a practical Web Performance Enhancement Plan that would be applicable for library websites and beneficial to library website users In the course of my research I found that most library websites fall below performance standards I also found that there are clear and identifiable steps for addressing shortfalls that libraries can follow to improve the performance of their websites

In order to evaluate the speed of library websites and to develop a relevant performance enhancement plan I examined the performance of 129 library websites during the period of FebruarySeptember 2015 Institutions were selected from the member list of the Digital Library Federation a community of web and digital practitioners whose membership includes a range of small medium and large academic libraries from across North America In working from the membership list I aimed to create a representative sample of library websites for performance evaluation For each library website I evaluated the performance of the homepage as an example of a primary starting point and landing page for users and the about page as an example of a common secondary page 


Performance Diagnostic Tools

Performance testing was conducted using two leading diagnostic tools Yahoos YSlow and Googles PageSpeed Insights These tools perform an automated evaluation of a given web pages URL measuring the performance of each web page against a set of rules and producing a score for each rule PageSpeed Insights evaluates ten different performance rules with three possible scores for each rule passed rules consider fixing should fix3 Googles documentation further explains these terms passed rules indicates that no significant issues were found for a given rule consider fixing indicates that a rule should be addressed if it wouldnt involve a lot of work and should fix indicates that addressing a given rule would have a measurable impact on page performance YSlow tests twentythree different performance rules with six possible scores for each A B C D E F4 Each tool then produces a single overall numerical scorebased out of one hundredgenerated from the aggregate scores across all rules  During the evaluation process I also recorded other key metrics HTTP requests page weight and image weight5 


Google PageSpeed InsightsPerformance Rules

	Leverage browser caching
	Eliminate renderblocking JavaScript and CSS
	Enable compression
	Optimize images
	Minify CSS
	Minify JavaScript
	Minify HTML
	Avoid landing page redirects
	Prioritize visible content
	Reduce server response time


Yahoo YSlowPerformance Rules 

	Make fewer HTTP requests
	Use a content delivery network CDN
	Avoid empty src or href

	Add expires headers
	Compress components with gzip
	Put CSS at top
	Put JavaScript at bottom
	Avoid CSS expressions
	Make JavaScript and CSS external
	Reduce DNS lookups
	Minify JavaScript and CSS
	Avoid URL redirects
	Remove duplicate JavaScript and CSS
	Configure entity tags ETags
	Make AJAX cacheable
	Use GET for AJAX requests
	Reduce the number of DOM elements
	Avoid HTTP 404 error
	Reduce cookie size
	Use cookiefree domains
	Avoid AlphaImageLoader filter
	Do not scale images in HTML
	Make favicon small and cacheable





Library Web PerformanceHomepage

A histogram of overall scores for library homepages from PageSpeed Insights fig 1 and YSlow fig 2 shows the distribution of scores produced from each tool The median PageSpeed Insights score was 65 and the median YSlow score was 73  These diagnostic tests revealed that library website homepages can indeed be improved PageSpeed Insights documentation states that a score of 85 or above indicates that the page is performing well and while YSlow has not published score guidelines a higher score is generally considered to be better Two key measures further demonstrate the current state of library website homepage performance page weight fig 3 and HTTP requests fig 4  The median page weight for library homepages was 967 kB and the median number of HTTP requests was 48 Since various pages may be more or less complex in design there is no exact performance benchmark for page weight and HTTP requests This analysis intends to convey the relative states of library websites included in the performance dataset


Figure 1 Histogram of PageSpeed Insight scores for library website homepages n129




Figure 2 Histogram of YSlow scores for library website homepage scores n129




Figure 3 Histogram of page weight for library website homepages n129




Figure 4 Histogram of HTTP requests for library website homepages n129






Library Web PerformanceAbout Page

Analysis of library website about pages produced similar results Ten library websites did not feature a discernable about page and so the dataset for about pages includes 119 library websites A histogram of scores for library about pages from PageSpeed Insights fig 5 and YSlow fig 6 shows the distribution of scores produced from each tool The median PageSpeed Insights score was 72 and the median YSlow score was 75 While moderately improved over the homepages the diagnostic tools revealed that library website about pages can also be improved Results for page weight fig 7 and HTTP requests fig 8 for about pages reveal that they are lighter than homepages and request fewer HTTP resources The median page weight for library about pages was 601 kB and the median number of HTTP requests was 35 


Figure 5 Histogram of PageSpeed Insights scores for library website about pages n119




Figure 6 Histogram of YSlow scores for library website about pages n119




Figure 7 Histogram of page weight for library website about pages n119




Figure 8 Histogram of HTTP requests for library website about pages n119








Performance Rules

To take a deeper dive into the results I then looked at the individual performance rules of library website homepages and about pages as scored by both PageSpeed Insights fig 9 and YSlow fig 10 For the purposes of data analysis I converted each tools rule measurement scores to numerical scores PageSpeed Insights scores were converted to a 2point scale with 2 for passed rules 1 for consider fixing and 0 for should fix YSlow scores were converted to a 5point scale with 5 for an A 4 for a B 3 for a C 2 for a D 1 for an E and 0 for an F I aggregated the results for all institutions and generated average mean ratings for each performance rule analyzed by PageSpeed Insights and YSlow While not directly comparable these two scales effectively show performance relative to their respective rules and scoring systems


Figure 9 Distribution of PageSpeed Insights scores by performance rule for library homepages n129 and about pages n119 Higher score indicates better performance




Figure 10 Distribution of YSlow scores by performance rule for library homepages n129 and about pages n119 Higher score indicates better performance



With its granularity this process helped identify strengths and weaknesses in the performance of the library websites included in the dataset Results show that library website homepages and about pages scored widely across a range of performance rules 

The score distributions also allowed for a further categorization of results that informed the creation of a priority list of performance enhancementsthe Library Web Performance Enhancement Plan I formed three categories of performance rules according to the scores produced by PageSpeed Insights Table 1 and YSlow Table 2 HighScoring MediumScoring and LowScoring Highscoring rules scored an average between 15 and 2 from PageSpeed Insights and between 4 and 5 from YSlow mediumscoring rules scored an average between 1 and 15 from PageSpeed Insights and between 2 and 4 from YSlow lowscoring rules scored an average between 0 and 1 from PageSpeed Insights and between 0 and 2 from YSlow

Table 1 Google PageSpeed Insights sorted resultslibrary website homepages and about pages

	HighScoring Rules	MediumScoring Rules	LowScoring Rules
		Avoid landing page redirects
	Prioritize visible content
	Reduce server response time

		Minify CSS
	Minify HTML
	Minify JavaScript

		Optimize images 
	Enable compression 
	Leverage browser caching
	Eliminate renderblocking JavaScript and CSS




Table 2 Yahoo YSlow sorted results library website homepages and about pages

	HighScoring Rules	MediumScoring Rules	LowScoring Rules
		Avoid empty src or href

	Avoid URL redirects 
	Make AJAX cacheable 
	Remove duplicate JavaScript and CSS 
	Use GET for AJAX requests 
	Avoid HTTP 404 error 
	Reduce cookie size 
	Make favicon small and cacheable
	Avoid AlphaImageLoader filter 
	Put CSS at top
	Avoid CSS expressions
	Reduce DNS lookups
	Reduce the number of DOM elements 
	Do not scale images in HTML

		Minify JavaScript and CSS
	Put JavaScript at bottom
	Compress components with gzip

		Configure entity tags ETags
	Make fewer HTTP requests
	Add expires headers
	Use cookiefree domains
	Use a content delivery network CDN




From these three categories I identified the most and least urgent performance issues present in the dataset I considered rules that scored within the high scoring category to be less urgent and so these rules were not included in the Web Performance Enhancement Plan I considered rules that scored within the medium scoring and low scoring categories to be more urgent and so these rules were included in the Web Performance Enhancement Plan Fifteen unique rules from PageSpeed Insights and YSlow were categorized as medium or low performing but many rules are similar such as PageSpeed Insights Enable compression and YSlows Compress components with Gzip This allowed for about half of the rules to be combined in the Web Performance Enhancement Plan I considered two particular YSlow rules to be exceptions that were not included in the plan Use a content delivery network CDN and Use cookiefree domains These two rules low scores and potential urgency are outweighed by other factors A CDN a method for delivering web content from geographically distributed web serversand typically an expensive thirdparty serviceis not likely a justifiable purchase for many libraries who serve mostly local user communities And while removing cookies from a web property will likely improve performance it may not be feasible for libraries to follow the steps required to address this issue such as creating multiple subdomains from which to serve static content By curating a list of relevant performance rules I aimed to create a highimpact and achievable Web Performance Enhancement Plan that would be applicable to the widest possible number of libraries 

And so armed with the results of my analysis of 129 library websites I drafted the Library Web Performance Enhancement Plan 


Web Performance Enhancement Plan

	Minify CSS and JavaScript
	Minify HTML 
	Optimize images
	Reduce HTTP calls
	Enable compression
	Add expires headersleverage browser caching
	Eliminate renderblocking JavaScript and CSS in abovethefold content 






Implementing a Web Performance Enhancement Plan

In order to test the efficacy and impact of the Web Performance Enhancement Plan I applied it to the library website homepage of my own institution Montana State University Before beginning implementation baseline performance measures of the website were established by following the same evaluation process described above The results from this initial evaluation were included in the full performance evaluation dataset At each subsequent step of the plan and at its completion I remeasured the performance of the website thereby tracking the impact and progress of the plan Table 3 I maintained the same visual design and functionality of the homepage during the implementation of the plan so as to isolate each performance step in the evaluation testing  

Table 3 Web Performance Enhancement Plan for the MSU Library website homepage stepbystep progression Each numbered step indicates a stage in the Web Performance Enhancement Plan Corresponding rows demonstrate performance gains that resulted following the implementation of each step

		PageSpeed Insights Score	YSlow Score	Page Weight kB	HTTP Requests
	Initial evaluation	76	73	720	30
	1 Minify CSSJS	78	75	668	30
	2 Minify HTML	79	75	666	30
	3 Optimize images	80	77	611	30
	4 Reduce HTTP requests	82	81	435	16
	5 Enable compression	89	83	309	16
	6 Add expires headers	94	95	298	16
	7 Eliminate renderblocking content	96	96	238	15
	Final evaluation	96	96	238	15


In the initial preenhancement evaluation the homepage scored a 76 from PageSpeed Insights 76th percentile in the performance dataset and a 73 from YSlow 46th percentile The homepage weighed 720 kB 29th percentile with 30 HTTP requests 11th percentile  After completing the Performance Enhancement Plan the homepage scored a 96 from PageSpeed Insights 99th percentile equivalent and a 96 from YSlow 99th percentile equivalent with a page weight of 238 kB 1st percentile equivalent and a decrease of 67 percent and 14 HTTP requests 1st percentile equivalent and a decrease of 53 percent  In short the Performance Enhancement Plan worked 

In the following sections I address each point of the plan directly and detail its stepbystep implementation process that I followed for my librarys website Each step of the plan contains a level of depth and detail that I am unable to address in the scope of this article so I also include links to further readings and documentation from Google Yahoo and Designing for Performance While certain steps individually affected performance metrics to a greater degree than others all steps of the plan ultimately operated in concert to create a coherent and effective program for performance enhancement 


Minify CSS and JavaScript

Minifying stylesheets and scripts comes as the first step because it is among the most straightforward to implement Minification entails the removal of spaces in markup and code For a human reader spaces between characters and words are necessary for interpretation but for machine readers such as a web browser spaces are unnecessary and even undesirable as spaces can add weight to a resource Many free web tools exist that automate minifying and unminifying resources6

Before minifying the CSS for the homepage the markup contained spaces unnecessary for a web browser 


socialicons afacebookhover 
backgroundcolor 305fb3


socialicons atwitterhover 
backgroundcolor 2daae1


socialicons ayoutubehover 
backgroundcolor ff3333


socialicons apinteresthover 
backgroundcolor e1003a


socialicons atumblrhover 
backgroundcolor 44546b




After minification the same CSS can be rendered on a single line and interpreted seamlessly by the browser 


socialicons afacebookhoverbackgroundcolor305fb3socialicons atwitterhoverbackgroundcolor2daae1socialicons ayoutubehoverbackgroundcolorf33socialicons apinteresthoverbackgroundcolore1003asocialicons atumblrhoverbackgroundcolor44546b



Minifying the primary CSS file for homepage reduced its size by 33 percent 24 kB to 16 kB Minifying our 6 JavaScript resources and 3 CSS resources reduced page weight by 7 percent 720 kB to 668 kB While this gain in itself was modest it represented one gradual step in a process which builds towards a highimpact result After this step the PageSpeed Insights score increased from 76 to 78 and the YSlow score increased from 73 to 75 

Further reading

	httpsdevelopersgooglecomspeeddocsinsightsMinifyResources
	httpdesigningforperformancecomoptimizingmarkupandstylesminificationandgzip





Minify HTML

The same best practice principles of minification apply to markup  Prior to minifying our homepage HTML the markup contained many necessary spaces for human interpretation but unnecessary for machine interpretation


div idrightpane
div idaside
ul classnavtabs
li classactivea hrefindexphpHoursali 
lia hrefindexphpviewnewsNewsali lia
 hrefindexphpviewchatChatali
ul
div
div



To complete the minification step I simply unindented each line of HTML


div idrightpane
div idaside
ul classnavtabs
li classactivea hrefindexphpHoursali 
lia hrefindexphpviewnewsNewsali lia hrefindexphpviewchatChatali
ul
div
div



Minifying our one HTML resource reduced page weight by 03 percent 668 kB to 666 kB After this step the PageSpeed Insights score increased from 78 to 79 and the YSlow score remained 75

Further reading

	httpsdevelopersgooglecomspeeddocsinsightsMinifyResources
	httpdesigningforperformancecomoptimizingmarkupandstylesminificationandgzip





Optimize Images

The role of images in web performance has been well documented and much discussed Trend analysis of data from the HTTP Archive shows that images have accounted for more than 50 percent of page weight since measurement began in November 2010 and as of November 2015 images account for 64 percent of average page weight In Designing for Performance Hogan notes optimizing images is arguably the easiest big win when it comes to improving your sites page load time 2014 p 27 Images have been elsewhere described as the biggest culprit for bloated web pages Avery 2014 Images on library websites are no different In my performance dataset images on average accounted for 25 percent of total homepage weight and 11 percent of total about page weight This data suggests that images on library websites can impact performance in a big way Optimizing existing images is an approach that can offer performance gains without requiring a redesign Optimization in this case entails choosing an appropriate file format and then reducing file size with compression tools For my librarys website I converted nineteen images to JPEG a reducedsize file format I then further reduced file size with Kraken a web tool that compresses image files Other tools for Windows Mac and the web can be used to compress image files7 Before optimization images accounted for 80 percent of the total weight of our homepage After optimization images accounted for 77 percent of total page weight In all optimizing our nineteen image resources reduced page weight by 8 percent 666 kB to 611 kB  After this step the PageSpeed Insights score increased from 79 to 80 and the YSlow score increased from 75 to 77 This modest improvement illuminated two aspects of web performance enhancement optimizing images offer solid performance benefits but greater gains can result from reducing the total number of images requested via HTTP I explore this second aspect in the next section

Further reading

	httpsdevelopersgooglecomspeeddocsinsightsOptimizeImages
	httpsdeveloperyahoocomperformanceruleshtmloptimages
	httpdesigningforperformancecomoptimizingimages





Reduce HTTP Requests

This step currently offers a high potential for performance gains YSlows FAQ on grading considers the rule Make fewer HTTP requests to be the most important aspect of web performance and Hogan states Optimizing the size and number of requests that it takes to create your web page will make a tremendous impact on your sites page load time 2014 p 14 For my library websites homepage reducing HTTP requests started with a critical review of each resource Prior to addressing this step the homepage was comprised of thirty requests nineteen image files six JavaScript files three CSS files one text file and one HTML file I reduced the overall number of requests to sixteen by combining or removing resources to build a page comprised of eleven images three JavaScript files one CSS file and one HTML file The highestimpact approach was simply to reduce the number of images on the page While it was not feasible to entirely eliminate our homepages slideshow carousel I reduced the number of slides by half from six to three8 Prior to this step our homepage used a JavaScript file to interact with the Instagram API dynamically loading six Instagram images onto the page In order to optimize this page element I eliminated the JavaScript request and created a single image that presented a static gridview of Instagram images thereby reducing both our JavaScript requests and our image requests while maintaining the same basic experience of this design element I took a more straightforward approach for our CSS by simply combining three separate files into one single file which was rendered seamlessly by the browser Our one text file was an outofdate resource that was easily removed In all reducing our HTTP requests from 30 to 16 reduced page weight by 29 percent 611 kB to 435 kB After this step the PageSpeed Insights score increased from 80 to 82 and the YSlow score increased from 77 to 81

While keeping all of the above in mind a recent development in HTTP protocol promises to considerably change the performance enhancement technique of reducing HTTP requests The technical architecture of HTTP1x currently limits the number of resources that can be loaded by the browser at a single time thus significantly slowing page load time if a large number of resources are required The architecture of HTTP2 on the other hand is designed for multiplexing a new method for delivering resources concurrently to the browser9 While not now widely adopted HTTP2 will likely become the norm andfrom the perspective of web performancewill render HTTP request reduction unnecessary10

Further Reading

	httpsdeveloperyahoocomperformanceruleshtmlnumhttp
	httpdesigningforperformancecombasicsofpagespeedrequests





Enable Compression

Compressing your page resources can offer instant performance gains Gzip is the leading method for web resource compression and it can be enabled for specific file types through server configuration settings or easytoinstall plugins and extensions for content management systems such as WordPress and Drupal My librarys website runs on an Apache server so our server configuration for enabling compression is a simple oneline command


AddOutputFilterByType DEFLATE
texthtml textplain textxml textcss textjavascript 



This setting compresses all HTML XML plain text JavaScript and CSS files that pass from our web server to a web browser Enabling compression reduced our homepage weight 29 percent 435 kB to 309 kB After this step the PageSpeed Insights score increased from 82 to 89 and the YSlow score increased from 81 to 83

Further Reading

	httpsdevelopersgooglecomspeeddocsinsightsEnableCompression
	httpsdeveloperyahoocomperformanceruleshtmlgzip
	httpdesigningforperformancecomoptimizingmarkupandstylesminificationandgzip





Add Expires HeadersLeverage Browser Caching

Caching page resources in the web browser can also offer instant performance gains When a resource is saved and cached in the browser it does not need to be immediately requested again from the server With this setting enabled your returning visitors will experience much faster page load time Through this process you can also set the duration of time that a page resource expires and must again be requested by the browser For example a CSS file that is edited infrequently can be given an expires setting of 30 days thus allowing a web browser to cache this file for one month before requesting it again During this onemonth time period a returning visitor to your website will benefit from having this CSS file stored for quicker access and faster loading by the web browser As with resource compression the exact configuration setting for adding expires headers and enabling browser caching will depend on your local server environment Since my librarys website runs on an Apache server I used the following server syntax to complete this step


IfModule modexpiresc
Enable expirations
 ExpiresActive on 
Default directive
 ExpiresDefault access plus 30 days
favicon
 ExpiresByType imagexicon access plus 1 year
cache
 ExpiresByType textcachemanifest access plus 0 seconds
Data
  ExpiresByType textxml access plus 15 days
  ExpiresByType applicationxml access plus 15 days
  ExpiresByType applicationjson access plus 15 days
Images
 ExpiresByType imagegif access plus 30 days
 ExpiresByType imagepng access plus 30 days
 ExpiresByType imagejpg access plus 30 days
 ExpiresByType imagejpeg access plus 30 days
CSS
 ExpiresByType textcss access plus 30 days
Javascript
 ExpiresByType applicationjavascript access plus 1 year
 ExpiresByType textjavascript access plus 1 year
HTML
 ExpiresByType texthtml access plus 43200 seconds
Fonts
 ExpiresByType applicationvndmsfontobject access plus 1 year
 ExpiresByType applicationxfontttf access plus 1 year
 ExpiresByType applicationxfontopentype   access plus 1 year
 ExpiresByType applicationxfontwoff access plus 1 year
 ExpiresByType fonttruetype access plus 1 month
 ExpiresByType imagesvgxml access plus 1 month
IfModule



These settings add various expires timeframes for all HTML XML JSON plain text JavaScript CSS image and font files that pass from our web server to a web browser The web server and the web browser coordinate resources through a mechanism known as Entity Tags Once youve enabled browser caching you will also want to check that your servers ETags are also configured correctly Leveraging browser caching reduced page weight 35 percent 309 kB to 298 kB After this step the PageSpeed Insights score increased from 89 to 94 and the YSlow score increased from 83 to 95

Further Reading

	httpsdevelopersgooglecomspeeddocsinsightsLeverageBrowserCaching
	httpsdeveloperyahoocomperformanceruleshtmlexpires
	httpsdeveloperyahoocomperformanceruleshtmletags
	httpdesigningforperformancecomoptimizingmarkupandstylescachingassets





Eliminate RenderBlocking JavaScript and CSS in AboveTheFold Content

This step involves optimizing the delivery of JavaScript and CSS resources for page content that loads in the immediate view of a user above the socalled page fold In practical terms this means loading CSS resources at the top of the page and asynchronously loading JavaScript at the bottom To complete this step for my library websites homepage I added the async HTML attribute to our primary JavaScript file


script async typetextjavascript srcmetascriptsscriptsallminjs
script



And I moved all the styles from our single CSS file used for the homepagealready quite small at 77 kBinto the HTML head of our homepage thereby improving page load time by reducing our HTTP requests and removing the dependency on this potentially renderblocking external CSS file Eliminating renderblocking JavaScript and CSS reduced page weight 20 percent 298 kB to 238 kB and reduced HTTP requests from 16 to 15 After this step the PageSpeed Insights score increased from 94 to 96 and the YSlow score increased from 95 to 96

Further Reading

	httpsdevelopersgooglecomspeeddocsinsightsOptimizeCSSDelivery
	httpsdevelopersgooglecomspeeddocsinsightsBlockingJS
	httpsdeveloperyahoocomperformanceruleshtmlcsstop
	httpsdeveloperyahoocomperformanceruleshtmljsbottom
	httpdesigningforperformancecomoptimizingmarkupandstylescssandjavascriptloading




Web Performance in Practice 

The Web Performance Enhancement Plan proved to be a great success for the MSU Library website From a visual standpoint the homepage interface itself went mostly unchanged through this process Only when looking under the hood is it possible to discern the differences The performance enhancements detailed in this paper translated into a fasterloading library homepage and an overall improved experience for our users Results from this research and walkthrough can help inform the work of library web practitioners and user experience designers with the Web Performance Enhancement Plan serving as one possible method for ensuring that your pages load quickly

Beyond the immediate impact of the plan are issues of workflow integration and the longterm sustainability of performance optimization To help introduce or reinforce performancefocused measures into existing workflows I recommend network checks which entail testing a website or web application under a variety of network speeds to ensure usability and functionality across a range of internet connection environments Many users from advanced countries such as South Korea Sweden and Japan enjoy average broadband connections that near an ideal 30 Mbps but many other users across the globe access the web from lessthanideal mobile connection speeds that average near 1 Mbps such as Vietnam Indonesia and Argentina Belson 2015 Within the United States network connection speeds can also vary greatly In 2011 the average download speed in Dover Delaware 189 Mbps was nearly three times that of Dallas Texas at 68 Mbps Statista 2011 Broadband adoption is another relevant website performance indicator which also shows a disparity among US states with Delaware recording a 97 percent adoption rate of 4 Mbps broadband in the first quarter of 2015 and West Virginia recording a 63 percent adoption rate Belson 2015 The reality of varying network connection speeds is especially relevant for libraries whose users access web content from a variety of geographic areas mobile devices and rural environments Hogan 2014

In order to track and measure web performance I also recommend performance benchmarking which entails documenting page weight and other performance metrics using PageSpeed Insights YSlow and other widelyavailable performance monitoring tools such as WebPageTest and Byte Check To provide additional structure to performance monitoring a performance budget can also be applied to a web page or a web application which entails setting upper limits for key metrics such as page weight HTTP requests PageSpeed Insights score YSlow score speed index and page render times11 Advanced CSS animations large images and complex JavaScript functions can dramatically impact the performance of a website and such costly functionality should be weighed against the goals of the site its users and the potential impact on web performance As more functionality is added to a website or web app a performance budget can serve as a check against unnecessary or overly costly web page elements Performance budgets can also be gamified as demonstrated by the University of Minnesota Libraries Web Development Team which has created a Speed Leader Board that publicizes uptodate PageSpeed Insights scores for each Big Ten university librarys website homepage 

As part of a comprehensive web analytics program metrics such as performance benchmarking and performance budgeting can be used to understand evaluate and improve library websites The role of web analytics overall has notably increased in recent years as libraries have begun incorporating analytics tools into web workflows and user experience research Recent studies detail the benefits offered by web analytics to usercentered web design and development Barba et al 2013 Veregin 2014 Young 2014 Tobias 2015 Helpful libraryfocused analytics tutorials and practical walkthroughs have also appeared in recent years Hess 2012 Yang  Perry 2014 In reviewing the function of web analytics reporting for academic library websites Hogan concludes that web analytics have the potential to be a treasure trove of valuable decisionmaking information for libraries 2014 p 32 Indeed web performance metrics can provide a valuable structure for shaping a librarys website with page load time and its associated measures helping to form the core of a librarys website design and user experience evaluation  

Final Thoughts

Performance is a fundamental aspect of a users experience of the web How fast or slow a page loads should be a matter of practical concern for those designing and developing the web Through research into library website performance I found that many library websites exhibit similar strengths and weaknesses across a range of performance rules Using this research data as a foundation for improvement I created a sevenstep Library Web Performance Enhancement Plan that I implemented for my own librarys website By following this plan the performance of my library websites homepage markedly improved with gains across key performance metrics such as PageSpeed Insights score YSlow score page weight and HTTP requests This plan which can be implemented with a modest commitment of time and resources ultimately produced an achievable and effective pathway for performance enhancement While the nuances of your local environment may generate greater or lesser gains web performance enhancement and maintenance promise to save the time of the user ultimately leading to an overall positive impact for your websites users

Data Availability

All research data is available from the authors institutional repository Montana State University ScholarWorks httpdoiorg1015788m23w2g

Acknowledgements

For their illuminating insight I would like to thank the Skylight writing group Ryer Banta Sara Mannheimer and Kirsten Ostergaard My thanks also to Krista Godfrey for many valuable video chats along the way

References

	Avery J 2014 Reducing image sizes Retrieved from httpsresponsivedesignisarticlesreducingimagesizes

	Barba I Cassidy R De Leon E  Williams B J 2013 Web analytics reveal user behavior TTU Libraries experience with Google Analytics Journal of Web Librarianship 74 389400 
	Barford P  Crovella M 1999 Measuring web performance in the wide area Performance Evaluation Review 272 3748 
	Belson D 2015 State of the Internet Q1 2015 report PDF document Vol 8 No 1 Akamai Retrieved from httpswwwstateoftheinternetcomdownloadspdfs2015q1stateoftheinternetreportpdf

	Bolot JC 1993 Endtoend packet delay and loss behavior in the Internet In Conference Proceedings on Communications Architectures Protocols and Applications pp 289298 New York Association for Computing Machinery 
	Brown J M  Yunkin M 2014 Tracking changes One librarys homepage over timefindings from usability testing and reflections on staffing Journal of Web Librarianship 81 2347 
	Brutlag J 2009 Speed matters Retrieved from httpgoogleresearchblogspotcom200906speedmattershtml

	Charzinski J 2001 Web performance in practicewhy we are waiting International Journal of Electronics and Communications 551 3745
	Chow A S Bridges M  Commander P 2014 The website design and usability of US academic and public libraries Reference  User Services Quarterly 533 253265
	Cooper P  Bachorik J 2015 NPRorg now twice as fast Retrieved from httpwwwnprorgsectionsthisisnpr20151027451147757nprorgnowtwiceasfast

	Cutler B 2010 Firefox  page load speedpart II Retrieved from httpsblogmozillaorgmetrics20100405firefoxpageloadspeedE28093partii

	Frost B 2013 Performance as design Retrieved from httpbradfrostcomblogpostperformanceasdesign

	Grigorik I 2012 Crash course on web performance PDF document Retrieved from httpswwwigvitacomslides2012webperfcrashcoursepdf

	Hess K 2012 Discovering digital library user behavior with Google Analytics Code4Lib Journal 17 
	Hogan L C 2014 Designing for performance Cambridge OReilly Media Inc
	Kim YM 2011 Factors affecting university library website design Information Technology and Libraries 303 99107 
	Konigsburg E 2013 Web performance at the New York Times Video file Retrieved from httpsyoutube2dwBB2XaB0

	Krishnamurthy B  Wills C E 2000 Analyzing factors that influence endtoend web performance Computer Networks 3316 1732
	Moses L 2015 How GQ cut its webpage load time by 80 percent Retrieved from httpdigidaycompublishersgqcomcutpageloadtime80percent

	Palmer J W 2002 Web site usability design and performance metrics Information Systems Research 132 151167 
	Paxson V 1997 Endtoend routing behavior in the Internet IEEEACM Transactions on Networking 55 601615 
	Pendell K D  Bowman M S 2012 Usability study of a librarys mobile website An example from Portland State University Information Technology and Libraries 312 4562
	Ranganathan S R 1931 The five laws of library science Madras Madras Library Association
	Raward R 2001 Academic library website design principles Development of a checklist Australian Academic  Research Libraries 322 123136
	Rush K 2012 Meet the Obama campaigns 250 million fundraising platform Retrieved from httpkylerushnetblogmeettheobamacampaigns250millionfundraisingplatform

	Schoen R 2015 Chrome improvements for a faster and more efficient web Retrieved from httpchromeblogspotcom201509chromeimprovementsforfasterandmorehtml

	Seeholzer J  Salem J A 2011 Library on the go A focus group study of the mobile web and the academic library College  Research Libraries 721 920 
	Sighal A  Cutts M 2010 Using site speed in web search ranking Retrieved from httpgooglewebmastercentralblogspotcom201004usingsitespeedinwebsearchrankinghtml

	Statista 2011 Average download speeds in selected US cities in 2011 in mbps Retrieved from httpwwwstatistacomstatistics210601averagedownloadspeedsinuscities

	Thorpe A  Lukes R 2015 A design analysis of Indiana public library homepages Public Library Quarterly 342 134161 
	Tobias C  Blair A 2015 Listen to what you cannot hear observe what you cannot see An introduction to evidencebased methods for evaluating and enhancing the user experience in distance library services Journal of Library  Information Services in Distance Learning 912 148156 
	Twitter 2012 Improving performance on twittercom Retrieved from httpsblogtwittercom2012improvingperformanceontwittercom

	Veregin H  Wortley A J 2014 Using web analytics to evaluate the effectiveness of online maps for community outreach Journal of Web Librarianship 82 125146
	Web Performance Inc 2010 Microsoft affirms the importance of web performance Retrieved from httpwwwwebperformancecomloadtestingblog201006microsoftaffirmstheimportanceofwebperformance

	Yang L  Perrin J M 2014 Tutorials on Google Analytics How to craft a web analytics report for a library web site Journal of Web Librarianship 84 404417
	Young S W 2014 Improving library user experience with AB testing Principles and process Weave Journal of Library User Experience 11 Retrieved from httpdxdoiorg103998weave125356420001101



Notes



	Also available on the web with a CCBYNCND license httpdesigningforperformancecom

	 Detailed discussion of this important and nuanced concept httpsdevelopersgooglecomwebfundamentalsperformancecriticalrenderingpath

	 See the full documentation for more detail httpsdevelopersgooglecomspeeddocsinsightsabout also see Googles performance guidelines for detail regarding various PageSpeed Insights rules httpsdevelopersgooglecomwebfundamentalsperformance

	 See the full documentation for more detail httpysloworgrulesetmatrix I tested websites using YSlow V2 from which one rule was excluded by default Make JavaScript and CSS external

	 Full dataset available at httpdoiorg1015788m23w2g

	 For example httpcssminifiercom and httpunminifycom 

	 For example RIOT for Windows httplucicrioswebroriot ImageOptim for MaciOS devices httpsimageoptimcom Smush it on the web httpwwwimgoptcom

	 For a more critical take of slideshow carousels see httpshouldiuseacarouselcom

	 For more information see httpshttp2githubiofaqwhyishttp2multiplexed httprmurpheycomblog20151125buildingforhttp2

	 For further reading on HTTP2 see Chapter 12 of High Performance Browser Networking by Ilya Grigorik httpchimeralabsoreillycombooks1230000000545ch12html

	 For more on performance budgeting see httpstimkadleccom201411performancebudgetmetrics and httpdanielmallcomarticleshowtomakeaperformancebudget






Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS





















































Signage by Design A DesignThinking Approach to Library User Experience


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










Signage by Design A DesignThinking Approach to Library User Experience 




Edward Luca and Bhuva Narayan

University of Technology Sydney Australia



Skip other details including permanent urls DOI citation information
Volume 1 Issue 5 2016



DOI httpdxdoiorg103998weave125356420001501



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













This paper was refereed by Weaves peer reviewers

Abstract


Signage is a powerful visual tool for communication and a crucial component of the library user experience Signage can welcome guide instruct and delight users helping them navigate the complex information world of any library In practice however signage can be problematic revealing tensions between various stakeholders and contributing to visual noise through information overload this often leads to signage blindness library anxiety and confusion This article explores how libraries can use a designthinking approach to improve the user experience in physical library spaces particularly with respect to signage based on our experience at the UTS Library a university library in Australia that serves the University of Technology Sydney UTS We found that a designthinking approach that uses the processes of empathy problem definition solution ideation prototyping and testing can help libraries make significant and meaningful changes that can be adopted at relatively low cost


Introduction

Aimlessly wandering through library aisles and browsing bookshelves can be a pleasurable experience but when one is new to a library the maze of floors and the variety of resources can be daunting and we rely on signs and visual clues to help us find our way Libraries are growing organisms Ranganathan 1931 and in our digital age users can find them more complex and confusing than ever before Even regular visitors to a library need help to inform and guide them through the continual changes that a library undergoes This assistance is often provided through signage which must be regularly reviewed and updated Polger  Stempler 2014

Despite or perhaps because of this signage is an issue that proves challenging for libraries Barclay and Scott state that if there is one truism about library signage it is that most of it is not very good 2012 p 37 Similar sentiments are echoed by White who identifies poor visual communication as a practice that librarians commonly cling to 2010 p 23 contributing to a poor user experience Unprofessional inconsistently designed and negative signage creates a poor user environment with do not prohibited and no talking signs scolding users rather than helping them use the library productively Furthermore bad signage can also turn away users wasting their time and the time of library staff in answering queries that could be easily addressed with better signage In fact White 2010 declares that having no signage whatsoever is better than bad signage

Literature Review

Library signage is one of many touch points Schmidt 2010 in a library which are any interaction the user has with library service Hahn  Zitron 2011 p 28 Such touchpoints can easily turn into pain points Schmidt 2010 p 20 or places of contact that can leave users feeling confused aggravated or disappointed Schmidt 2010 p 20 Library staff workshops and the librarys website are also examples of touch points Though a single sign may only be a small part of a users library experience the fact that the library has considered the impact that this one sign has on peoples perceptions of the library is a good indication that it is also considering the impact of more significant touchpoints such as programming and services Schmidt 2015 p 25 Poor signage however can trigger library anxiety a term coined by Constance Mellon to describe feelings of fear uncertainty and worry when visiting the library McPherson 2015 p 317 

Effective signage contributes to a userfriendly environment and can help users move throughout buildings more efficiently and accurately and may reduce questions at service points Bosman  Rusinek 1997 p 81 It has been found that library users may experience a fear of appearing stupid and revealing ignorance by asking questions Coker 1993 p 27 which can be a psychological barrier to requesting assistance More recently library anxiety has been found to have a paralyzing effect which can prevent users from approaching a research assignment rationally and effectively and can influence a students ability to complete assignments McPherson 2015 p 318 Signage can help to reduce this uncertainty fear and confusion Carlile suggests combating issues of library anxiety by providing visual guidance through better signage wording directions and instructions in jargonfree terminology and having staff wear nametags 2007 p 138 Together these elements allow users to feel more comfortable about using the space finding information and locating resources 

Library signage serves two broad purposes informing library users and trying to influence their behavior Serfass 2012 p 5 It is important to help users to feel comfortable and confident in using the library to achieve this Polger and Stempler argue that library signs are living documents 2014 p 67 and must adapt and change as the library does Librarians undertake responsibilities around designing signage brochures informational handouts web pages and promotional and instructional documents every day as part of their jobs Hence librarians are in the business of graphic design even if they have not been formally trained in design Wakimoto 2015 p 172

Signage also acts as an affordance to the resources in a libraryaffordances are features in the environment that indicate the potential for a behavior but not the actual occurrence of that behavior Maier Fadel  Battisto 2009 p 397 An affordance according to Gibson points two ways to the environment and to the observer 1979 p 141 and in this sense library signage is a key affordance in the library user experience Library signage is there to help users to use the library which could be anything from assisting a user in navigating the library collection to explaining how to use a selfcheck loans machine The role of the librarian is to connect people to information and according to Schmidt and Etches signs can be seen as tools to achieve this and hence their design falls well within the scope of library work 2014 p 71

Improving wayfinding is something that librarians can easily have control over Mollerup calls this wayshowing and it includes all activities and implements that make a location navigable identifiable understandable memorable and accessible 2013 p 50 Signage is an integral part of this wayshowing changes to signage can be prototyped refined and implemented in a relatively lowcost manner reducing library anxiety and increasing positive attitudes

Human wayfinding behaviors are affected by three factors differentiation of the environment visual access and complexity of the spatial layout Li  Klippel 2012 p 23 Li and Klippel argue that the layout complexity of an environment has the most significant impact on human wayfinding behaviors and that even in areas with low layout complexity a misleading sign made participants choose the wrong bookshelf 2012 p 36 Too many signs and signs dense with information can also cause information overload for in a sense signage can be considered the filters we use to sift through the information in our environment When that information seems too much Clay Shirky argues that it is not information overload its filter failure Asay 2009 Hence signage failure is a type of filter failure 

Godfrey suggests that the same usability principles that are applied to library websites are also relevant to other forms of library communication such as signage for by avoiding library jargon using personal and friendly language and reducing unnecessary text library communication becomes usable useful and clear 2015 

Apart from recommending that libraries create a brand identity and use a consistent visual language on all signs Schmidt and Etches 2014 rework Browns 2002 classification of the types of signage and propose five types This article uses these classifications of signsdirectional identification instructional regulatory and informational Schmidt  Etches 2014 and uses examples from UTS Library and the literature to present evidence for how these signs can be improved in all libraries

Context and Approach

UTS is an innercity university with more than a dozen buildings in varying architectural styles built across several decades These buildings are not within a campus per se but located on busy streets in the city amongst several tourist destinations resulting in a lot of people traffic Students and academics often struggled to locate campus buildings and the classrooms Consequently the university implemented large standardized signage throughout the university and inside buildings This signage system was not sufficient for the librarys purposes due to the complex nature of the librarys resources 

Around the same time the UTS library retrieval system went online in July 2014 This onsite underground automated storage and retrieval system uses radio frequency identification to store lowuse items from the library collection The system stores roughly 450000 items while a further 200000 remain on the physical library shelves This system although allowing UTS to retain its print collection onsite is not browsable In preparation for its implementation UTS Library staff were faced with the task of not just enhancing its online discovery tools using a designthinking approach as detailed in Booth Schofield and Tiffen 2012 but also reconfiguring the library spaces and redesigning all the signage Simultaneously as described in Tiffen and England we envisioned the library as a place of collaboration social engagement and creativity staffed by individuals who are approachable personable and unique 2011 p 238 Existing signage did little to support this vision as evidenced by the increased number of help desk inquiries

Since 2012 the UTS Library has also appointed an artistinresidence to in the words of our university librarian ask questions of us that wed not ask of ourselves and to consider aspects of the library and its progress from a visual artists perspective Booth 2016 The first of our artistsinresidence Chris Gaul aimed to show that interfaces for exploring and browsing library collections both physically and online can be creative delightfultools that encourage playful exploration and serendipitous discovery Gaul 2013b The UTS Library also intended to represent a culture of creativity as described in Chan Crosbie and Williams where the visual identity will become synonymous with the experience of the library bringing the university together as a hub of knowledge culture and collaboration 2015 p 2

Alhamdani describes design thinking as an inventive process of thinking backwards from people that leads to design a product a service or else is based on the conclusions of the knowledge gathered in the process 2016 p 80 Razzouk and Shute assert that design thinking engages a person in opportunities to experiment create and prototype models gather feedback and redesign 2012 p 330 A key aspect of the process involves empathizing with the user which the Stanfords design school describes as the centerpiece of a humancentered design process Hasso Plattner Institute of Design 2013 p 2 Amiel and Reeves argue that designbased research calls for practitioners and researchers to engage in longterm collaborations 2008 p 33 while Serfass recommends that one staff member should be assigned to oversee signage 2012 In our case the communication officer at the library also a trained librarian was the coordinator of this project and engaged with all the stakeholders including library staff students academics and university staff at various stages of the redesign process A number of academics were also consulted from various departments including researchers from the library and information science discipline and from the design disciplines

We adapted the designthinking process as follows to suit an academic library

	
Empathy To understand the needs of our users including students academics university staff and members of the public we conducted observations Curedale 2013 library sweeps Given  Leckie 2003 shadowed users engaged in conversations and conducted interviews This approach provided us with rich contextual information and a more insightful understanding of the library user experience than the numerous surveys that had been conducted in the past 
	
Definition The information we gained from the empathetic approach above was used to define the problems we found that were related to signage or could be solved with signage We conducted a signage audit by photographing signage found throughout the library and mapping them to a table organized according to the categories outlined by Schmidt and Etches 2014 p 83 We also identified touchpoints that lacked sufficient signage 
	
Ideation Based on the mapping as above library staff engaged in brainstorming sessions that were not only fun in terms of group cohesion but also resulted in several nontraditional signage ideas These brainstorming sessions also involved some students working parttime at the library who offered a valuable student perspective with a lot of reflexive humor from their own experiences The resulting solutions we arrived at had a conversational tone to them Although this was not common practice in previous signage we decided to prototype the more playful ideas for testing as it was in line with our vision for the library being seen as less authoritarian and prescriptive We also removed signs that were duplicated redundant or caused an information overload
	
Prototyping We prototyped a range of signs on printed paper First we addressed common printed signage around the library followed by hanging identification signage and wayfinding signage last By beginning with lowcost printed signs we had the freedom to experiment with fonts colors and placement before deciding on a final design Updating signs in this way allowed us to implement gradual changes over a period of two years with continual user input throughout the process This made the process more manageable and over time helped us arrive at signage that worked for all our users
	
Testing As the testing was in parallel to the prototyping on account of the lowcost and lowstakes solutions unlike product testing for example we simultaneously engaged in a process of prototyping and testing that informed each other in a continuous process Once there was enough user input to decide on a sign we proceeded to make more fixed signage that was professionally produced


Implementation

This section details the designthinking process we adopted as described above Given and Leckie argue that identifying usage patterns within library spaces is useful in matching information services to users information behaviors or to redesign the social activity space of libraries 2003 p 366 We identified through user observations and signage sweeps on every floor that there were a number of issues within the physical library spaces This was done in a process similar to Given and Leckies 2003 library sweeps wherein we conducted timed walks or sweeps through the library space and documented a range of user behaviors taking place including signagerelated behaviors This provided a valuable method for investigating questions about how our users interact with the signage As part of this process library staff observed shadowed and had informal conversations with users over a period of several months in 201314 We tracked reference desk queries using RefTracker and were able to use statistics from the application to assess the changes in the number of queries about particular library topics 

We observed that students were regularly visiting the information desk with questions that the staff believed they had already addressed in various signs throughout the building These included locating spaces services and resources within the building such as finding the printing room printing locating a water fountain finding parts of the library collection locating group study rooms finding library workshops and ordering books from our automated library retrieval system

The sheer number of inquiries and evidence of confusion amongst our users led us to examine our assumptions about how we expected users to find that information It was at this point that we discovered that many of the inquiries we received were about wayfinding or howto processes to interact with library systems We also identified that some of the recent changes in the library spaces were not implicitly addressed in our current signage Thus some of the confusion was caused by the very signage that was aimed at reducing this confusion 

We conducted a signage audit to identify the scope of the issue in which we photographed every sign in the library and created a spreadsheet Such an inventory of all signs throughout the library allowed us the opportunity to evaluate a multitude of issues relating to language design branding and overall aesthetic Stempler  Polger 2013 p 122 The first phase of the project examined common printed signage before examining permanently fixed signage in the second phase This allowed us to observe the effects of lowcost changes and test these to receive feedback before implementing more permanent changes 

As part of the signage audit every sign in the library was photographed annotated and placed in a spreadsheet and classified in the following categories directional identification instructional regulatory or informational Each sign was also evaluated in terms of its usefulness Does it serve its intended purpose and is it clear and easy to understand1 Figure 1 provides an example of how our signage audit was formatted 


Figure 1 All signs were recorded and evaluated using the following categories name type location text usefulness whether to update or remove the sign and whether it utilized the library branding appropriately



The signage audit revealed the following issues

	Too many signs some of which were reactionary or temporary responses to an inquiry that occurred years ago
	Signage introduced at different points in the librarys history resulting in inconsistent branding terminology and style 
	Poor information design with too much text laid out in a confusing and convoluted manner such as in Figure 2
	Multiple signs referring to the same information leading to information overload
	Many signs were simply old and looked faded untidy and unprofessional 



Figure 2 An example of two problematic signs They use inconsistent colors and fonts contain too much information and the content cannot be scanned quickly



Based on the issues identified above seventeen of the fiftyfour kinds of common printed signs could be removed immediatelyeither they were no longer relevant contradicted another sign or the information was already addressed elsewhere One paper sign had been up for ten whole years according to the date in the footer

We developed a simple template for printed signs with a range of complementary background colors and a clear typeface fig 3 Figure 4 a confusing and poorly formatted sign is redesigned in Figure 5 


Figure 3 A selection of new signs implemented with a consistent visual style brief messages and colors corresponding to the floor




Figure 4 While this sign uses the library colors and some brand elements the information is poorly conveyed with a poor choice of typeface




Figure 5 The redesigned version of the sign in Figure 4 The critical information previously the final sentence has been flipped to the top of the sign



All the new signs are divided into two partswith an important attentiongrabbing message in a large type and then further detail for those willing to read on fig 6 At the bottom of each sign we added our social media hashtag utslibrary and icons for Facebook Twitter and Instagram Students actively engage with the library on social media and many of our signs sparked positive conversations amongst students who photographed the signage and posted it 


Figure 6 The signs key message is communicated with a brief amount of text in a large font followed by more information below



In keeping with Schmidt and Etches classification 2014 the following discussion is mapped to their five categories as mentioned earlier We propose a sixth category fun and delightful signage which we implemented to reduce library anxiety and encourage a positive user experience


Directional

Directional or wayfinding signage helps users get from where they are to where they want to be Schmidt  Etches 2014 p 83 Brown suggests that library signage should not be wholly responsible for guiding users and that wayfinding should be considered even when developing the architecture for the building Brown 2002 p 95 Although the UTS Library building was purposebuilt as a library Peake  Wilschefski 1989 our users were still encountering a number of issues locating certain features of the library In our study we found that wayfinding signage at UTS Library served the following purposes 

	Helps a user to orient themselves upon entering the library and to work out where they need to go next
	Find the area in the library that is relevant to their visit a group study room a training room a silent study area and so on
	Helps a user to locate specific parts of the library collection including print and other media
	Helps the user locate facilities such as bathrooms computers printers and water fountains


A key consideration is where a sign should be placed hence the library sweeps and user studies described earlier were essential in allowing us to consider the physical locations where users may require information Serfass calls these decision points 2012 p 5 and argues that identifying these is particularly relevant for directional signage Similarly Barclay and Scott use the term bump point to identify areas where people routinely stop or slow down as they decide which way to go next 2012 p 37 Library staff typically find it challenging to adopt a usercentered perspective so conducting ethnographic research was essential in making informed design decisions that addressed the needs of our users Fortunately this form of user research can be performed relatively quickly and at low costsimply observe your users in action Despite this methods informal structure ethnographic observations should still be systematic careful and well documented with notes sketches photographs or raw video footage Martin  Hanington 2012 p 120

We did this through a meticulous process of observing shadowing and documenting our users their queries and their navigation through the library over several months The bump points were mapped to the library floor plans before any new signage was implemented Figure 7 demonstrates the final signage and information required by users entering each floor which we identified through observations and interviews


Figure 7 The library directory is prominently visible on each floor Floors are assigned different colors and call number ranges are clearly labeled



The placement height of wayfinding signage was also found to be an issue Many signs were hanging from the ceiling well above eye level and ignored by users When we began to experiment with new wayfinding signage we used temporary printed signs mounted on portable stands to test placement before implementing final signage 

Being a university with a large international student cohort it was also necessary to make the signage universally comprehensible and hence floor numbers needed to be highlighted prominently at doorways stairs and elevators and not just in the directory and at floorelevator entrances They also needed to follow a consistent design This had not been especially clear in the previous iteration of wayfinding signage which is shown in Figure 8


Figure 8 This wayfinding sign was professionally designed and on brand yet wasnt conveying information effectively and was pasted on top of the space vacated by an even older sign There is no clear hierarchy of information and the text is too small to read from a distance






Identification

UTS Library uses the Dewey Decimal System to classify its book and journal collection In 2013 the Collection Ribbon fig 9 was introduced to the online library catalog inspired by our artistinresidence Chris Gauls work in developing ways to visualize library collections The Collection Ribbon is a colored ribbon that assigns colors to different subject ranges This is a functional feature too as clicking on the different colors allows a user to refine their search results by subject area enabling them to discover new materials This feature was designed to simulate a browsable way to look at the collection like walking through a traditional library aisle In addition a Shelf View design was incorporated into the catalog to show the books adjacent to any individual book on the physical shelves


Figure 9 The interactive Collection Ribbon is visible at the top of UTS Librarys online catalog 2016



Hahn and Zitron found that call number classification confuses students where they do not have the context and frame of reference whereby they can apply this number as corresponding to the location of a book on a shelf 2011 p 32 The addition of posters that assign a broad subject to call numbers has been found to assist firstyear students who are unfamiliar with the library Hahn  Zitron 2011 The call number itself is the most crucial element of the sign for a known search but subject headings and material lists help to encourage browsing and discovery Stempler 2013 The same study found that a colorcoded stack signage system has helped users orient themselves and find materials in a library with high layout complexity Stempler 2013 p 512 

Woodward suggests that libraries consider how they might adapt elements of the bookstore model to attract users in the same way bookstores have developed sophisticated strategies to attract customers 2004 p 20 Due to the size of library collections and the counterintuitive ways in which they are often organized Woodward argues that effective signage and logical arrangement often make it easier to find materials in a bookstore than in a library 2004 p 118

We took these ideas into consideration and decided to introduce topic headings different from the Dewey Decimal Classification classes on our call number signage to make the stacks in our physical library easier to browse fig 10 These topic headings match our students study areas which makes it easier for users to browse and discover items in the subjects of their interest or related itemsor stumble upon something entirely different elsewhere This was a collaborative effort with input from our liaison librarians as they were familiar with the terms most useful to students studying at our university 

Using the Collection Ribbon from our library catalog we were also able to assign colors to the call number signage For example items in the 300s social science are blue shown in Figure 10 This simple visual clue aids navigation and provides a hint to users unfamiliar with the layout of the collection Figure 11 shows the transition from one topic area to another demonstrated by the change in color


Figure 10 Call number signage uses topic headings to allow for greater discoverability of materials The colors from the Collection Ribbon are used as a visual clue to assist students locating items




Figure 11 The transition from yellow to green communicates the change from the 00s computer scienceinformation  general works to 100s philosophy and psychology



When auditing signage it is important to be critical and question the rationale behind all signage At UTS Library a particular row of computers is reserved for community membersalumni members day visitors and independent researchers Originally named GRow the meaning has become unclear over time and in 2016 it was the only row of computers to be specifically named A librarys signage system must be flexible enough to allow for changes in resources services and facilities In this instance many staff members referred to the row as GRow yet the name had no meaning and was unnecessarily confusing for users Signage should help create a meaningful experience for its patrons Polger  Stempler 2014 p 68 and librarians must be able to acknowledge when something is no longer working A simple sign stating This row is for community members to indicate that the computer was available to those who were not UTS staff or students was created and is now being used to designate the appropriate row We found it valuable to be wary of statements such as thats the way its always been Questioning the status quo and asking whether there was a better way of doing something led to a number of unexpected changes that significantly improved the user experience at our library




Instructional

Instructional signage helps users to better utilize the library This is also one of the most common types of poor signage when a user encounters an issue helpful staff members are quick to prepare a handmade sign explaining the correct procedure These accumulate And become outdated And cause clutter Schmidt and Etches argue that paper signs are often put up because something isnt working very well 2014 p 86 Instead librarians should address the core issue which will improve the visual environment and make the library more pleasant to use This idea is supported by Mollerup who argues that user instructions can sometimes be seen as repair design for poorly designed products that cannot themselves explain how they should be used 2005 p 15 Creating a professionallooking version of the same sign does little to address the underlying issue Brown suggests that most library policies and instructions for complicated procedures should be presented to users by word of mouth or in a handout or flyer rather than a sign 2002 p 93

Printing is a common but often complicated procedure at academic libraries and UTS Librarys own Print  Copy Room proved to be a problematic user environment Staff members at the librarys reference desk receive many inquiries about printing and copying services and as part of this study we shadowed users and observed the room to uncover why The room appeared to be thoroughly signposted with many different signs explaining how to add money to your account Yet there was little consistency to these instructions with many signs created at different points in time and using different terminology and language A key piece of informationthat users can print from their laptop or mobile device not just the library computerswas not to be found on any of the signage The librarys website did not provide information about this either instead listing printing costs how to add money to your account and where to get help Clearly there was a wealth of information available about printing but not necessarily the information users actually needed to print and copy 

All existing signage was removed and the following strategies were implemented to address this issue of information overload

	Rewriting the page on the librarys website to include clear sections on printing from a library computer and printing from your laptop tablet or phone UTS Library 2016
	Developing a handout for the reference desk on printing from your own device which was given to students who were not using library computers
	New simplified signage in the Print  Copy Room that clearly explained how to add money to your account how to print and how to copy


An amusing and simple solution also became apparent through our observationsthere were large queues of ten or more students forming to use the one stapler available This example illustrates the value in critically observing user environments in action We added a few extra staplers in the room and the issue was solved




Regulatory

Regulatory signage aims to enforce rules and influence user behavior and is typically the most challenging type of sign to implement Schmidt suggests that most or all regulatory signs should be removed as they do not apply to most users and are usually not effective anyway Schmidt 2015 It is not surprising to find users appearing confused when entering a space covered in signage proclaiming rules regulations and instructions By cultivating a positive library experience users may feel more confident and comfortable with using the library Carlile 2007 p 138 which encourages continued use of the library 

Controlling noise levels is a challenge faced by most libraries The silent floor at UTS Library was found to be completely covered in regulatory signage all of which was largely ignored by users Signs such as No smoking Text not talk and Quiet environment were found on every column in silent study areas creating visual clutter and a poor user environment There was also inconsistent terminology with quiet environment and silent zone used in the same areas shown in Figure 12 Words such as environment and zone are unnecessarily complicated particularly when the signs refer to the entire floor


Figure 12 A number of oldfashioned and unhelpful regulatory signs which were removed after the signage audit and subsequent analysis



Rather than regularly reminding users we decided instead to focus on the three access points to the silent flooran elevator a front stairwell and a rear stairwell This sign went through many iterations and library sweeps were conducted to evaluate the success of the signs by assessing noise levels A number of abandoned designs are shown in Figure 13 The final sign we decided on is seen as users arrive at the silent floor PSST This is a Silent Floor fig 14 Note that psst is used instead of shh its not a command but is more of a playful aside This is in fact an instructional sign but is enacted like a demonstrative sign which doesnt regulate users who are already following the rules A reflective silver color is used rather than black to prevent the sign from appearing too officious or confrontational Library staff have since noticed a marked decrease in noise levels after the signage was implemented


Figure 13 Ineffective noise level signs that were prototyped and tested The first sign in particular requires too much thinking and is unclear




Figure 14 Our final effective noise signage seen immediately upon reaching the silent floor






Informational

Informational signage need not only tell users about things that they are seeking information on but can also tell them things they may have never known about Figure 15 provides an example of communicating key information to library users at an appropriate time


Figure 15 Informational sign close to the group study rooms which is placed at a bump point where users might be wondering whether they can book a study room



The library foyer is an important first impression We found that this space was not being utilized appropriately with a range of signs not at eye level fig 16 A common challenge was conveying that the ground floor is actually Level 2 which is especially important when users need to move between levels Establishing the floor the users were in within the building whether they were entering or moving through the building was accomplished through large floor numbers installed near the front stairwell rear stairwell and near the elevator These are also colorcoded to create another layer of visual identification for users A directory has also been installed to the left of the stairs to allow students to orient themselves before moving to another floor shown in Figure 17


Figure 16 Library foyer before any signage work Directional signage is well above eye level and ignored by users Poster boards displaying promotions and events look oldfashioned and untidy




Figure 17 The library foyer as of early 2016 Two digital displays have been introduced at eye level showing todays library workshops informational as well as exhibitions and other promotions A directory board is seen on the lefthand side






Fun  Delightful

We propose a sixth category of signs which are those that do not serve a direct purpose in helping users to understand the library but rather reinforce a positive environment with humor and illustrate a culture of playfulness creativity and authenticity Chan Crosbie  Williams 2015 p 3 We saw this as a key aim of our audit and redesignwe wanted to be surprising and subvert users expectations of library signage Using humor where users may typically expect a harsh or even mean instruction engenders goodwill and gives users more confidence in using the library Furthermore incorporating humor into our signage allowed us to convey important information in a way that is fun rather than authoritarian 

A popular place for our studentsto sleep is in an informal bean bag area underneath a stairwell but most students did so with a guilty feeling as they did not really know why the bean bags were there The sign shown in Figure 18 was placed in the area to encourage and normalize sleeping in this designated space The implied meaning is that the space is in fact intended for users to sleep in and that this behavior is an acceptable use of the library In this example library anxiety is reduced by clarifying any uncertainty about the use of the space This sign has also been the subject of numerous mentions on social media channels where students have advised others that the library is a great place on campus to have a nap


Figure 18 This sign is a playful acknowledgment of a common user behavior



With the success of new signage to reduce noise levels on the librarys silent floor we decided to introduce a playful Shhhhhhhhhhh sign wrapped along the stairwell fig 19 This is not intended to be taken seriously but still serves as a useful reminder about the appropriate use of the silent floor


Figure 19 A playful take on a regulatory sign



The UTS Library has regular rotations of book displays and exhibitions We observed that students were not borrowing items from the collection that were on display despite many showing an interest and examining the books After speaking to a number of students we realized that students viewed the display as a static one rather than something that they could interact with and borrow from We included the sign Borrow the one you love fig 20 on our book display to encourage students to borrow directly from the display


Figure 20 Users are encouraged to pick up books from any of our displays and borrow them We change their location in the library catalogue to On Display to assist accessthis also allows us to evaluate how effective the display is as we can see the number of books that have been borrowed



Another project by UTS Librarys artistinresidence Chris Gaul saw our return chutes transformed into a playful and useful way for visitors to reflect on the books they have just finished reading Gaul 2013a The return chutes originally reflected three sets of call number ranges 000349 350650 and 651999 This seemed to users like we were making them do our work of sorting the returns however this sorting served no useful purpose as the items would then be mixed before being checked in The introduction of the labels in Figure 21 provided an unexpected moment of reflection for users returning materials


Figure 21 UTS Librarys return chutes Credit Chris Gaul



In summary all of our playful and delightful signage has made the library a fun place to visit and has improved the library user experience By using signage to convey our librarys personality we help to reinforce an image that is not authoritarian but rather userfocused and accessible Students have been receptive to these signs too as is evident from the dozens of photos posted by students to social media channels of all of our new signage



Conclusion

This paper demonstrates how the designthinking process can be utilized to guide the development of library signage as a key aspect of the library user experience Often neglected and poorly maintained library signage is an important touchpoint for users that can be made more useful and as we have argued offers an opportunity to reflect the librarys personality The examples throughout this paper are demonstrations of how we have addressed a number of issues experienced at UTS Library The design principles behind these solutions however are universal and can be applied to any library This approach simply requires a thoughtful focus on your users and their library experience when designing signage 

Acknowledgements

The authors thank the University Librarian Mal Booth and all the librarians and employees of the UTS Library at the University of Technology Sydney Australia for their contribution and support in various parts of the redesign mentioned in this article Specifically we would like to credit UTS Librarys 2012 artistinresidence Chris Gaul and inhouse designers Thomas Fethers Joanna Grygierczyk and Emily Gregory who have been responsible for the development of the librarys visual identity and brand

References

	Alhamdani W A 2016 Teaching cryptography using design thinking approach Journal of Applied Security Research 111 7889 httpdoiorg1010801936161020151069646

	Amiel T  Reeves T C 2008 Designbased research and educational technology Rethinking technology and the research agenda Journal of Educational Technology  Society 114 2940
	Asay M 2009 Shirky Problem is filter failure not info overload Retrieved June 29 2016 from httpwwwcnetcomaunewsshirkyproblemisfilterfailurenotinfooverload Archived by WebCite at httpwwwwebcitationorg6icSAGxUi
	Barclay D A  Scott E D 2012 Directions to library wayfinding American Libraries 4334 3638
	Booth M 2016 VALA events 2016 Technology alone isnt the answer you are looking for Retrieved April 3 2016 from httpwwwvalaorgauevents1078valaevents2016technology Archived by WebCite at httpwwwwebcitationorg6i0efLnHQ
	Booth M Schofield S  Tiffen B 2012 Change and our future at UTS library Its not just about technology Australian Academic  Research Libraries 431 3245 httpdoiorg101080019308262011531645

	Bosman E  Rusinek C 1997 Creating the userfriendly library by evaluating patron perception of signage Reference Services Review 251 7182 httpdoiorg10110800907329710306599

	Brown C R 2002 Interior design for libraries drawing on function and appeal Chicago ALA Editions  
	Carlile H 2007 The implications of library anxiety for academic reference services A review of literature Australian Academic  Research Libraries 382 129147 httpdoiorg10108000048623200710721282

	Chan H Crosbie J  Williams K 2015 The library as shapeshifter the new rules of engagement Retrieved April 3 2016 from httpinformationonlinealiaorgausitesdefaultfileslibraryasshapeshifter09jan15docx Archived by WebCite at httpwwwwebcitationorg6gUf9476p
	Coker S 1993 Libraries versus users How and how not to deter library users Library Management 142 2431 httpdoiorg101108EUM0000000000844

	Curedale R A 2013 Design thinking Processes and methods manual Topanga CA Design Community College Inc
	Gaul C 2013a Return chutes Retrieved April 3 2016 from httpchrisgaulnetworkslibraryreturnchutes Archived by WebCite at httpwwwwebcitationorg6gUfY99Zf
	Gaul C 2013b Shelf life Retrieved April 3 2016 from httpchrisgaulnetprojectsshelflife Archived by WebCite at httpwwwwebcitationorg6gUfeezfI
	Gibson J J 1979 The ecological approach to visual perception Boston Houghton Mifflin
	Given L M  Leckie G J 2003 Sweeping the library Mapping the social activity space of the public library Library  Information Science Research 254 365385 
	Godfrey K 2015 Creating a culture of usability Weave Journal of Library User Experience 13 httpdxdoiorg103998weave125356420001301

	Hahn J  Zitron L 2011 How firstyear students navigate the stacks Implications for improving wayfinding Reference  User Services Quarterly 511 2835
	Hasso Plattner Institute of Design 2013 An introduction to design thinking Retrieved April 3 2016 from httpsdschoolstanfordedusandboxgroupsdesignresourceswiki36873attachments74b3dModeGuideBOOTCAMP2010LpdfsessionID279d284171a07bdcd139c9e3dc82a73c8ce0f3aa Archived by WebCite at httpwwwwebcitationorg6gUg0MvIX
	Li R  Klippel A 2012 Wayfinding in libraries Can problems be predicted Journal of Map  Geography Libraries 81 2138 httpdoiorg101080154203532011622456

	Maier J R A Fadel G M  Battisto D G 2009 An affordancebased approach to architectural theory design and practice Design Studies 304 393414 httpdoiorg101016jdestud200901002

	Martin B  Hanington B 2012 Universal methods of design 100 ways to research complex problems develop innovative ideas and design effective solutions Beverly MA Rockport Publishers
	McPherson M A 2015 Library anxiety among university students A survey IFLA Journal 414 317325 httpdoiorg1011770340035215603993

	Mollerup P 2005 Wayshowing A guide to environmental signage principles  practices Baden Switzerland Lars Müller Publishers
	Mollerup P 2013 Wayshowing  wayfinding Basic  Interactive Amsterdam BIS Publishers
	Peake D G  Wilschefski W A 1989 A history of library services at the University of Technology Sydney Sydney Australia
	Polger M A  Stempler A F 2014 Out with the old in with the new Best practices for replacing library signage Public Services Quarterly 102 6795 httpdoiorg101080152289592014904210

	Ranganathan S R 1931 The five laws of library science Madras The Madras Library Association Retrieved from httpcataloghathitrustorgRecord001661182

	Razzouk R  Shute V 2012 What is design thinking and why is it important Review of Educational Research 823 330348 httpdoiorg1031020034654312457429

	Schmidt A 2010 Touch points and testing Library Journal 1358 20
	Schmidt A 2015 The user experience Positive signs Library Journal 14014 25
	Schmidt A  Etches A 2014 Useful usable desirable Applying user experience design to your library Chicago American Library Association
	Serfass M 2012 The signs they are achangin Is it time to give your librarys signage a makeover AALL Spectrum 169 56
	Stempler A F 2013 Navigating circular library stacks A case study on signage Reference Services Review 413 503513 httpdoiorg101108RSR0220130006

	Stempler A F  Polger M A 2013 Do you see the signs Evaluating language branding and design in a library signage audit Public Services Quarterly 92 121135 httpdoiorg101080152289592013785881

	Tiffen B  England A 2011 Engaging with clients and personalising services at UTS Library Measuring the value for libraries and their clients Australian Library Journal 603 237247
	UTS Library 2016 Printing Retrieved April 3 2016 from httpwwwlibutseduaufacilitiesprinting Archived by WebCite at httpwwwwebcitationorg6gUflapvf
	Wakimoto D K 2015 Librarians and graphic design Preparation roles and desired support Public Services Quarterly 113 171182 httpdoiorg1010801522895920151054545

	White L L 2010 Better none than bad American Libraries 418 23
	Woodward J A 2004 Creating the customerdriven library Building on the bookstore model Chicago ALA Editions


Notes



	This measure was borrowed from Abby Coverts Information Architecture Heuristics httpabbytheiacomwordpresswpcontentuploads201204posterreadablejpg






Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS






















































A Novel Technique for AB Testing Using Static Prototypes


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










A Novel Technique for AB Testing Using Static Prototypes




Scott Goldstein

APPALACHIAN STATE UNIVERSITY



Skip other details including permanent urls DOI citation information
Volume 2 Issue 1 2019



DOI httpdxdoiorg103998weave125356420002101



Creative Commons 40 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 40 International License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	














Abstract



AB testing is a powerful technique for evaluating the success of a specific design element but it is not yet widely adopted among library user experience professionals Many libraries cannot or choose not to do AB testing on a live website for a variety of practical reasons Appalachian State University Libraries recently piloted a variety of AB testing that has the potential to address some of these shortcomings a Qualtrics survey of tasks carried out on static prototype websites embedded into the survey as inline frames The technique allowed us to capture qualitative data in the form of survey questions and link it to quantitative server data typical in live AB tests Prototype AB testing allowed us to reap the benefits of AB testing without needing to modify a production server environment Based on our findings from a large sample of undergraduate and graduate students we were able to justify a postmigration design choice



This paper was refereed by Weaves peer reviewers


Introduction

AB testing is a research methodology for evaluating an isolatable design element of a product or service At its core AB testing also referred to as split testing or multivariate testing involves presenting users with versions of an interface differing in only one respect the independent variable and collecting data on performance metrics dependent variables to determine which version outperforms the others AB testing has become a staple in the UX community as companies perpetually test and make changes to their online presence It is a powerful datadriven technique to improve how users interact with systems In the context of libraries however its adoption has been complicated by scale 

Generally speaking libraries have not been able to successfully split a service and gather data from the entire user population A recent and notable exception is Young 2014 who describes how Montana State University leveraged Google Experiments to test which word best approximated students mental model for getting information on research services Focusing on library websites in particular there are some barriers to conducting such a largescale split test Many libraries do not have direct access to a production server or lack the wherewithal to set up a test in the appropriate software In addition AB testing could interfere with librarians who teach or create elearning resources based on the current version of the website Obradovich Canuel  Duffy 2015 found that over 70 percent of Canadian Association of Research Libraries and Association of Research Libraries member institutions that provide instructional videos on their library website feature content on using a library catalog discovery tool or specific databases As many of these videos likely use the library homepage as a starting point it could confuse viewers to encounter a version of the website different from the one seen in the video What many libraries have done is adopt the basic principle of AB testing but conduct it on a much smaller scale typically with a tiny subset of users Instead of collecting inthewild data they sit the user down and observe a common task the user might perform on the website And instead of comparing against live variations of the website they rely on a surrogate or prototype website for variations from the live control This kind of AB testing is known as prototype AB testing and is common in web development projects outside of libraries Frome  Cohn 2015

Appalachian State University Libraries recently performed a prototype AB test of the library website that scaled to a level more typical of a live AB test giving us data from more than a hundred users The technique we used offers libraries the potential for performing larger scale AB testing while avoiding many of the problems noted above We accomplished this by inserting the prototype AB test inside an electronic survey sent out to a large number of students The survey consisted of tasks to be carried out on a static prototype website embedded as an inline frame or iframe Our setup allowed us to track two kinds of data qualitative selfreported data in the form of survey questions similar to what is collected in facetoface usability tests and quantitative data associated with live AB tests such as what pages were visited and for how long Best of all the two kinds of data were not disparate but we were able to be joined together allowing us to see how reliable each measure was when compared with the other This method relies on standard survey software and a class of software known as static site generators and it requires only a sandbox server As no changes need to be made to a live site libraries may find this a more feasible approach to AB testing This paper will walk through the process of what issue we tested how the test was set up and how data was extracted and analyzed to inform our decision

Literature Review

AB testing has been a staple in product development for the past fifty years Large tech companies such as Google and Facebook continuously experiment with website and app features to gather data on what their user base prefers As Youngs 2014 article points out the literature on AB testing is extensive in fields such as computer science and marketing but essentially nonexistent in library science However librarians are clearly thinking about the same kinds of usercentered design considerations especially given the large emphasis placed on website usability studies

Prototyping like AB testing is an integral part of the design process It can be used in different stages of the process but is often used early to test features without having to create a functional final product Prototypes can range from lowfidelity paper mockups to highfidelity themed websites Some prototypes have little to no functionality and are used very early in the brainstorming phase while others have enough functionality to test relevant aspects of the user interaction albeit with some imagination required on the part of the test participant For example one can make interactive paper prototypes by having a human computer process a users tap when an element is tapped the sheets of paper are rearranged thereby representing the response of the system Facilitators occasionally need to explain to users that some expected responses could be nonfunctional and ask them to make believe Pernice 2016 The literature on using website prototypes in the library setting is somewhat sparse but representative studies have many commonalities including recruiting a small number of participants and comparing task performance between a prototype website and a current website Ellis and Callahan 2012 discuss prototyping in the context of reimagining how online finding aids are organized They tested users with a Bootstrapbased prototype to see how they would interact with an atomizedcomponents approach to viewing archival content Other examples are more straightforwardly AB testing using prototypes Swanson Hayes Kolan Hand and Miller 2017 Dougan and Fulton 2009 and Reynolds 2008 used prototype websites in the course of usability testing their library websites Metrics ranging from the total time on task task completion the path of webpages taken think aloud comments and selfreported ratings all showed that the prototype outperformed the current website

In recent years prototyping has been aided with the introduction of a set of tools called static site generators A static site generator is a web development program that resides on the developers local machine rather than on a server It allows the developer to arrange website content and systematize how it interacts with other aspects of a website such as site layouts and CSS assets The website can then be compiled generating a complete and selfcontained static website that is ready to be uploaded to any server As the website only contains HTML CSS and JavaScript it might be asked what is gained by working with this software The fact is static site generators have found a wide audience owing to their many advantages over larger content management systems such as Wordpress or Drupal For example static websites load faster have fewer security vulnerabilities and are easier to preserve and version that is save a snapshot at a particular time For websites that are smaller or lack the need for complex databasedriven interactive features static websites are a viable and increasingly preferred option Newson 2017 describes how the Ontario Historical Topographic Maps Digitization Project website was developed using Hugo a Gobased static site generator Diaz 2018 describes how Northwestern University Libraries used Jekyll perhaps the most popular static site generator currently to publish conference proceedings and an open educational resource Outside of libraries static site generators are commonly used in the design process to create static mockups

Surveys are frequently used as a research methodology within libraries and are almost certainly the most common data collection method in the field Halpern Eaker Jackson  Bouquin 2015 They are helpful for gathering data about the experience opinions and attitudes of library users staff and other stakeholders Survey research is typically contrasted with experimental research although it is possible to manipulate variables in socalled survey experiments Surveys implemented in library contexts usually adopt a purely descriptive form but other creative uses have been tried with some success For example Symonds 2011 describes how survey software can also be used as a remote asynchronous usability testing tool Symonds and her colleagues used SurveyMonkey to disseminate both a link to a website and a series of tasks on that website that respondents were to complete After completing each task they were instructed to answer questions that could be used to assess how usable the website was

The methodology described in this article builds off Symonds 2011 by combining a descriptive electronic survey with an interaction with a randomly assigned prototype website We arrived at this approach mostly as a natural extension of our experience with the two featured software tools electronic surveys and static site generators In particular we knew our preferred survey tool Qualtrics was capable of displaying and capturing much more information than we had had the need for in previous surveys Around this same time we were using static prototypes to mock up ideas during our website redesign process Merging the two methods struck us not only as an interesting technology challenge but an opportunity to glean the benefits of having rich qualitative survey data with quantitative server log data The latter would allow us to determine which pages respondents visited and how much time was spent on each page By itself this information is informative but combined with user feedback it provides us with some insight as to why users did what they did

Methodology

The AB testing discussed in this article occurred after Appalachian State Universitys main library website was redesigned and migrated to a new Drupal theme in August 2017 Leading up to the launch members of the librarys Web Content Committee had conducted an electronic survey which included an open and closed card sort implemented with the Pick Group and Rank question type in Qualtrics Card sort data indicated there was a need to better organize our content relating to our spaces Previously information on the website relating to our rooms and spaces was situated in the Services menu item However from our card sort we realized that this type of content would be better categorized in a standalone section of the website In addition the library had been undergoing a major space renovation More space for students was being created the Writing Center was relocating to another floor and other spaces such as our makerspace and video recording room were being created or expanded A Rooms  Spaces menu item was seen as an important design decision to better inform our users of the changes taking place in the building

When the website was launched we had put our building floor maps as the landing page to this new section as it seemed at first glance to be the conceptually obvious choice Our previous card sorting tests however had not specifically looked at where users expect to find a map of the building The floor maps had been in the About section of our website prior to the migration and a scan of other library websites indicated that this was a common location We realized we lacked a datadriven rationale for our decision and began looking into ways to test this with our users Since we were interested in testing two specific and definable options  ie floor maps under About versus floor maps under Rooms  Spaces  we opted to conduct an AB test

The prototypes were built in a static site generator called Sculpin We chose Sculpin because it was developed in a programming language PHP we use for our own projects However nearly any static site generator would have been adequate for our purpose To create the base theme for the static prototype we simply asked our colleagues in Web Services if they could provide the flat filesHTML CSS JavaScript and imagesthat together made up the template of the Drupal site This is typically an easy request because many custom themes are created and refined first as static HTML before being converted into a form the content management system can handle However if these files are not readily available they can be always be recreated though it will require some extra work 

The Web Services department provided us with a single HTML file that contained links to all the required assets on a central server This HTML file served as the basis of our Sculpin theme We inserted snippets of Twig code which is the templating language Sculpin uses to tell Sculpin where to put our page title and page content Then we manually created all the sites pages Fortunately for most pages this was simply a matter of copying and pasting the source code from our live Drupal site and making some minor adjustments such as removing Drupalspecific HTML code

We created two versions of our prototype website One situated our floor maps page under About where it had been prior to our migration and the other located it under Rooms  Spaces where the page currently existed The sites were deployed to one of the librarys sandbox servers Since the websites were entirely static it was not necessary to install or configure any specialized software to get the sites to run However there were two specific requirements for the server setup First server logging in Common Log Format needed to be enabled to capture the respondents browsing activity Second SSL needed to be enabled in order for the website to be embedded as an iframe in the Qualtrics survey software

Qualtrics was the mechanism through which we recruited participants but it also enabled us to link together the survey data with data from the browsing session While we could have used IP addresses or a service like Google Analytics to achieve the same thing we wanted to keep the survey truly anonymous This was important to us because if respondents could be identified we would be obligated to provide information on how their session was being tracked which might have affected the response rate or the informality we were trying to convey as they approached the tasks The nature of our project was such that it was limited in scope to gathering data about Appalachian State University users As that data could not generalize to other populations it was not subject to human subjects review However those wishing to utilize a technique like the one described would be wise to consult with their Institutional Review Board chair or administrator For details on how we associated a respondents survey with his or her browsing activity see the Appendix

The static websites generated were highfidelity functional prototypes See the prototype homepage in figure 1 However there were a number of features that one would expect on a dynamic library website that could not be replicated on the prototypes and so we were forced to compromise First in areas where the content was too complex to be worth rendering in Sculpin we left it out or replaced it with a shaded box This informed the user what should have been there but was not fleshed out in detail For example we did not list detailed information on every one of our databases Since none of these features were crucial for the tasks users were to complete this was seen as an acceptable compromise although even here we cannot rule out the possibility that this biased some user interactions Second we wanted to track just about everything a user did or encountered on the site in our server log On a real library website however with links and forms directing users to databases catalogs and other thirdparty sites it is unlikely that the totality of interactions would be captured in a single place Furthermore as we were only testing our website we did not want to allow our users to leave even accidentally Our solution was to lock down external sites For each outbound link or form submission we redirected users to a single page called 404 as shown in figure 2 The page captured what link was clicked or what query was submitted and displayed this to the user along with an explanation for the atypical behavior and access to a Back link This is no doubt a stark case of asking the user to make believe for the purpose of a test but we felt this was probably the smoothest way to handle this limitation To confirm this we did some inperson pretesting of the prototype website with students we found in the library We simply asked them to complete some tasks that we knew would lead them to this explanation page Based on observations and talking with them afterwards we believed the page was sufficiently clear and not unacceptably disruptive


Figure 1 Prototype homepage




Figure 2 Workaround for outbound links



The survey had a few sections First an introductory section explained the purpose of the survey provided brief instructions on what they would encounter and what they were to do and obtained informed consent Next the survey software randomly chose one of two paths corresponding to the assignment of either the A website or the B website The task question consisted of three parts 1 a brief description of the task 2 the prototype website loaded directly underneath it in an iframe and 3 a Likerttype question that asked how easy the task was to complete if it could be completed at all This last question was a slight modification of the Single Ease Question and represents a simple way to gather data on perceived usability Laubheimer 2018 After the task question we included a general openended feedback question before ending the survey See figure 3 for a screenshot of the first section of the survey We chose a task that we hoped would get our users searching for floor maps of the building You were told to meet up with your study group in room 303 of the library but you have no idea where this is Find out where exactly this room is in the library


Figure 3 Prototype website loaded in iframe beneath task description



We collected a total of four pieces of data In addition to the Single Ease Question we collected the total elapsed time on task measured in seconds the path length or total number of page loads needed to complete the task and the final page that was loaded which could be used to determine whether the respondent successfully completed the task All this data came from analysis of the server logs using the R programming language see the Appendix for sample code

The survey was launched on November 1 2017 To generate our contacts list we used a previously downloaded full population list of students currently enrolled at the university If a directory list of students is not easily accessible at your institution consider talking with your office of institutional research as they may be able to provide a full or partial list of student email addresses We randomly sampled 4500 students using the R programming language and sent them invitations to participate A reminder email was sent to nonresponders two weeks later and the survey was closed on November 30 2017 No incentives were used

Analysis

Before doing any analysis the data first needed to be cleaned Three types of respondents were excluded from the analysis First we excluded any respondent who did not finish the survey which is simply anyone who did not click through to the end and submit the survey on the final screen This removed 130 responses Second we excluded respondents who did not engage at all with the prototype which we defined as anyone who did not navigate beyond the landing page Given that our task could not reasonably be attempted without leaving the homepage we felt this decision was justified This excluded twentyfive responses Third we excluded extreme outliers with respect to time on task Our goal was to have these tasks completed in a single uninterrupted sitting we wanted to exclude users who became distracted with other things on their computer or device and came back to the task much later when it was no longer fresh as this would significantly overestimate the time needed This excluded one response that took over nine hours to complete the survey

Out of 130 valid respondents 67 had been randomly assigned by Qualtrics to interact with the prototype featuring floor maps under About while 63 had been assigned to the prototype featuring floor maps under Rooms  Spaces These sample sizes are significantly higher than anything we could have achieved with inperson usability testing which typically rely on as few as five and as many as twenty users Beck  Manuel 2008 Small sample sizes in usability testing are justifiable but only for problem discovery they are inappropriately underpowered to draw conclusions about which of several interfaces performs best according to some metric Nielsen 2006

The data for each condition are summarized in the table below Only 31 percent of respondents ended the task on the correct page when floor maps were featured under the About page A large number instead navigated to the page on group study rooms which is a comprehensive source of information about our rooms except that it lacks a map of their location in the building Since room numbers are listed on this page it is at least arguable whether it provides the necessary information to complete the original task so the 31 percent may be an underestimate By contrast 83 percent of respondents correctly navigated to Rooms  Spaces in the other prototype website This was clear evidence that users expected to find information about locations inside the building on this page Not surprisingly users perceived the task as easier when they found the information available on this page

Table 1 Survey results

		
Percent rated somewhat or very easy

	
Percent successfully completed task

	
Median time on task in seconds

	
Median path length in page loads


	
About

	
62

	
31

	
37

	
3


	
Rooms  Spaces

	
93

	
83

	
18

	
2




The other metrics we collected time on task and path length showed significant differences between the two conditions When floor maps were featured under the About page respondents took longer to complete the task and required browsing through more pages These two metrics are represented as histograms in figures 47 Note that they are rightskewed meaning most of the data points are at lower values unlike a bellshaped normal distribution To determine if the two groups were statistically different we used a MannWhitney test which does not assume that the data come from a normal distribution This test confirmed that the differences between the two conditions were statistically significant across both metrics


Figure 4 Histogram of time on task About  Floor Maps version




Figure 5 Histogram of time on task Rooms  Spaces version




Figure 6 Histogram of path length About  Floor Maps version




Figure 7 Histogram of path length Rooms  Spaces version



Conclusions

AB testing allowed our library to confirm that a design choice implemented with less than desirable forethought was not a major source of confusion to our users This would have been difficult to determine using any other single means AB testing was the most efficient methodology because two interfaces immediately suggested themselves given the context of the problem Furthermore with sample sizes of more than sixty per interface we were able to make statistically valid conclusions something that would be impossible if we were only able to recruit half a dozen users as is typical in usability testing scenarios This is an important consideration for librarians and information professionals who often rely on small sample sizes to arrive at their conclusions As Laubheimer 2018 points out Numeric data from five users should not inform design decisions and reporting numbers collected with such a small sample is highly misleading

By the same token AB testing like any other research methodology should not be relied upon in isolation but should be triangulated with other approaches As an example the openended freetext responses that we collected as the final survey question while very helpful do not come close to capturing the nuanced reactions that are observed in a facetoface usability test nor could we probe with followup questions to elicit further thoughts and feelings Others may wish to extend this method by soliciting more data from the respondent such as class year major and degree of familiarity with the library website That data was not analyzed in our test and may have been relevant Perhaps heavy users of the library website expected to find floor maps of the building in its old spot to a greater degree than light users It may also be worthwhile to compare the effectiveness of live AB testing to prototype AB testing

References

	Beck S E  Manuel K 2008 Practical research methods for librarians and information professionals New York NealSchuman
	Diaz C 2018 Using static site generators for scholarly publications and open educational resources Code4Lib Journal 42 Retrieved from httpsjournalcode4liborgarticles13861

	Dougan K  Fulton C 2009 Side by side What a comparative usability study told us about a web site redesign Journal of Web Librarianship 33 217237 doi10108019322900903113407
	Ellis S  Callahan M 2012 Prototyping as a process for improved user experience with library and archives websites Code4Lib Journal 18 Retrieved from httpsjournalcode4liborgarticles7394

	Frome N  Cohn S 2015 February How split testing validates new product concepts without code UX Magazine Retrieved from httpuxmagcomarticleshowsplittestingvalidatesnewproductconceptswithoutcode

	Halpern R Eaker C Jackson J  Bouquin D 2015 DitchTheSurvey Expanding methodological diversity in LIS research In the Library with the Lead Pipe Retrieved from httpwwwinthelibrarywiththeleadpipeorg2015ditchthesurveyexpandingmethodologicaldiversityinlisresearch

	Laubheimer P 2018 Beyond the NPS Measuring perceived usability with the SUS NASATLX and the Single Ease Question after tasks and usability tests Retrieved from httpswwwnngroupcomarticlesmeasuringperceivedusability

	Newson K 2017 Tools and workflows for collaborating on static web projects Code4Lib Journal 38 Retrieved from httpsjournalcode4liborgarticles12779

	Nielsen J 2006 Quantitative studies How many users to test Retrieved from httpswwwnngroupcomarticlesquantitativestudieshowmanyusers

	Obradovich A Canuel R  Duffy E P 2015 A survey of online library tutorials Guiding instructional video creation to use in flipped classrooms Journal of Academic Librarianship 416 751757 doi101016jacalib201508006
	Pernice K 2016 UX prototypes Low fidelity vs high fidelity Retrieved from httpswwwnngroupcomarticlesuxprototypehilofidelity

	Reynolds E 2008 The secret to patroncentered web design Cheap easy and powerful usability techniques Computers in Libraries 286 647
	Swanson T A Hayes T Kolan J Hand K  Miller S 2017 Guiding choices Implementing a library website usability study References Services Review 453 359367 doi101108RSR1120160080
	Symonds E 2011 A practical application of SurveyMonkey as a remote usabilitytesting tool Library Hi Tech 293 436445 doi10110807378831111174404
	Young S W H 2014 Improving library user experience with AB testing Principles and process Weave Journal of Library User Experience 11 doi103998weave125356420001101


Appendix

Qualtrics has an internal ResponseID rID variable that it associates with each survey This identifier is both unique and anonymous making it an ideal primary key to join together the Qualtrics and server log data The rID was simply passed to the respondents browsing session through a query string and subsequently passed around as they navigated the prototype website A query string is a part of a URL that contains extra information in the form of a fieldvalue pair It would therefore be captured in the resource field of the server log We designated a field called r that held the respondents rID and question number in the survey concatenated together with an underscore For example if a respondents rID was R123 and she were interacting with a prototype on question 1 r would be set to R123Q1 This field was initially set directly in the src attribute of the iframe In Qualtrics the HTML source of the iframe would appear as

iframe srchttpsabtestlibraryappstateeduvarareFieldResponseIDQ1iframe

We also needed a way to carry this information across a session as the respondent clicked on links to other pages otherwise the query string would not persist and the trail would be lost This was accomplished with some custom JavaScript coding that altered all links to include the fieldvalue pair currently in the URL For example if the URL were currently httpsabtestlibraryappstateeduvaraaboutrR123Q1  then all links on the page would have rR123Q1 appended to the href attributes value



  Code created with the help of Stack Overflow question

  httpsstackoverflowcomquestions901115howcanigetquerystringvaluesinjavascript

  Question by Deleplace

  httpsstackoverflowcomusers871134deleplace

  Answer by Code Spy

  httpsstackoverflowcomusers1045296codespy

 
 

function getParameterByNamename 

   var url  windowlocationhref

   name  namereplaceg 

   var regex  new RegExp  name  

      results  regexexecurl

   if results return null

   if results2 return 

   return decodeURIComponentresults2replaceg  





function trackRespondentID 

   var serverName  httpsabtestlibraryappstateedu

   var anchors  documentgetElementsByTagNamea

   for var i  0 i  anchorslength i 

      if anchorsihrefsubstr0 serverNamelength  serverName  anchorsihasAttributerole 

        anchorsihref  anchorsihref  r  getParameterByNamer

       else if anchorsihrefsubstr0 serverNamelength  serverName 

       anchorsihref   siteurl 404linkClicked  encodeURIComponentanchorsitextContent  r  getParameterByNamer

     

  

   var forms  documentgetElementsByTagNameform

   for var i  0 i  formslength i 

      if formsiactionsubstr0 serverNamelength  serverName 

        var input  documentcreateElementINPUT

        var typeAttribute  documentcreateAttributetype

        typeAttributevalue  hidden

        inputsetAttributeNodetypeAttribute

        var nameAttribute  documentcreateAttributename

        nameAttributevalue  r

        inputsetAttributeNodenameAttribute

        var valueAttribute  documentcreateAttributevalue

        valueAttributevalue  getParameterByNamer

        inputsetAttributeNodevalueAttribute

        formsiappendChildinput

     

  

   on the 404 page include an empty element with an ID of msg

  if getParameterByNametabClicked  null 

     documentgetElementByIdmsginnerHTML  Well well just have to empretendem that you did a search for   getParameterByNameq   in a form named   getParameterByNametabClicked  

  

   if getParameterByNamelinkClicked  null 

     documentgetElementByIdmsginnerHTML  Well well just have to empretendem that you clicked a link called   getParameterByNamelinkClicked  

   




documentaddEventListenerDOMContentLoaded functionevent 

   if getParameterByNamer  null 

      trackRespondentID

   






The following R code provides a sample of how to merge data from a Qualtrics CSV with server log data in Common Log Format

 read in data from csv files

qualtricsdf  readcsvsurveydatacsv nastrings  12 

serverlogdf  readcsvserverlogdatacsv header  FALSE sep    stringsAsFactors  FALSE

 convert datetime to POSIXlt object

serverlogdfV4  paste0serverlogdfV4 serverlogdfV5

serverlogdfV4  asPOSIXltserverlogdfV4 format  dbYHMSz

 filter data containing relevant ResponseIDs

respondentlog  serverlogdfgreppaste0qualtricsdfResponseId collapse   serverlogdfV6 

 filter just the resource requested

requests  lapplyrespondentlogV6 strsplit split    fixed  TRUE

respondentlogresource  sapplyunlistrequests recursive  FALSE  2

 clean up column names

respondentlogc2 3 5 6  listNULL

colnamesrespondentlog  cremoteaddr timelocal status bodybytessent httpreferer httpuseragent resource

 list all combinations of ResponseID and questions of interest

expandeddf  expandgridResponseId  qualtricsdfResponseId task  colnamesqualtricsdf510

 create columns for metrics and fill with NAs

expandeddf pathaslist  NA

expandeddf pathlength  NA

expandeddf timeontask  NA

for row in rownamesexpandeddf 

    if the respondentquestion pair exists

   taskset  grepsprintfss expandeddfrow 1 expandeddfrow 2 respondentlogresource fixed  TRUE

   if lengthtaskset 

      expandeddfrow pathaslist1  listrespondentlogtaskset resource

       pathlength is calculated by counting the total number of pages loaded

      expandeddfrow pathlength  lengthtaskset

       timeontask is calculated by subtracting the datetime of the first page load from the datetime of the last page load

      expandeddfrow timeontask  asnumericdifftimerespondentlogtailtaskset n  1 timelocal respondentlogtaskset1 timelocal units  secs

   



 remove all rows with NA

expandeddf  naomitexpandeddf

 join the data frames on ResponseID

mergeddf  mergequaltricsdf expandeddf







Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS






















































How Much Research is Enough


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










How Much Research is Enough




Susanna Galbraith

MCMASTER UNIVERSITY



Skip other details including permanent urls DOI citation information
Volume 1 Issue 7 2017



DOI httpdxdoiorg103998weave125356420001702



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













Introduction

In an earlier issue of Weave Emily Mitchell and Brandon West 2016 described a number of lowbarrier solutions for getting UX insights when making design decisions And while this is useful what do you do when thats not enough for stakeholder buyin Or vice versa what if you are expected to conduct a rigorous research study yet dont believe rigor necessary to make design decisions

 

Often the quick and dirty is regarded with skepticism On the other hand more intensive research is too timeconsuming and not always necessary when the goal is selecting a label for a dropdown menu 

Erika Halls insightful book Just Enough Research 2013 has helped me work through some of these juxtapositions and could be valuable to fellow librarians In this article I summarize key points from Halls book that I found useful in the context of user experience in libraries If youre looking for something practical as implied in this articles title Ive also supplied a few scenarios with suggested research techniques Youll notice that my scenarios are strictly online or interface focused as thats the only user experience work Ive been involved with If youre looking for the application of research techniques to physical spaces or administrative structures you wont find it here 

 

Just Enough Research

In her book Hall distinguishes between pure research applied research and design research Pure research is carried out to create new human knowledge whether to uncover new facts or fundamental principles Hall 2013 p 12 When we take this definition and apply it to user experience in libraries studies looking at cutting edge new interfaces for library catalogs or the beginnings of the first digital collection could fit into this category Even more broadly ethnographic research that seeks to understand informationseeking behavior in the academic context would be pure research 

 

Hall separates pure research from applied research Applied research borrows ideas and techniques from pure research to serve a specific realworld goal p 12 An example of applied research is a designer working on building a library interface who uses the pure research of the Nielsen Norman Group as a starting point The Nielsen Norman Group has supplied us with wellknown usability principles such as when writing for the web less is more Nielsen 2011 Recently through their evidencebased research theyve found that commonly used hamburger menus are not as usable as was initially thought Pernice  Budiu 2016 Applying general usability principles and design conventions is undoubtedly useful Conducting pure research within our libraries to learn the uniqueness of their contexts is an ideal worth striving for but we need to use the applied research to make change in libraries 

Halls design research is a unique form of applied research specifically for making design decisions Design research is for gathering useful insights Hall 2013 p13 An example could be taking the pure research done on the first prototype of a discovery layer and applying it to some of our design decisions While useful and easily accessible its a less rigorous form of research than doing research on a specific context in which other research cannot be applied A common argument in opposition to design research in libraries is but we already know all of this As Hall helpfully explains a good counterargument is Unless this knowledge comes from recent inquiry specific to your current goals a fresh look will be helpful Familiarity breeds assumptions and blind spots p 26

 

For me the value in making the distinction between pure research applied research and design research is to bring validity and credibility to UX research within librarianship which is looked at skeptically and not always understood My hope is that by acknowledging the limited role of design research and distinguishing it from pure research we can increase buyin In order to maintain support from colleagues who are unaccustomed to user experience research clarifying the role and scope of our proposed research is essential

 

Anthropologists Donna Lanclos and Andrew Asher 2016 argue that constructing longterm views of student behavior gained via ethnography is good and necessary practice for effective engaged and innovative libraries and indeed education generally It is an ideal worth striving for and I agree pure ethnography should be done to inform highlevel administrative decisions We need advocates to push for more ethnography to support the future of libraries in a quickly shifting landscape But Andrew Priestner 2017 responded the goal of user experience work as I see it is not a purity of methods but a balancing of these methods with a practical effectiveness of outcomes

Research Rigor

So if we want to ensure were representing our users needs we need to ensure a level of rigor in our quick and dirty methods Design research may be less rigorous than the alternative types but some rigor is still important to reduce bias As Hall 2013 p 3335 outlines there are a number of biases to look out for Sampling bias interviewer bias and social desirability bias are the most difficult to avoid in user experience research within libraries


Sampling Bias

Most librarians should be aware of sampling bias from their graduate school coursework According to Wikipedia it is a bias in which a sample is collected in such a way that some members of the intended population are less likely to be included than others Sampling bias 2017 Hall says that sampling bias is almost unavoidable in quick and dirty qualitative research 2013 p 34 But as she points out this can always be countered by being mindful in the general conclusions you draw p 34 If were designing a LibGuide for undergraduate students and only have graduate students available to do a few quick usability tests pointing out the potential limitations of this usability test helps counter the bias However aiming to reduce sampling bias as much as possible will bring more valuable results




Interviewer Bias

Hall describes interview bias as inserting ones own opinion into an interview Hall 2013 p 34 This can be a particularly tricky bias to overcome An example of interviewer bias would be to ask during an interview how do you use the library catalog implying that the user does in fact use the catalog or even knows what that word means 




Social Desirability Bias

Hall points out that it can be hard to admit to an interviewer that you dont know what certain terminology is p 35 Students faculty members or other users may not admit that they dont know what a library catalog or a subject heading is This is called social desirability bias One technique for helping to reduce this bias is to emphasize the need for honesty and promise confidentiality Hall 2013 p35 



What Should You Do

Amanda Etches and Aaron Schmidt summarized many different research methods applied to specific libraryrelated situations in their book Useful Usable Desirable 2014 They describe twelve research methods with key strengths and example use cases  

	
Surveys Ask questions about attitudes and opinions not behavior Example usage Ensuring users are receiving assistance on the website when and where they need it
	
Focus groups Aim for unique opinions and inclusion Example usage Ensuring website searches of online collections are relevant to member needs

	
User interviews Good for gathering info about attitude and behavior Example usage Ensuring library web services solve problems
	
Contextual inquiry Observing users completing a task Example usage Ensuring the website supports diverse behaviors 
	
Journey mapping Identify specific touch points that cause friction Example usage Ensuring firsttime visitors can easily locate all parts of the website 
	
Usability testing Testing online environments to see what works and what doesnt Example usage Ensuring users can easily accomplish critical tasks 
	
Cultural probes Provide a way to collect data over an extended period of time Example usage Ensuring services are consistent across the organization 
	
Card sorts Help determine a site architecture and navigation Example usage Ensuring the website is easy to navigate 
	
AB testing Comparing two versions of a design Example usage Developing a homepage with two different search boxes 
	
Personas Ensure everything you do is designed in a usercentered way Example usage Ensuring marketing materials are relevant to user needs 
	
Fivesecond tests To determine what elements on a web page stand out the most Example usage Ensuring the homepage clearly expresses what people can do on your site 
	
Content audit Helps you take stock of whats on your website and allows you to do some useful assessment Example usage Ensuring that web content is engaging 


Combining Etches and Schmidts research methods with Halls perspective on bias below Ive described four common library UX scenarios where you could apply these techniques These recommendations are based partially on my own experience using some of these research techniques ie usability tests user interviews journey mapping surveys and card sorts in my role as virtual services librarian The scenarios themselves dont come from personal experience but are instead situations I imagine to be quite common in academic library contexts My assessments of each technique and recommendations are subjective 




Scenario 1 Adjusting the label on a new library discovery system search box


The Setup

You have a short timeline to complete this task approximately one month Youre not solely a UX librarian you have multiple other responsibilities such as working on the reference desk and teaching classes But you want to ensure your users have a positive experience searching the librarys resources A working group has been pulled together to refine the usability of the new discovery system and the group has decided to call it Discovery Search 




The Problem

Will the search results created when executing a search of the discovery system match the user expectations for a Discovery Search results list If not will this create frustration for users




Recommended Research Techniques

	Techniques	Resource and time intensive	Bias	Credibility buyIn
	Usability tests	Somewhat	Sampling bias social desirability bias	Medium
	AB testing	Somewhat depends on sample size and tools used	Sampling bias	High if high sample







Scenario 2 Preliminary exploratory research prior to implementing a new Digital Collection


The Setup

Your team is in the early stages of establishing a new Digital Rare Book Collection Youd like to learn more about the context in which faculty researchers and the public will use this tool and how it will integrate into their daytoday activities You have good support for doing this research and a long timeline is expected to successfully meet your goal 




The Problem

Will the new digital collection meet the diverse needs of the end users




Recommended Research Techniques

	Techniques	Resource and time intensive	Bias	Credibility buyIn
	Contextual inquiry	Yes	Sampling bias	Medium
	User interviews	Yes	Social desirability bias interviewer bias sampling bias	Medium
	Focus groups	Yes	Social Desirability Bias Interviewer Bias Sampling Bias	Medium







Scenario 3 Determining the most critical tasks on a large university library website homepage


The Setup

Your librarys website has built up a large collection of links images and content that make the page very busy and potentially overwhelming Stakeholders are continually requesting new content be added to the homepage Youd like to identify the websites top five critical tasks to use as a boundary for what should be included on the homepage 




The Problem

To determine the top five critical tasks across all user groups when using your librarys website 




Recommended Research Techniques

	Techniques	Resource and time intensive	Bias	Credibility buyIn
	Survey	Somewhat depends on rigor of methodology	Sampling bias	High depends on rigor of analysis and sample size
	Cultural probes	Yes	Social desirability bias interviewer bias	High







Scenario 4 Evaluating LibGuides for firstyear undergraduate students


The Setup

Youre a librarian whos created a suite of information literacy LibGuides and tutorials targeting firstyear students but the traffic was low throughout the previous year Your goal is to increase the traffic for the upcoming school year 




The Problem

Are the LibGuides adequately represented in the library website information architecture including the labelling and placement within the website 




Recommended Research Techniques

	Techniques	Resource and time intensive	Bias	Credibility buyin
	Fivesecond test	No	Sampling bias	Low
	Journey mapping	Yes	Sampling bias social desirability bias	Medium




Conclusion

When deciding what type of UX research to conduct its important to not only consider the time and resource investment of the methods but also the potential for bias and your colleague and stakeholders understanding of the methodologies used When proposing design research methods or presenting results communicating the different intentions behind design research versus pure research and accounting for any potential biases should increase buyin and your chances for a successful user experience project

References

	Etches A  Schmidt A 2014 Useful usable desirable Applying user experience design to 	your library Chicago American Library Association
	Hall E 2013 Just enough research New York A Book Apart
	Lanclos D  Asher A 2016 Ethnographish The state of the ethnography in libraries 	Weave Journal of Library User Experience 15 doi 	httpdxdoiorg103998weave125356420001503

	Mitchell E  West B 2016 DIY usability Lowbarrier solutions for the busy librarian 	Weave Journal of Library User Experience 15 doi 		httpdxdoiorg103998weave125356420001504

	Nielson J 2011 Top 10 mistakes in web design Nielson Norman Group Retrieved from 	httpswwwnngroupcomarticlestop10mistakeswebdesign

	Pernice K  Budiu R 2016 Hamburger menus and hidden navigation hurt UX metrics 	Nielson Norman Group Retrieved from httpswwwnngroupcomarticleshamburgermenus

	Priestner A 2017 Whats in a name Does it really matter if we call it UX ethnography or 
	service design Weave Journal of Library User Experience 16 doi 	httpdxdoiorg103998weave125356420001603

	Sampling bias 2017 In Wikipedia The Free Encyclopedia Retrieved August 1 2017 from httpsenwikipediaorgwikiSamplingbias






Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS



















































User Experience in Libraries Applying Ethnography and HumanCentered Design


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










User Experience in Libraries Applying Ethnography and HumanCentered Design




Edited by Andy Priestner and Matt Borg

Review by Heidi Steiner Burkhardt

University of Michigan Library



Skip other details including permanent urls DOI citation information
Volume 1 Issue 5 2016



DOI httpdxdoiorg103998weave125356420001505



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	















User Experience in Libraries Applying Ethnography and HumanCentered Design Routledge 2016 makes the compelling case that user experience work in libraries must go beyond our digital presence in broad and meaningful ways The edited volume published in May 2016 fills a void in the scholarly literature Others have taken library user experience beyond the digital namely Courtney McDonalds  Putting the User First and Aaron Schmidt and Amanda Etches Useful Usable Desirable but no other book dives into qualitative research and ethnography to this level of depth

Schemed by Andy Priestner and Matt Borg at the same time as the inaugural UXLibs conference this tome aims to advocate for more ethnography and design thinking encourage discussion and debate and help kickstart library UX projects big and small p ix After finishing the book you can go back to this stated goal from the first paragraph of the preface and will likely agree that it succeeds

To set the tone and stage Priestner and Borg authored the first chapter in which they articulate the current state of affairs in libraries regarding UX work and persuasively conjecture how we got here This chapter is a manifesto The editors acknowledge reality and counter the standard excuses and arguments against UX research techniquesdefined as chieflyethnography usability and service design p 3with serious aplomb They also propose that the positioning for UX work in libraries is riper than ever and the impressive body of contributed work that follows their chapter supports that stance 

The editors efforts to feature a variety of viewpoints and illustrate a wide range of work is well considered and they deliver An array of topics author perspectives and types of pieces case studies overviews of methods theoretical pieces etc is presented Though each chapter stands distinctly on its own they piece together beautifully for a holistic look at user experience work in libraries Early chapters include theory topical overviews and discussions of the groundwork that can be laid to make an organizations engagement with user experience most productive From there we move through a broad variety of case studies before closing with a reminder on the power of storytelling and a call to action 

Beyond the opening by the editors Donna M Lanclos standout chapter Embracing an Ethnographic Agenda Context Collaboration and Complexity deftly reframes the challenges of visibility the critical nature of usability the perils of mediation and libraries as part of larger networks She argues that ethnographic approaches necessarily explode usability out of the library into spaces where people are p 29 and libraries can benefit from the perspective that comes from anthropology as a worldview p 33 Its a piece of scholarship so immediately useful that it even provides you with a new mental framework that can inform your engagement with the rest of the book 

Bryony Ramsden provides an excellent starter guide to using ethnographic methodsincluding primers on observation interviews cognitive mapping and focus groups as well as what to do with your datathat is relatable to anyone working in a library building Penny Andrews powerful chapter on autoethnography library anxiety hidden disabilities and real inclusion brings in the much needed perspective of accessibility positing against accommodating the special case and instead fixing problems with a solution available to everyone Leah Emarys chapter provides valuable advice on research design including considerations of validity reliability and scoping Andrew Asher gives the rundown on taskscapeswhich weave together locations rhythms schedules obligations etc revealing students lived experiences p 92and how they vary dramatically between different individuals lives Imparting expertise from outside the library field PaulJervis Heath of Modern Human shares an overview of the design thinking process that includes ample prompts for methods and models across four overlapping spaces or modes Immerse Inspire Imagine and Invent p 50 

The included case studies illuminate the varied scope scale and potential applications of UX research techniques Priestner discusses the creation of Spacefinder a webbased service to help users find study spaces near them based on attributes like facilities and noise level Spacefinder was developed entirely from scratch it derives directly from ethnographic research and threads UX throughout the process while Michael Courtney and Carrie Donovan apply an ethnographic lens to library instruction Many of the other case studies are dedicated to changes in spaces but present a wide array of examples from a multiyear intense participatory design process for a new building that included students as cocreators and partners to the small scale work by one person to cultivate a UX mindset and inform minor changes

A number of themes emerge throughout the course of the chapters including an emphasis on looking at our libraries within their larger ecosystems moving beyond standard quantitative data collection and feedback surveys considering the importance of context taking a holistic approach and focusing on our users as whole people The entirety of this book is filled with honesty and keeps things real there is a even a chapter dedicated to an epic fail p 103 This authenticity continually strikes you while reading and you might find yourself doodling hearts and writing things like BOOM and yesssss in the margins 

Despite all this greatness there are some weaknesses to User Experience in Libraries Though the chapters come together well you may notice some repetition if reading from covertocover specifically around defining ethnography and the relationships between quantitative and qualitative data When the chapters are taken individually this repetition has value but can become tiresome when taking in the book as a wholeespecially if you already have some familiarity with the concepts On the flipside this can also be considered reinforcement as the concepts are essential to the books core

And though the title broadly encompasses all libraries the chapters are predominantly written by authors associated with academic libraries in the United Kingdom There is some practical guidance applicable to all sorts of libraries as well as mentions of public libraries here and there Even with plenty of takeaways that transcend their originating context particularly from a theoretical perspective the book most benefits and supports academic work

Its easy to acknowledge and broadly accept the general concepts of user experience and humancentered design in relation to libraries but the real work illustrated in User Experience in Libraries is hard to do It requires support buyin and dedication of time and resources As with so many things the question becomes how to get this book these powerful chapters into the right hands How do we move beyond the echo chamber of passionate advocates There are no answers offered in this review other than for practitioners to keep talking and sharing If were lucky with its honesty and rational approach User Experience in Libraries Applying Ethnography and HumanCentered Design can break through




Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS





















































DIY Usability LowBarrier Solutions for the Busy Librarian


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










DIY Usability LowBarrier Solutions for the Busy Librarian 




Emily Mitchell

SUNY Oswego

Brandon West

SUNY Geneseo



Skip other details including permanent urls DOI citation information
Volume 1 Issue 5 2016



DOI httpdxdoiorg103998weave125356420001504



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













Although every library would benefit from running usability studies not every library has a dedicated staff available to conduct those studies Anecdotally librarians seem to feel incapable of undertaking usability studies for reasons including time budget and expertise We all have other job duties and tight budgets Moreover how many of us have ever actually received any kind of training or education on conducting usability studies For all their importance theyre not exactly standard coursework for a degree in library science

We all may be jealous of the libraries that have dedicated usabilityuser experience librarians but that doesnt mean the rest of us cant conduct successful worthwhile usability testing that leads to website improvements There are plenty of quick usability tests that can be run with just a little time and even less expertise These studies probably wont get you the indepth finegrained results that are possible with more involved studies but they will help you to identify your websites biggest problems Theyll also point you in a usercentered direction as you fix those problems 

As an added bonus the data you gather could have applications beyond the website Understanding which aspects of using the library give people trouble improves our ability to assist patrons at the desk and is useful to know when preparing instruction sessions It can also inform library promotion and outreach as you learn more about your patrons mental models of the library and its services If you start by taking a couple minutes to figure out how the results of a usability test will be relevant to your coworkers it will be much easier to ask those coworkers to collaborate with you on conducting the tests After all the only thing better than an easy and productive usability test is an easy and productive usability test done with help

If You Have a Couple Hours

Can you scrape together five or six nonconsecutive hours to gather data to improve the website Better still can you spare those five or six hours twice a year 

If so consider doing some guerrilla usability testing Just by walking up to people and asking them for three minutes or less of their time and then asking them a few questions you can gather quite a bit of useful data For tasks as quick and easy as those involved in guerilla testing you probably dont need to offer any incentives at all That said if you want to sweeten the pot for your participants you can invest in a bag of individually wrapped chocolates or offer some other such tiny reward 

Consider these options


1 Surveys

If youre curious what your patrons like dislike or believe about your website a survey can help Bear in mind that a survey wont tell you where patrons actually struggle on your website Youll need to observe website use to find that out since patrons dont necessarily realize when theyre not using our sites as we intend and might occasionally exaggerate or downplay their struggles and misunderstandings Still it can be extremely useful to know what your patrons believe are the strengths and weaknesses of the site This can also be a fantastic opportunity to ask questions like what they last used your website for The results may surprise you

Some things to keep in mind when running a survey


Keep Your Survey Short

The shorter your survey is the less time it takes to get someone to complete itand the less time it will take for you to analyze the results Lets be honest asking two or three questions may well get you all the data you have time to work with Plus its a lot easier to recruit patrons to participate if your survey is very short

If you really cant decide on only two questions to ask why not come up with a few different but equally short surveys You can run them simultaneously or spread them out over the course of a couple months if that works better for your schedule




Running Your Survey

Unless youre able to offer a small incentive or a chance to win something for survey completion you will likely get more results from running your survey in person Walk up to people who are sitting down or at least dont appear to be in a hurry to get somewhere else and ask them if they have three minutes to spare to help make the library website better Make sure your survey really does only take three minutes to complete Better still get a student worker or an intern to run the survey or see if your service desks can hand out surveys to everyone they talk to You can post your survey online instead of or in addition to this but dont be too surprised if you have a very low return rate for the digital version 

At Penfield Library we like to take our surveys to the campus food court and ask all the groups who are eating lunch to fill them out During a moderately busy lunch hour a single librarian usually averages about 20 responses to a twoquestion openended survey Happily 20 responses to a question tend to be enough for us to see the major trends in peoples answers 




Write Good Questions

Entire books have been published about the art of writing good surveyquestionnaire questions For the purposes of librarians with 20000 other things that need to get done today here are some basics to keep in mind

	Dont ask a question unless it will get you information you need and which will directly inform your decision making
	Avoid leading or biased questions For example Do you agree that the library offers quality reference services is a bad question to ask because its both leading and closed ended Consider asking something more like How would you describe your experience getting help with your research
	If your questions have any kind of multiple choice answers be sure the choices make sense and will allow everyone to answer honestly It can be helpful to pilot test your questions with colleagues and students to make sure your questions make sense
	Keep your language simple and avoid jargon


Try out some questions on a small number of patrons If youre not getting the answers that will help you make progress change your questions and try again If you want quick questionwriting tips A Simple Guide to Asking Effective Questions is a useful read 






2 FirstClick Testing

Firstclick testing offers a way to gain insight about an interface in order to make design decisions based on data rather than opinion or anecdotal evidence The concept is simple show a patron a library web page and give them an imaginary task to complete Then ask them to show you where they would click to get started with their task 

For example a task for a college student may include asking them where they would find journal articles related to sociology for their Social Work 101 class After the student makes their first click the test is complete Talk about simple

The premise of firstclick testing stems from research indicating that users are much more likely to succeed at a task if they are able to select the correct link or pathway to begin with According to usability expert Bob Bailey 2013 a user will have an 86 percent chance of completing a websiterelated task if their first click sends them on the correct pathway A persons success rate drops to 46 percent if they click on the incorrect path While firstclick testing is not a cure for the myriad issues that can plague websites it does provide insight to help you make better web design decisions


Set an Objective for the Test

Before you begin testing set an objective to test and decide which page you want users to start from Do you want to know if patrons can find your databases on the library homepage Do you want to know how they discover your ebook collection Do you want to know if the wording you used on your journals page connects with patrons who are trying to check your holdings Pick one or two things to test with each patron you talk to




Running the FirstClick Test

The easiest way to collect firstclick data is to do it in person and the easiest way to do it in person is on paper Print off a picture of the librarys homepage or whichever page you want to test and have the patrons circle where they would click Completing these tests takes very little time patrons are usually willing to participate if you make it clear that you will take less than three minutes of their time

If youre able to put slightly more effort into your setup you can run your firstclick test digitally with software like Chalkmark Chalkmarks free plan lets you test three tasks with as many users as you like The benefit to running your test this way is that your results will be recorded as a heatmap of where users have clickedvery useful for showing off your results to other librarians or administrators Another bonus is that you can link patrons to the test from your website though youll probably still get more responses by taking a tablet or mobile device and roving your campus or community





If You Can Spare a Day or Two for Usability

The world will not end if you never go beyond surveys and firstclick testing If you can make time for more indepth testing though you will see the payoff in richer more powerful data It really is worth the effort if you can manage itimprovements to your website will come more quickly


Recruiting Participants

Because the tasks in this section tend to be longer and more involved youll have to decide whether youll have more success asking patrons to participate on the spot or by scheduling patrons to come in at set times You may choose to do larger or smaller tasks with your participants depending on what makes sense for your recruitment efforts

If you opt to schedule your tests ahead of time be prepared to market the session deal with patrons who dont show up on time or at all and to be generally flexible Aside from hanging up posters or asking instruction librarians to help with recruitment its also helpful to offer an incentive for patrons to participate in longer usability tests Tests can range from ten to thirtyplus minutes depending on the patron and what youre asking them to do The incentives dont have to be extravagant Can you buy participants a coffee Waive a fine Give them a small gift certificate Anything youre able to offer will make recruitment easier

To streamline the scheduling process for your patrons consider using a service like YouCanBookme to let them set up their own appointments This kind of flexibility seems to increase the percentage of patrons who will actually show up to their scheduled appointments Youll still want to be sure you have some other work on hand to keep you busy in case of noshows though

If possible you should test patrons that represent your target audience for the task For example imagine that you want to find out how undergraduate students go about selecting subject databases to find articles If you were to recruit graduate students you see studying in the library every day then you may not learn as much as youd hoped the graduate student may have more experience in utilizing library resources than your typical undergraduate does The sophomore who pops in once a week might be a more fruitful participant for the study in this example




1 Card Sorting

Do you already know what content youre going to put on a page or the labels in a navigational scheme but youre not sure how to organize it so users can find things Dont just alphabetize that list of links Card sorting will get you a much more userfriendly answer by showing you what groupings of content and labels make sense in the minds of your users For an open card sort all you have to do is

	Write down each of the link labelspieces of content on an index card
	Shuffle the deck
	Ask patrons to sort the cards into any categories that make sense to them
	Ask patrons to name those categories


Another variation of card sorting is a closed sort where you have patrons sort cards into predefined categories that you define for them at the beginning of the test This makes it easier to analyze your data afterward 1 for being easier but it also limits patrons to your categories with all the baggage and assumptions that go along with those categories 1 for being less usercentric 

Regardless of whether your sort is open or closed if youre running a small enough test there are free tools that will let you do your card sorting online OptimalSort for example will let you sort up to thirty cards with up to ten participants for free you can pay to remove these restrictions The benefits of online card sorts include the fact that you dont have to schedule meetings with patrons to conduct the card sorts Plus the software automatically generates graphs that take care of a lot of the grunt work involved in turning your raw data into meaningful information Both of those features will save you a lot of time Drawbacks of course include the fact that unless you have a budget to spend on software youre limited to thirty cards and ten participants




Running Your Card Sort

Some people will sort the cards very quickly and decisively Others will agonize over every decision and you may need to reassure them that there are no wrong answers and everything is going to be ok even if they make a rushed decision These personality differences mean that running a card sort with thirty to forty cards could take you anything from ten to forty minutes If youre doing the sort inperson make sure your schedule allows for this

Some participants might struggle to understand link labels when they see them out of context like this no matter how clear the language is To be certain that everyone understands what each card represents try writing an explanationdescription on the back of each card rather than explaining the labels verbally Brucker 2010 p 51 That way everyone is getting the same explanation Since it could affect how someone sorts the card this is important

Our experience is that you probably want ten to fifteen participants at least for an open card sort For a closed card sort you may start to see trends before then since you will be dealing only with variations in the content of each category rather than variations in the categories themselves Finally because a card sort requires a substantial time investment from participants its nice to offer a small reward for participation if you have the budget 




Analyzing Your Results

Analyzing the results of a card sort can be tricky Be prepared to spend time on this data analysis especially if you used physical cards instead of software capable of generating graphs and reports for you Google Fusion Tables offers the capability of creating many different types of graphs for free once youve cleaned up your data in spreadsheet form Our personal favorite for visualizing card sort data is a network graph which isnt an option in Exceland that is why we use Fusion Tables fig 1


Figure 1 Network graph showing connections between items on SUNY Oswegos Penfield Library homepage that at least half of card sorters agreed on






2 ThinkAloud Testing

When it comes to usability testing the patrons actual thoughts and decision making are the most difficult data to gather While surveys first clicks and card sorting can be good for gleaning feelings perceptions and interactions none of these methods fully capture patrons actual thought processes when performing a task on a website Since telepathy or crawling inside their brains is not an option yet try the next best thing a thinkaloud test 

Thinkaloud testing is easy to run and offers data that can be persuasive even to skeptical colleagues Essentially the patron says aloud what they are thinking as they navigate through a series of website tasks During this test the librarian keeps quiet except to remind the patron to articulate their thoughts if they go silent It can be painful to watch a patron struggle through a task but helping them defeats the very purpose of this test

While easy to conduct there is some advance legwork to the thinkaloud test that may take a few hours Since this testing can produce such meaningful yields its worth the initial investment of time three to five thinkaloud tests with your patrons should turn up plenty of fixes you want to make on your library website




Designing the Tasks

When youre coming up with tasks for your patrons stay focused on gathering data you can act on Avoid asking anyone to do more than five or six key tasks that way the patrons wont get tired or frustrated The tasks dont need to fall under a single theme but they should be related to actual patron needs and help to answer your questions about the website Ask other librarians for task ideas that way youll better understand their concerns about the website and you might even get them interested in usability testing




Setting Up the Think Aloud

The thinkaloud test can be done either in person or online Before you start testing do some pilot testing and make sure youre comfortable guiding participants through the test By its nature the thinkaloud test is an unnatural social situation so building some quick rapport with the patron will make it easier for both of you

For an inperson think aloud try to conduct the test in a quiet semiprivate space Keep in mind that not every patron will be comfortable sitting in a fully private space with a complete stranger You will also want to make sure the computer you use is fully functional to minimize the patrons distractions

For online thinkaloud tests you can use conferencing software with a screen sharing ability Google Hangouts is a great free option Whatever you choose make sure you pilot it ahead of time so you can anticipate or preempt technology issues like outdated plugins etc




Recording the Data

Before the thinkaloud test decide how youll record the data Its best practice to let the patron know that you are recording their responses regardless of how you record the test 

Some of the options for recording a thinkaloud test include

	Take careful handwritten notes This is cheapest way to record the session but you may miss out on essential details especially if the patron works quickly through the tasks
	 Record the think aloud using video or screencasting software This is an easy way to ensure you capture the entire think aloud Just make sure to use a microphone to capture the audio You dont have to use a highend product to capture the think aloud but be aware of the time limits on some free options You dont want to disrupt the patrons train of thought by fiddling with the software
	For online thinkaloud tests keep in mind that conferencing software usually has the ability to save the session


If youre still worried about whether your thinkaloud sessions will run smoothly check out a copy of Steve Krugs Rocket Surgery Made Easy Krug provides stepbystep instructions for the whole process from planning to analyzing including scripts you can follow



Making Sense of Your Results

Regardless of the test you use to collect usability data you will need to interpret your findings If youre a oneperson usability team with lots of other responsibilitiesor even if youve successfully roped in a few of your colleaguesyoure probably not going to have as much time as youd like to spend wrangling usability data Never fear You dont have to apply advanced statistical methods to your data to learn useful information The biggest thing you want to do with your data is simple look for trends 


Analyze Your Results

For survey results read through all the answers by question rather than by participant That is read every participants answer to the first question and then every participants answer to the second question etc Are there common themes Type those themes into a Word document as headings and copypaste the relevant answers beneath them Read through them again now that theyre organized and theres a strong chance youll see a direction you want to take in improving your website

You can treat most of the other usability tests we mentioned in this article the same way Look for the patterns in your firstclick tests or your thinkaloud sessions For card sorting if you dont have time to fight with spreadsheets of data even just a look at which cards appear frequently with which other cards can be useful While a fuller analysis can provide more insight the bottom line is that if your data provides you with a usercentered direction to move in youve achieved something worthwhile




Share Your Results

Once you have patterns to reportmost users fail to figure out how to pay their fines online or theyre failing to distinguish between journals and databases or whatever the stumbling blocks aredraw your coworkers into a discussion of what comes next You never know when someone who works in a different capacity might be able to point you toward a solution for seemingly intractable usability problems 

Similarly you never know when youll be able to reassure your coworkers about something that worries them Its a lot harder for someone to raise a stink about the wording of a link on the homepage if you bring back data showing that actual patrons understand that wording and use it successfully By sharing what youve learned from usability testing its often possible to tone down opinionbased arguments over the website




Fix What You Can

Above all else dont worry if youre not able to fix every problem users have right away Fix what you can and keep track of the remaining issues in case the opportunity to correct them arises later on Part of the beauty of quick lowcost usability testing is that you can find ways to fit it into your schedule and budget on a recurring basis Even if you can only squeeze this in once a year think long term Eventually small fixes can add up to big change



References

	Bailey B 2013 Firstclick usability testing Retrieved from httpwebusabilitycomfirstclickusabilitytesting
	Brucker J 2010 Playing with a bad deck The caveats of card sorting as a web site redesign tool Journal of Hospital Librarianship 10 4153





Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS






















































Whats in a name Does it really matter whether we call it UX ethnography or service design


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










Whats in a name Does it really matter whether we call it UX ethnography or service design




Andy Priestner

Andy Priestner Training  Consulting



Skip other details including permanent urls DOI citation information
Volume 1 Issue 6 2017



DOI httpdxdoiorg103998weave125356420001603



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	














Names Whats in a name really I mean besides a bunch of letters or sounds strung together to make a word Does a rose by any other name really smell as sweet Would the

most famous love story in the world be as poignant if it was called Romeo and Gertrude Why is what we call ourselves so important Julie Kagawa Summers Crossing




Naming things Librarians love it If were renaming the catalog launching a newsletter or more commonly a new committee were all over it And whether we end up calling things after characters from Greek or Egyptian mythology devising a clever acronym or we are intent on getting library in there somehowI recall leyebrary as a suggestion for the title of Futurelibs eyetracking projectagreeing on the name is high priority Of course this impulse to define runs much deeper than dreaming up new monikers and I admit an occasional impatience with our professional fetish for naming We spend a great deal of time defining words perhaps sometimes in preference to doing the work itself There are countless times Ive sat in conference sessions increasingly restless thinking that we should spend less time defining and more time doing 

I brought my impatience with me when I originated and chaired the first UX in Libraries conference in 2015 I was determined not to fall into the trap of focusing on definitions scope and terms of reference This is why I made a plea as recently as June in my UXLibs2 opening address that we stop debating what we call our work and just get on with it The plea did not go down well with some of the audience and the more I have thought about it the more I have realized that they had a point The names we use have a huge effect on how our work is perceived and understood and how we understand ourselves and our inherent motivationsNames might not be the work but they can affect the work deeply

This lesson was underscored for me when I met with the new interim Cambridge University Librarian to discuss Futurelib the program I formerly ran Very quickly I realized that he viewed the research program as little more than stargazing despite our focus on practical and immediately applicable work in user experience His assumption was squarely based on the name of the program a shorthand for future library services Futurelib was not originally intended to be the name of an ongoing user experience research program We had used the name for a single project looking at new services to serve near future library users and the name lived on as an umbrella title for the new program If anything it should be called NowLib  as it is concerned with researching current user experience and designing services and products as a result Nothing clarifies the stakes of a name like institutional understanding especially when funding is at stake

Of course Futurelib is at most a microcosm of a wider and far more important issue what we should be calling this type of work in libraries I have recently reflected that when youre actively building on the work of others developing it redefining it exploring it from a new angle that it is a bit like organizing a wedding There are many stakeholders each with an emotional investment and compromise is the only happy possibility 

The convergence of UX ethnography and servicehumancentered design in libraries benefits tremendously from generous and devoted voices that come from a variety of backgrounds and from whom we can all learn But as someone coming to user experience from a career in libraries I have chiefly advocated that librarians should place user experience front and center in our terminology even if this potentially deemphasizes ethnography or service design despite the obvious and independent value they both offer Why Because I believe our effort is most fundamentally to uncover the real experience and behavior of our users and improve or develop new services in response to what we learn We should focus on the user above all else not only in the work we do but also in the terminology we use

There is room for disagreement here Donna Lanclos and Andrew Asher both seasoned and trained anthropologists working in libraries recently wrote a piece for this very journal in which they argued that much of the user experience research taking place in libraries was not really ethnography and was thereby missing out on the full value and benefits of the approach They described current efforts as at best ethnographish My first instinct was to be offended but it soon dawned on me that they were absolutely right They had called it The ethnography I have conducted and encouraged others to conduct in Cambridge and through my freelancing all over the world is not and could never be true ethnography But neither have I or many others sought for it to be or described it as such The goal of user experience work as I see it is not a purity of methods but a balancing of these methods with a practical effectiveness of outcomes If ethnography and service design can be understood as poles on a spectrum with methods on one side and outcomes on the other then user experience would be my term for the spectrum itself

Consider an example of ethnographish methods at Futurelib the Protolibliterally prototyping librariesproject We didnt come to understand a particular study community and uncovered very little in a cultural or social sense about the people who chose to work in particular reading rooms Nevertheless we did learn a great deal about their behavior and needs We discovered that users switched between different study environments depending on the work they were tackling that in certain contexts soft furnishings and comfortable furniture did not necessarily encourage noise and mess and that occupancy of a reading room could be significantly increased by removing chairs to give users more space Crucially the qualitative and quantitative data we gathered throughout the project informed the construction of a set of design patternstemplates for library environments that detailed furniture and other requirements needed to support different intensities of study activity These patterns were a result of physical prototyping in four different spaces which we gradually optimized over time through iteration and response to user behavior and feedback

This was in a sense service design We had an end goal of creating a relevant framework for other spaces being modified or newly created within the Cambridge library system However to only call the project service design focuses too much on the end product and discounts the true serendipity of the wider process of research we learned more than we meant to and thats the way it should be 

Much of what Protolib uncovered was incorporated into a set of patterns for designing library spaces but the full picture of what we uncovered could not be In a strict servicedesign approach the findings would only contribute to a solution leaving out a lot of what we learned The additional knowledge we gathered contributed to our overall understanding of our users and will potentially inform future decisions Understanding for understandings sake has a lot of value When stakeholders can see and appreciate the rich and detailed picture of user experience you have uncovered support and positive change become more likely The realand often surprisingbehavior of library users and the way ethnographicish techniques can uncover it is something we should shout from the rooftops

So while ethnography offers us something crucial it must be part of an admittedly difficult balancing act and undertaken with a cleareyed understanding of what it involves The adoption of true longterm ethnography in librarieshowever laudable the intention is a Utopia we shall never see But I would rather conduct ethnography on these terms than not at all

We librarians still have a tremendous amount to learn from experienced partners such as trained anthropologists and designers and I know I personally owe them a great deal But all the same we can and should occupy the point in the UX continuum that makes sense to usand that point doesnt even need to be fixed 






Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS

























































User Personas as a Shared Lens for Library UX


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










User Personas as a Shared Lens for Library UX




Alex Sundt

Erin Davis

UTAH STATE UNIVERSITY LIBRARIES



Skip other details including permanent urls DOI citation information
Volume 1 Issue 6 2017



DOI httpdxdoiorg103998weave125356420001601



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













This paper was refereed by Weaves peer reviewers

Introduction

Libraries interested in usercentered design are faced with a number of options for measuring and improving their library user experienceusability tests contextual interviews and direct observation being a few popular user research methods While experts often encourage the use of multiple techniques for a fuller understanding of users and their needs Pruitt  Grudin 2003 Rohrer 2014 this can be difficult for libraries with fewer resources or time for dedicated user research making it important to consider practical tools to assess library UX and spur usercentered thinking 

User personas are one such tool helping both communicate UX findings and knowledge of users and helping guide the design process by ensuring that the right questions are being asked and users remain the central focus in decision making The power of personas lies in their ability to distill knowledge of a target user group into relatable characters that are easy to remember and empathize with Harley 2015 This can help address a common problem among product design teams known as the elastic user where a teams definition of users will shift at different stages of the design process and will often be different for each team member reflecting their own personal biases and preferences Cooper 1999 By creating a concrete and shared definition of target product users personas are a first step in creating a common consistent vocabulary for usercentered design helping facilitate discussions and encouraging a shared vision for product UX

At Utah State University Libraries personas provide an imperfect but compelling lens for understanding library users helping us assess and improve granular details of design like copy and layout while also serving as a reminder to keep users at the center of the design process from start to finish In the past decisions and priorities for website development were primarily influenced by internal needs and preferences Discussions of users were not central to the design process and largely revolved around anecdotes and assumptions about library users with little agreement on how to valuate or prioritize their assumed characteristics Personas have helped address these problems by providing librarians designers and development staff with a common understanding of library users that is both concrete and evidencebased For example instead of starting with a list of features or goals as dictated by internal stakeholders personas force us to consider the users expectations needs and goals to determine design features and specifications As a project progresses usability testing can help validate and refine our design but returning to wellmade personas also provides a practical way to keep our process on track and ensure our design is still reflecting users goals 

Like many libraries we have sought out budgetfriendly ways to incorporate UX into our everyday library practices For example we employ a lightweight usability model that allows us to quickly gather feedback without formal test procedures and recently adopted a continuous design model that allows us to quickly respond to problems and make improvements as we learn more about our users needs As a complement to this agile budgetfriendly approach this article will propose a similarly lightweight method of persona creation that allows personas to be developed quickly and improved iteratively as they are put into practice 

What are Personas

Personas are profiles of imaginary people that describe the behaviors motivations frustrations and end goals of target users for a product or service First proposed by Alan Cooper as a way to focus the design process 1999 personas typically include a portrait background information and other fictional details to help make the persona feel like a real person As a standin for large groups of potential users personas help to illustrate common behaviors and tasks that are shared among otherwise diverse groups of people helping designers imagine how users might interact with a product and what features they need most to achieve their goals Goodwin 2008 

In concept personas are similar to a list of product requirements that would traditionally be gathered from internal discussions or surveys of users However instead of listing out all potential features personas focus the design process on only those features that support users tasks and end goals helping to filter out noncritical items and exclude internal assumptions and preferences Fox 2014 As a UX tool personas provide a memorable way to distill and synthesize user research using fictional characters to describe findings in a more relatable human way Compared to an abstract list of design requirements this more realistic characterfocused presentation also helps encourage empathy and investment in user success Guenther 2006 In theory design teams and other stakeholders will come to know personas by name intuiting their needs and preferences and use the personas as a common language for discussing users and making choices during the design process

These qualities made personas a good choice to address problems in the way we at Utah State University Libraries were managing and designing our website helping us better understanding users needs and by extension helping identify the core features our website needed to include in order to better meet those needs Previously the library had no common or consistent understanding of library users and as a result web design was essentially haphazard with no clear goals or vision The term user meant something different to each staff member and was strongly influenced by personal experience preferences and assumptions For example due to their regular exposure in the classroom an instruction librarian might have a traditional undergraduate student in mind when thinking of users whereas staff in resource sharing traditionally work with graduate students and faculty shading their understanding of common user needs These differences would often lead to project goals being unfocused based on different stakeholders perceptions of the target audience For a usercentered process to be successful at our library we clearly needed to move away from fluid definitions of users and instead determine exactly whom we were designing for and what attributes should be the focus of decision making 

How Personas are Made

To accurately reflect users and encourage personas to be taken seriously by internal stakeholders a datadriven approach is often recommended for persona creation using either primary or secondary information about users Pruitt  Adlin 2010 Primary data is often collected through direct observation or interviews with target users where they openly discuss their thought processes or feelings about using a product Firsthand observations of users especially within the environment or context where a product will actually be used provide the most accurate data from which to create personas Goodwin 2002 Secondary data by contrast isnt gathered directly from users but is instead filtered through some thirdparty source For example while it can be extremely valuable to elicit insight from staff who frequently interact with users this information is considered secondary because it is a step removed from actual users 

While datadriven personas are ideal there are advantages to drawing from experience and assumptions to inform persona creation Assumption personas are quick and easy to create and encourage reflection in the design process For example Donald Norman reported success using assumptionbased personas to help designers get a fresh perspective and develop empathy with their target audience which ultimately led to more thoughtful designs Norman 2004 The process of gathering assumptions can also be useful exposing tacit knowledge and suspect or contradictory ideas about users indicating where more research may be needed Pruitt  Adlin 2010 For example we assumed the core audience for the librarys discovery layer was inexperienced undergraduate students not graduate students and faculty However after reviewing survey feedback it became clear that a wider group was using the discovery layer for knownitem and other quick searches significantly changing how we managed this tool

No matter what type of data you use to inform persona creation data collection does not have to be a timeconsuming process as Pruitt and Grudin 2003 showed in their use of existing market research Both primary and secondary data can be drawn from previous research efforts conducted internally or from an external source allowing for quick analysis and draft personas to be made Such personas can then be refined by additional primary research in order to create more valid representations of users as we will describe in this article One significant benefit to this iterative approach is that personas will continue to grow and improve as new data and research are incorporated

After data are collected about users there are a number of ways to go about forming personas to represent those users When evaluating a large amount of data Pruitt and Grudin 2003 recommend divvying up data sources among the team members who will be participating in persona creation Next methods such as affinity diagramming can be used to compare and find relationships between the data sets helping form the foundation of unique user personas In affinity diagramming interesting facts trends or other pieces of data are pulled out and written on cards or sticky notes which are then arranged as part of a group exercise This quick method of persona analysis is useful because it works well for diverse data source types and is highly collaborative Pruitt  Adlin 2010 The behaviors and personality types that emerge from these kinds of exercises are then enhanced by adding a persona name and other fictional biographical details to make the persona feel realistic Because personas are meant to aid the design process by reflecting common behaviors and goals Guenther 2006 recommends limiting the number of personas to a small set of characters representing broad user patterns

Drawbacks of Personas

There are some limitations and drawbacks to using personas that should be kept in mind As Cooper 1999 notes designing for one wellunderstood person is far more successful than trying to design for each and every potential user But by distilling diverse people into a handful of characters personas can potentially obscure important differences among individuals in favor of characteristics that support broadbased design Thus it is important to recognize that personas are a form of stereotyping whether positive or negative which have the potential to legitimize and exacerbate the effect of personal biases in the design process Turner  Turner 2011 Persona creators can limit this risk by ensuring that solid research is used to inform persona characteristics rather than relying on potentially faulty assumptions 

Personas if not properly designed also pose a risk of being viewed as unnecessary and may be quickly abandoned by an organization Long unfocused persona biographies discourage team members from reading and remembering the persona McKay 2011 This can lead to personas being viewed as fake and irrelevant to the design process To keep personas relevant McKay recommends creating simple documents that focus on traits and behaviors that are important to the design process while limiting personal back story Incorporating user research into persona documents especially observational research that elicits the users voice can also encourage team members to trust and actively use personas in the design process Edeker  Moorman 2013

Finally personas are most successful when combined with other usercentered research and design practices and customized to fit a specific context or user community A set of personas developed for a specific aspect of the library user experience may not necessarily transfer to other applications or areas of library use As a best practice libraries should encourage different units and service areas to pick and choose the individual personas that are most relevant to their area expanding on those personas or creating new ones as needed and initiating their own research projects to learn about different target audiences

How Libraries Have Applied Personas

While library  information science authors have been advocating for the use of personas for many years Cunningham 2005 Phillips 2012 Schmidt 2012 they dont appear to be in widespread use among libraries especially public libraries However as interest in usercentered design grows libraries continue to experiment with personas as a way to introduce usercentered approaches into library practice Fox refers to personas as a proxy stakeholder and an advocate for their proxied constituents Fox 2014 p 70 and notes that the process of creating personas can be as useful as the personas themselves Most commonly personas are used by libraries to improve the web design process Ballard  TeagueRector 2011 Cunningham 2005 but have also been used to inform web and overall library strategy Koltay  Tancheva 2010 Personas have been applied in order to better understand users in a number of unique library contexts including medical library users Brigham 2013 users of an institutional repository Maness Miaskiewicz  Summer 2008 humanities scholars Khaled AlShboul  Abrizah 2014 and adult distance education students Lewis  Contrino 2016  

Many different approaches and data sources have been used to develop library personas including surveys and other user assessments Cunningham 2005 text analysis of user interviews Maness et al 2008 software analysis of chat reference transcripts TempelmanKluit  Pearce 2014 and a mix of ethnographic techniques using undergraduate students as data collectors Zaugg  Rackham 2016 Although personas have been applied in a variety of settings many have argued for a more simplified approach to persona development Fox 2014 Guenther 2006 Koltay  Tancheva 2010 which could allow for more libraries to create and adapt personas This article is intended to address this need by proposing a practical model for quickly creating and putting personas into practice Additionally our approach advocates for iterative personas that change and improve over time keeping personas relevant and reflective of the user community while supplementing ongoing design and UX work 

Our Approach to Persona Creation at Utah State University Libraries

In 2014 the librarys new web services librarian created a working group to explore ways to improve the current web design process by incorporating more usercentered methods This group would serve as the core team described by Pruitt and Adlin 2010 as a key part of the persona family planning phase of persona development During this stage a diverse team is assembled and engages in a kind of organizational introspection to expose underlying needs and identify potential persona types that will be needed to meet those needs To better leverage the experience of librarians particularly those that worked closely with students and faculty our team included several members of our reference department as well as programmers from our systems department Based on discussions with the working group and other staff who had been involved in website planning throughout the years the group identified several problems with how the website was being designed and managed

	Website improvements were generally made as part of a major redesign which were timeconsuming and infrequent making it difficult to make necessary UX improvements or incorporate insights from user research 
	Web design and development was largely driven by internal preferences and assumptions about what users needed not a firm understanding of actual user needs 
	Our understanding of users and their needs varied significantly due to the diverse backgrounds and experiences of library staff members making it difficult to collaborate and form consensus around web development matters
	The knowledge and experience of front line staff and others with a strong understanding of user needs wasnt being heavily incorporated in the design and development process


 

To address these problems the group decided to adopt an iterative continuous approach to website design In contrast to a major website redesign continuous design allows for highpriority problems to be addressed immediately and introduces major changes incrementally over time creating less disruption for users and reducing stafflevel conflict resulting from largescale redesigns Schmidt 2011 In addition personas were identified as a useful way to reorient our process away from a staffcentered focus and toward more broad usercentered goals To achieve this we wanted our personas to represent all important user populations within our community including undergraduate and graduate students faculty members and communitypublic patrons showing where users needs both overlapped and deviated from each other This would help us satisfy broad user needs in cases like the website homepage while in other cases helping us keep in mind more unique narrower needs such as for pages geared for interlibrary loan or other facultyoriented services To create the personas we chose a lightweight approach that would complement our web development process and allow us to put personas into practice sooner rather than later The goal was to establish a basic definition of our target users using data that could be gathered quickly and easily In addition we wanted to incorporate the collective knowledge and experience of our library staff as a way to foster collaboration and include a broader range of voices in our web development process Although it was important to take any assumptions with a grain of salt we considered frontline staff and others who commonly interacted with patrons as user informants who could provide particularly valuable information about users common needs and frustrations 

We also hoped personas could help us better reflect and meet the needs of less visible users With 12459 distance learners for the 20152016 semester USU Libraries are increasingly serving patrons who have minimal direct interaction with library staff Personas could also help formalize our understanding of this diverse patron group as well as undergraduates in general who we often think of as a single homogenous bloc Knowing that personas are in essence a form of stereotyping it was important that our process drew from evidence to illustrate underlying needs and motivations and not simply use academic status or other demographic details to distinguish different types of personas However we recognize that some assumptions had to be made where we lacked extensive data for certain groups such as university faculty We plan to address these flaws by incorporating future research to more accurately better reflect these and other less visible users 

To help personas remain accurate and reflective of the target audience Pruitt and Grudin 2003 encourage user research to be collected and incorporated into personas as an ongoing practice With this in mind our team decided to separate persona development into two distinct phases relying first on previous assessment and usage data to create basic personas followed by usability tests and interviews with students and the incorporation of feedback from librarians and other staff to validate and further refine the personas In addition to several phases of data collection and refinement we plan to regularly review persona documents to ensure they continue to reflect our changing user population and technological landscape This iterative and adaptive approach provides a good middle ground between highly datadriven and purely assumptionbased persona methods allowing libraries to create basic personas that can evolve over time and work in concert with continuous design and agile development methods

Persona Development Phase One

Before creating personas Pruitt and Adlin 2010 recommend assembling data from a wide variety of sources both primary and secondary showing some insight about users and their behaviors To begin we drew heavily from previous assessment and usage data including reference desk transaction summaries transcripts of reference chat transactions user comments from the 2013 LibQUAL survey and results from a 2014 usability study conducted by our former assessment librarian These sources were selected because they were convenient and readily accessible and provided the following

	A broad range of users library needs frustrations and behaviors
	The resourceservice requests reference questions or requests for assistance that were asked for most often
	Users thoughts and feelings about library services including desires for improvement provided in their own words


For the full list of data sources included in phase one see table 1

Table 1 Phase one data sources

	Data source	Data type	Methods
	Reference transaction summaries	Secondary	
	July 22 2013  November 2 2014
	10413 summaries
	One member reviewed


	 40 summaries for facultystaff choosing sets of 5 throughout the data
	 30 summaries for graduate students choosing sets of 5 throughout the data
	 100 summaries for undergraduate students choosing sets of 10 throughout the data
	 77 summaries for regional campus and distance education



	Chat transcripts 	Primary		August 25 2014  November 3 2014
	724 transcripts
	Coded independently by 3 group members


	User comments from 2013 LibQUAL Survey 	Mix		Comments coded and grouped by user type by assessment librarian
	All members analyzed the openended comments from the survey


	2014 usability study results	Mix		114 undergraduate survey respondents
	10 usability test participants 
	All members reviewed usability test results and responses to two openended questions




Data Analysis

Prior to reviewing our data sources some assumptions were made about users in order to help with the analysis and organization process For example following the recommendations of Pruitt and Adlin 2010 we drew from our knowledge of users to identify important user categories including undergraduates graduates faculty and distance users that would help group our data and guide the persona development process Over a period of two weeks group members reviewed data for outstanding comments requests behaviors and statements that illustrated some aspect of users underlying motivation or goals when interacting with library services Data sources were divvied up with all members reviewing data from our 2014 usability and 2013 LibQUAL studies several members reviewing reference chat logs and only one group member reviewing reference summaries Comments and themes from each data set were collected in a master document in a relatively raw unstructured format either using direct quotes from users or summarized by the group member analyzing the data This allowed each member to review the themes as a whole and refer back to the original source if necessary

Divvying up the data sources a method Pruitt and Grudin 2003 also employed allows for a large amount of data to be reviewed quickly but may result in a more biased analysis of the data While this may have undermined the validity of the results it allowed data to be analyzed more efficiently our main goal at this stage Because most of the sources used in this initial phase were primary sources we considered this a reasonable tradeoff allowing a basic outline of personas to be developed with limited investment In addition all of the sources with the exception of the 2014 usability survey reflected the needs of highly motivated patrons either requesting help or providing feedback In both cases these data may not reflect the broader population of users who may be less likely to request assistance or report feedback In phase two targeted interviews and usability tests allowed for more direct observation of library users to be incorporated into our persona development process


Reference Transaction Summaries

Summaries of 5482 reference desk transactions were downloaded from the Springshare LibApps platform for the time period July 22 2013  November 2 2014 From this set we selected 40 transactions tagged as facultystaff and 30 tagged as graduate students pulling sets of 5 in intervals of 100 We also selected 100 transactions tagged as undergraduates choosing sets of 10 in intervals of 400 This presented us with a broad snapshot of users resource and service needs including what problems and frustrations were commonly encountered but reduced the amount of time and effort needed to review a large set of data In addition all 77 transactions tagged for our regional campus locations or distance users were selected to ensure we were accurately representing this important population

The transaction summaries were then reviewed in detail by the assigned group member with information related to the type of request or resource needed as well as user information and characteristics about the patron recorded by theme table 2

Table 2 Reference transaction summaries data breakdown

	Data group 	General theme of question
	
Undergraduates

4065 total 

100 reviewed

	Room locations study rooms course reserves citing sources identifying credible sources finding full text locating articles on a specific topic looking for textbooks looking for a specific book articles specific USUrelated info hours of library scanner LibGuide printing
	
FacultyStaff

766 total 

40 reviewed

	Finding booksjournals streaming video access Visiting faculty orientation access to computers course reserves request for library instruction accessing resources online citation management software interlibrary loan copyright
	
Graduate Students

574 total

30 reviewed

	Comprehensiveness of research looking for a specific book citation software help research help for subject specific research accessing resources online thesis binding interlibrary loan
	
Regional Campus and Distance Education

77 total

Reviewed all

	Accessing resources online login problems interlibrary loan general research questions thesis binding locating articles on a specific topic upperdivision research on specific topics streaming video access Encore problems course reserves





Chat Transaction Logs

Chat transaction logs for two months were downloaded from the LibApps platform for August 25 2014  November 3 2014 totaling 724 transcripts The group member assigned to review chat transcripts recorded themes and perceived user characteristics that stood out from the transaction data which were used to develop a coding schema that was applied to the data Because the chat logs were considered primary data two other group members independently coded the transcripts to confirm the analysis The coded transcripts where then compared to find characteristics that seemed to commonly occur together in order to identify trends and relationships that could be used to inform persona outlines This constituted a kind of miniaffinity mapping exercise a technique we later applied to our data as a whole to identify related characteristics Using this method two distinct approaches to research questions and other requests were apparent reflecting different levels of comfort or experience with libraries and the research process among the users in our analysis For instance a chat user that wanted quick answers also commonly mentioned their assignment requirements such as needing a certain number of sources or format types for their bibliographies Their research questions were also less focused and required more elicitation on the part of reference librarians Similarly users with more focused research questions were commonly more willing to engage in longer and more indepth chat sessions and might also be referred to a subject librarian for more help These distinctions suggested that highly motivated and engaged users are also more experienced with library research while less experienced users either have less indepth research needs or simply dont want to spend a lot of time engaging in the reference process These relationships were important in forming our basic personas while characteristics from the chat transcripts were used as inspiration for our personas representative quotes Access problems and issues with our Integrated Library System ILS seemed to span across both types of users making this a common frustration featured in our final personas Table 3 illustrates characteristics that commonly appeared together in our group analysis

Table 3 Chat transcript themes by type

		Research questions	Answer time	Type of request	Willingness to contact	Access issues	ILS
	Inexperienced	Broad or unfocused research questions	Want quick answers
	Book checkout periods
	Link to LibGuide
	Find EBSCOASP


	Concerned with assignment requirements
	Sometimes ask for specific number of sources other assignment requirements 


	Worry about bothering librarians	Troubleshooting access issues from offcampus	ILS issues
	Experienced	Focused research questions	Willing to take time to work on complicated questions 		Need help locating known items usually wanted an electronic copy of a specific article
	Book check out periods

	Often eventually referred to subject librarians





LibQUAL Survey Questions


In 2014 USUs assessment librarian conducted a detailed analysis of openended comments from a 2013 LibQUAL survey and created reports for each major user type including undergrads graduates and faculty members which summarized each groups perceptions and expectations of the Libraries and included representative quotes This data was selected because it was not only readily available it also provided a rich source of primary information about users related in their own words regarding their thoughts and feelings about library services including desires for improvement 

Each group member reviewed the assessment librarians reports while several members also reviewed the raw survey data Each member collected trends and themes from the data including direct quotes expressing common perceptions and feelings users expressed about library services which were organized into our master document by user type For example comments from undergraduates such as make the website less cluttered and make things simple indicated that navigation and easeofuse were important areas for improvement Many undergraduates also felt overwhelmed by the large number of library resources and expressed confusion with starting the research process Faculty members feedback indicated frustration with specific tools like the catalog or electronic journals with comments such as it often retrieves irrelevant items and could be more logical and userfriendly while praising the value and efficiency of services such as interlibrary loan Interestingly many graduate students expressed a desire for more library instruction and research tutorials to help them use library resources more effectively All patron groups expressed a desire for a more usable website and easier access to the materials they needed most 




User Survey and Usability Tests

Our analysis also included data from two openended questions from a 2014 survey of 114 undergraduate students recruited from an introductory English course at our main campus location The survey occurred before they had received any formal library instruction The first openended question asked You have to write a paper for a class How do you go about getting information and resources for your topic List everything you can think of Google and search engines were mentioned in 78 percent of responses usually first Library databases or other eresources were mentioned almost as often 76 percent and librarians or other experts were listed in 21 percent of responses Other information sources included the students professor textbook the course management system friends family members and peers 

The second openended question asked How could we improve the library website Is there anything specific we could do to help you find the information you need for classes Common responses included a desire for quick access to commonly used resources and features greater simplicity and easier navigation Negative comments noted that the website had too much information was cluttered and disorganized and lacked information for basic questions like how to find books in the stacks Users also commonly expressed feelings of being overwhelmed and confused by the library mirroring comments from our LibQUAL data In addition students expressed a desire to be more effective at using the library without needing help from library staff 

Along with survey questions formal usability tests with ten undergraduate students were also conducted as part of the librarys 2014 study Results from these tests provided valuable information about how lessexperienced users approached research topics and interacted with library resources Together with the survey questions data from this study confirmed many of the trends found throughout our data analysis providing a strong sense of the needs behaviors and preferences of undergraduate students a key user group for USU Libraries and an important category that we wanted to reflect in our user personas




Affinity Diagramming

After collecting data from their assigned sources along with comments from the LibQUAL survey and our 2014 usability study group members reviewed and discussed common trends and attributes that stood out from our master document Next the group conducted an affinity diagramming exercise in which each theme trend or attribute was written on a sticky note and posted on a large wall Group members then worked together to arrange similar sticky notes into related clusters Over several rounds of connecting and combing similar notes the clusters eventually could not be further condensed and were each given a general label The following clustered emerged from our exercise 

	Need for speed
	Techonline 
	Overwhelmedstressed
	Confused
	Library as place
	Feelings 
	Personal network
	Outsiderregional campus
	Shyintrovert 
	Traditionalist
	Wants personal help
	Open to help
	Google
	Novice researcher
	Advancedproficient researcher
	Busyconvenience
	Independence
	Positive relationship with library


Each cluster represented several interconnected themes or attributes For example under the need for speed cluster team members grouped attributes such as quick searcheasy to find wants quick answers impatience only cares about practical info hours study rooms The techonline cluster included attributes such as techsavvy avid texter loves smart phones and social media 

After the affinity mapping exercise the group started to make connections between clusters and formulated rough outlines for initial user personas For instance the need for speed cluster could be easily connected within the novice researcher cluster based on the relationships that emerged from our analysis of chat reference transcripts Other behaviors and attributes however were more difficult to connect For example attributes from the traditionalist cluster which included resistance to change and a preference for print formats werent obviously connected to other clusters Due to the disparate nature of our data and the fact that it was not based on our own direct observation of users making connections between our clusters did not lead to distinct outlines for personas Instead based on recommendations to keep personas simple and focused on addressing design needs McKay 2011 we decided to further organize our affinity clusters into four broader categories that we felt had a strong influence on a users overall success in using the library website 

	
Research The users level of skill in scholarly information seeking and knowledge of scholarly practices in their field of study 
	
Technical The users level of skill with using technology both in terms of proficiency with computers and web technology and as specific skill using library systems 
	
Emotional The users level of comfort or anxiety when conducting research or using the library and feelings of being overwhelmed confused or frustrated with the library experience
	
Location The location where the user primarily conducted research or engaged with library resources and services Due to USUs large population of distance and regional users we identified location as having a high impact on their ability to easily access and use library resources and services as well as the nature of users interactions and relationship with the Libraries 


Table 4 illustrates how the attribute clusters mapped to each of these categories 

Table 4 Attribute categories

	Category 	Attribute clusters
	Research	Advancedproficient researcher Novice researcher Personal network Traditionalist Wants personal help Open to help Independence
	Technical	Techonline Need for speed Google Busyconvenience Traditionalist Independence Advancedproficient researcher Novice researcher
	Emotional	Overwhelmedstressed Shyintrovert Confused Feelings Positive relationship with library
	Location	Library as place Off campus Outsiderregional campus Independence


 

While user personas werent immediately apparent these categories helped focus persona development around core design needs relevant to the library service experience Because they could be mapped along a spectrum eg novice researcher intermediate researcher advanced researcher or binary eg near location far location attributes from each category could be mixed in varying degrees to develop the skeletons of our personas This allowed us to form persona types that would include the full breadth of characteristics that seemed necessary for our design needs In addition this scheme allowed us to mix attribute clusters across several highlevel categories for example traditionalist was placed under both research and technical reflecting the multiple areas where those attributes were observed 



Creating Initial Personas

To get the process started each group member was assigned to create two personas drawing attributes from each of our categories to form the basic outline for each personality Following the family planning phase of the personas creation process outlined by Pruitt and Adlin 2010 we already had in mind an initial set of user types that we considered important to represent in our personas Thus we decided to create personas matched to our key groups within our user population undergraduate students graduate students faculty and instructors and our community patrons The goal was to represent a broad range of users and needs using a mix of attributes from our affinity diagrams and later pare the number of personas down to a more manageable and usable set It was also important to represent our attribute categories at varying degrees across each of our persona types For example for each of the persona types we outlined we created a separate persona to reflect both novice and advanced research skills and different levels of emotional connection and comfort with library services using a mix of attributes from each category to illustrate each persona 

The user attributes from each of our categories were incorporated into the protopersonas under three sections labeled Attributes Frustrations and GoalsMotivations To help flesh out the personas and make them seem like real users fictional details such as a majordepartment and other biographical information were added along with goals frustrations and a representative quote which were based partly on data and partly on knowledge and past experiences with users While biographical details help make personas more relatable it is important to remember that these are merely examples that are certainly not representative of all the real people who could be affiliated with that persona Not all undergraduate students for example are inexperienced researchers or education majors for that matter 

To keep our set of personas small and focused on representing broad user needs we compared and combined each of the personas created by the group into a final set of nine initial protopersonas These represented each important user type we identified as well as different levels of research technical emotional and locationrelated attributes figs 19 In all two undergraduates three graduate students three faculty members and one community member were kept in our final selection Although undergraduates make up the majority of our user population we felt our graduate student personas could also stand in for more advanced and academically motivated undergraduates so only two undergraduate personas were kept The group also felt that only one community member persona was necessary to adequately meet the broad design needs for our main website 


Figure 1

Traditional undergraduate protopersona



Figure 2

Nontraditional undergraduate protopersona



Figure 3

Beginning researcher graduate student protopersona



Figure 4

Intermediate researcher graduate student protopersona



Figure 5

Regional campus graduate student protopersona



Figure 6

New faculty member protopersona



Figure 7

Tenured faculty member protopersona



Figure 8

Regional campus faculty member protopersona



Figure 9

Community patron protopersona


This initial round of persona creation was by no means a complete picture of our user population While we had a lot of data related to the needs and approaches taken by undergraduates and graduate students we had to draw from experience and make assumptions to fill in details for our faculty and communityoriented personas making these inherently less reliable As a future step for improving our personas we plan to collect additional data to help validate our assumptions and improve our understanding of these groups To avoid leaving the impression that specific user groups could only be associated with certain personas we replaced our initial persona names based on user type with generic names that would suggest their general background such as Pam the Professional By downplaying user type and other biographical information that McKay 2011 suggests is unnecessary we hoped our personas would illustrate how patrons from different disciplines backgrounds and educational levels could actually be very similar in terms of research behaviors library use and needs and other core characteristics 

Persona Development Phase Two

To improve our basic personas the group felt we needed to validate the conclusions drawn from our initial data set and incorporate a more complete and consistent voice of library users We also felt it was important to include more perspectives from our regional campus and distance users which are key to USUs landgrant mission as well as undergraduate students in general in order to develop more diverse personas To address this weakness we decided to conduct indepth interviews and usability tests with students at one of USUs regional campuses in the second phase of our persona development process We also subjected our draft personas to several rounds of review by subject librarians and all library staff members with subject librarians in particular being asked to validate our assumptions against their knowledge and experience


Interviews and Usability Testing

Brief interviews and usability tests were conducted with eleven undergraduate students at one of USUs regional campuses using questions based on a persona creation project conducted by North Carolina State University which was specifically focused on library users and could be easily adapted for our purposes NCSU Libraries 2010 Over the course of a thirtyminute interview students were asked about their online habits perceptions of the library the services they used and what they typically did at different stages of the research process See the Appendix for the complete interview questionnaire

Speaking with and hearing from students directly allowed us to develop a better sense of the student voice and perspective which was difficult to glean from the disparate data in our initial analysis Quotes from these interviews were adapted into both of our undergraduatefocused personas Interviews and usability tests also provided insight into students academic habits validating much of what we anecdotally understood about traditional undergraduates namely that web usage figures heavily into their daily lives including their academic work and research We also learned that while some regional campus students had unique needs and approaches in many ways undergraduate students shared a lot in common regardless of how or where they took classes A more important factor was whether a student was traditional collegeaged or a more nontraditional returning student Compared to the traditional students we interviewed returning students spent more time planning and actively sought help with research projects in advance In this way returning students and other advanced undergrads were very similar to graduate students This validated our chat transcript and reference desk analysis confirming that research experience motivation and user effort were allimportant variables for distinguishing personas types




Staff Feedback and Validation

As an additional step to help improve our personas our nine draft personas were given to subject librarians and displayed prominently on large posters in the staff break room for critique and feedback This area is accessed by nearly everyone who works in the libraryfaculty staff and student workers and all were invited to contribute to and comment on the personas While staff are certainly a secondary data source when it comes to understanding library patrons Pruitt and Grudin 2003 encourage tapping into those that have strong knowledge of and experience working directly with users Drawing on staff as user informants not only provided a rich source of experiential information about users it was also a great way to introduce personas and encourage buyin from groups who otherwise might not have been engaged in the process While this feedback was useful for filling in gaps in our understanding of faculty members graduate students and other advanced library users it cannot replace the role of observational research in truly understanding users from their own perspectives Edeker  Moorman 2013



Final Personas

After analyzing feedback from staff and incorporating more information about undergraduates from our interviews the group reconvened to finalize our draft personas It was clear that there was too much overlap between our original personas and to ensure we had an effective memorable set we decided to fold characteristics of our regional and online users into our traditional undergraduate and graduate student personas The remaining six personas were refined through several rounds of editing and condensed to fit into a smaller trading card style format see figs 1012 These pocketsized personas were printed and distributed to every library department and several conference rooms making them easy to bring to meetings or pin around our desks and helping encourage staff to actively adopt them Pruitt and Grudin 2003 reported success using similar strategies printing personas in a variety of formats to help evangelize persona information and use We are still assessing whether this format has been successful and what more might be needed to encourage persona adoption

The front of each persona includes a name biographical information a picture to help illustrate the character and a quote based on real comments from our interviews and assessment data On the back persona characteristics are categorized as key attributes goals and frustrations as well as sliding scales representing the personas relative level of research skill technical skill which we define as including both general technology literacy and specific literacy with library technology and personal motivation and effort These scales are largely assumptive reflecting a possible range of levels within our user community In the future these scales are one area that could be improved with data for instance a systematic analysis of reference transactions similar to the persona project from New York University TempelmanKluit  Pearce 2014 


Figure 10

Front and back of undergraduate studentaffiliated personas



Figure 11

Front and back of facultyaffiliated personas



Figure 12

Front and back of graduate student and community memberaffiliated personas


So far our personas have proven to be a practical and easy to implement tool for our web design process Our persona trading cards are a common sight at design meetings and have been particularly useful during the earlier stages when project needs are being identified and discussed Personas are used to evaluate everything from copy and content to layout and visual design of the page By starting with our personas stakeholders are forced to analyze the target user audience by prioritizing which users should be the focus of the design and what information and features are necessary to meet their goals For example when planning the design of a landing page for our digitized collections we identified students community users and faculty as important users But after analyzing our personas and considering their unique goals it became clear that faculty would have very different needs related to scholarly communication and the institutional repository This clarified the purpose of the design project illustrating a need for two separate pages one focused on educating and promoting the repository to faculty and another where the repository was presented as a distinct collection In the future we plan to apply personas more broadly to the entire library user experience including both digital and inperson interactions and services For example journey maps could be created to illustrate different stages where personas interact with the library showing critical points where users struggle and helping improve the overall service experience

Theres a lot of room to improve how well our personas reflect knowledge of different users within our community For instance by nature of the service points and sources we were analyzing the data were more focused on undergraduate and graduate student populations These are certainly not the only important user groups for our library More data particularly observational research into faculty members and other less visible user groups will help ensure our personas reflect greater diversity while limiting the influence of assumptions in design process Knowing that our user community is constantly changing it will also be important to ensure our personas continue to represent growing needs and new patterns of use As we learn more about our users drawing regularly from staff feedback and ongoing user research our personas can be refined in order to stay relevant both as a reflection of our users and a practical tool for the design process 

In addition some technical improvements could be made to make the personas more usable as a design tool For example in order to limit the risk of personas being used to stereotype users the biographical details might be updated to make it clear they are only examples and suggest ways in which a persona could be affiliated with multiple user types Supplemental and supporting documents for example instructions explaining the purpose of personas or showing how to use them during design or assessment work could also improve the likelihood that personas become a regular part of our practice 

Discussion 

By establishing a concrete definition of users and their motivations and goals personas provide a reminder to think deeply about users and keep them in mind throughout the design process Instead of a vague fluid definition of users personas allow for a shared context and create a common language for usercentered design making them particularly useful for the collaborative approaches often employed in library web design Unlike reports and other communication tools personas are also a highly relatable format for presenting UX research and encouraging staff to empathize with library users Our lowcost approach to persona development draws heavily from existing user research and internal knowledge which allowed us to quickly create and put personas into practice Moreover by treating personas as living documents that will be regularly refined with user research persona documents can remain a reflective and relevant tool for our organization In this way we view personas as an important part of our UX strategy providing a critical communication tool for ongoing user research and supporting our continuous design philosophy 

After adopting personas we have already observed improvements in how we communicate and make decisions regarding the design and management of our website By shifting focus to users as the standard for evaluating website success we now have a clearer design philosophy guided by better processes for designing and prioritizing web development projects We also have a shared vocabulary for understanding users and communicating their needsone that is meaningful for both programmers and service staff This helps break down communication barriers and avoid misunderstandings fostering collaboration and a culture where anecdotes assumptions and individual preferences are eschewed in favor of an evidencebased and userfocused approach to design

Libraries have traditionally valued a userfocused and consensusdriven approach to the development and design of library collections and services But as library professionals it can often be challenging to distinguish our own preferences and assumptions from the real trends and needs in our communities putting these values at risk Personas with their usercentered and teamoriented qualities provide a practical solution to this problem helping separate real from perceived needs and offering a sharper lens for design and UX work in libraries 

References

	Ballard A  TeagueRector S 2011 Building a library website Strategies for success CRL News 72 3 Retrieved from httpcrlnacrlorgcontent723132full

	Brigham T J 2013 Personas Stepping into the shoes of the library userMedical Reference Services Quarterly324 443450
	Cooper A 1999 The inmates are running the asylum Indianapolis SAMS
	Cooper A 2008 The origin of personas Retrieved from httpwwwcoopercomjournal20085theoriginofpersonas

	Cunningham H 2005 Designing a web site for one imaginary persona that reflects the needs of many Computers in Libraries 259 1519
	Edeker K  Moorman J 2013 Love hate and empathy Why we still need personas Retrieved from httpuxmagcomarticleslovehateandempathywhywestillneedpersonas

	Fox R 2014 Dramatis personaeOCLC Systems  Services302 6973 
	Goodwin K 2002 Getting from research to personas Harnessing the power of data Retrieved from hhttpswwwcoopercomjournal200805gettingfromresearchtoperso

	Goodwin K 2008 Perfecting your personas Retrieved from httpwwwcoopercomjournal200108perfectingyourpersonas

	Guenther K 2006 Developing personas to understand user needs Online 305 4951
	Harley A 2015 Personas make user memorable for product team members Retrieved from httpswwwnngroupcomarticlespersona

	Khaled AlShboul M  Abrizah A 2014 Information needs Developing personas of humanities scholars The Journal of Academic Librarianship 405 500509 Retrieved from httpdxdoiorg101016jacalib201405016

	Koltay Z  Tancheva K 2010 Personas and a usercentered visioning processPerformance Measurement  Metrics 112 172183 
	Lewis C  Contrino J 2016 Making the invisible visible personas and mental models of distance education library users Journal of Library  Information Services in Distance Learning 1012 1529 doi1010801533290X20161218813
	Maness J Miaskiewicz T  Summer T 2008 Using personas to understand the needs and goals of institutional repository users DLib Magazine 149 Retrieved from httpwwwdliborgdlibseptember08maness09manesshtml

	McKay E 2011 Personas Dead yet Retrieved from httpwwwuxdesignedgecom201106personasdeadyet

	NCSU Libraries 2010 Persona interviews for website redesign User studies Retrieved from httpwwwlibncsueduuserstudiesstudies2010personainterviewsredesign NOTE NCSU removed the persona project documents from their website but the report is still available from the Web Archive
	Norman D 2004 Adhoc personas  empathetic focus Retrieved from httpwwwjndorgdnmsspersonasempathhtml

	Phillips D 2012 How to develop a user interface that your real users will love Computers in Libraries 327 615
	Pruitt J  Adlin T 2010 The persona lifecycle Keeping people in mind throughout product design San Francisco Morgan Kaufmann
	Pruitt J  Grudin J 2003 Personas Practice and theory Proceedings of the 2003 Conference on Designing for User Experience San Francisco CA
	Rohrer C 2014 When to use which userexperience research methods Retrieved from httpswwwnngroupcomarticleswhichuxresearchmethods

	Schmidt A 2011 Resist that redesign Library Journal 136 4 21 
	Schmidt A 2012 Persona guidance The user experience Library Journal Retrieved from httpljlibraryjournalcom201210opinionaaronschmidtpersonaguidancetheuserexperience

	TempelmanKluit N  Pearce A 2014 Invoking the user from data to design College  Research Libraries 755 61640
	Turner K  Turner S 2011 Is stereotyping inevitable when designing with personas Design Studies 321 3044 
	Zaugg H  Rackham S 2016 Identification and development of patron personas for an academic library Performance Measurement  Metrics 172 124133 doi101108PMM0420160011


Appendix

Interview Questions based on questions from NCSUs persona project NOTE NCSU removed the persona project documents from their website but the report is still available from the Web Archive

	Background Information
	What is your class statusyear in school
	What is your major If you havent declared a major what areas are you interested in
	Have you taken ENG 1010 or 2010 or have you ever had a class that visited the library or had a librarian guest lecture 



	ComputerOnline Use
	Can you take me through your typical online routine When you open up a web browser what sites do you usually check out
	Do you have any other favorite websites ie news sites social media email etc



	Academic Information
	Describe a typical assignment for a class in your major How do you approach that task



	Library Information
	How often do you go to the library
	How would you describe your campus library to a friend who has never been there
	What frustrates you about using the library
	How often do you go to the library website
	What frustrates you about using the library website
	Youve been given an assignment to write a term paper on the dangers of sports with at least four sources cited throughout the paper
	What is the first thing you do
	How would you look through results to determine the four sources you want to use
	What is the thing that makes you most nervous about this assignment
	How would you fit those sources into your paperargument 
	You have been given two weeks to complete this assignment When would you typically start



	When was the last time you talked to a librarian What was the conversation about





To create your own personas based on our design see our persona templates 




Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS






















































An Overview of the System Usability Scale in Library Website and System Usability Testing


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










An Overview of the System Usability Scale in Library Website and System Usability Testing




Brandy Klug

GIBSON D LEWIS HEALTH SCIENCE LIBRARY

UNIVERSITY OF NORTH TEXAS HEALTH SCIENCE CENTER



Skip other details including permanent urls DOI citation information
Volume 1 Issue 6 2017



DOI httpdxdoiorg103998weave125356420001602



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













This paper was refereed by Weaves peer reviewers


Abstract


The System Usability Scale or SUS was created in 1986 by John Brooke and has been used extensively by a variety of industries to test numerous applications and systems The SUS is a technology agnostic tool consisting of ten questions with five responses for each question ranging from strongly agree to strongly disagree Incorporating the SUS into library website and system usability testing may offer several benefits worth considering however it does have some very specific limitations and implementation challenges This article summarizes examples in library and general literature of how the SUS has been incorporated into usability testing for websites discovery tools medical technologies and print materials Benefits and challenges of the SUS best practices for incorporating the SUS into usability testing and grading complexities are also examined Possible alternatives and supplementary tools such as singleitem scales or other evaluative frameworks such as the UMUX UMUXLITE or SUPRQ are also briefly discussed    


Introduction

The System Usability Scale or SUS was created in 1986 by John Brooke as a quick and dirty way to measure the usability of products Usabilitygov nd It has been used extensively by various industries to test numerous systems and applications including hardware software mobile devices websites and applications Usabilitygov nd The SUS is widely referred to as an industry standard in the business and technology industries although Brooke has noted it has never been through any formal standardization process 2013 p 29

The SUS is a simple tenitem scale giving a global view of subjective assessments of usability Brooke 1996 p 6 There are five responses for each question ranging from strongly agree to strongly disagree SUS scores range between 1100 and 68 is considered the average score Sauro 2011c Scores are affected by the complexity of both the system and the tasks users may to perform before taking the SUS Condit Fagan Mandernach Nelson Paulo  Saunders 2012 p 90

The ten items on the scale are as follows

	I think that I would like to use this system frequently
	I found the system unnecessarily complex
	I thought the system was easy to use
	I think that I would need the support of a technical person to be able to use this system
	I found the various functions in this system were well integrated
	I thought there was too much inconsistency in this system
	I would imagine that most people would learn to use this system very quickly
	I found the system very cumbersome to use
	I felt very confident using the system
	I needed to learn a lot of things before I could get going with this system


There are several potential benefits of incorporating the System Usability Scale into library website and system usability testing The SUS has been in use for approximately 30 years and is a reliable tested tool for evaluating a wide range of products and systems It is also customizable and easily administered via simple survey tools like Survey Monkey or more advanced survey distribution tools like Qualtrics The data it provides has a variety of uses It can be used as a benchmark to measure how changes to a system or product are received by users Or it can be used to quantify user reaction to two alternatives such as two different versions of the same web page or two different user interfaces so that they can be compared for decisionmaking purposes When used in conjunction with data gathered from other sources such as usability testing it can be a helpful supplemental tool for researchers who need to collect a source of big picture quantitative data that can be easily communicated to library administration and stakeholders

The SUS does have some specific limitations and implementation challenges Depending on the website or system being tested SUS data may have very limited value on its own Grading the SUS is also a complex process that can potentially lead to scoring errors if not executed properly and calculated grades must be normalized to produce a percentage Usabilitygov nd Another possible issue is the SUS scale alternates between positive and negative statements and this may cause confusion for participants when completing the scale Odd statements on the scale are positively worded with the number 5 being the highest score and even statements on the scale are negatively worded with the number 1 being the highest score Libraries who want the kind of data the SUS can provide but find its shortcomings prohibitive may wish to look into other similar options as possible alternatives or as supplementary tools such as singleitem scales or other evaluative frameworks such as the UMUX UMUXLITE or SUPRQ which are also discussed briefly in this article1  

SUS in the Literature


In Libraries

The SUS has been referenced in more than 1300 articles and publications Usabilitygov nd including many library and information sciences publications detailing its use in testing various library systems and applications such as websites and discovery tools Usability testing where the SUS is used to gather data from participants after completing a series of tasks using a discovery tool such as Primo EDS or Encore are the most typical cases noted in library and general literature The literature also includes studies in which the SUS is used to test other systems such as scholarly repositories The majority of tests noted in library and general literature utilize the SUS with usability methods as a means to gather data answer research questions and identify general painpoints that users encounter when interfacing with a website or system 

Perrin Clark DeLeon and Edgar 2014 incorporated the SUS into usability testing of the Primo discovery tool at Texas Tech University Libraries Participants were given seven tasks to complete including find a book and find a thesis followed by the SUS The data gathered using the SUS helped researchers come to the conclusion that overall the implementation of OneSearch was successful at least in terms of how students perceived it after using it while additional data obtained during task completion such as task time error rate and success rate helped to identify specific problems with the interface Perrin et al 2014 p 59

Condit Fagan Mandernach Nelson Paulo and Saunders 2012 incorporated the SUS into a usability evaluation of the EBSCO Discovery Service at James Madison University Libraries The SUS was administered to participants after a series of nine tasks designed to showcase usability issues show the researchers how users behaved in the system and measure user satisfaction followed by a posttest consisting of six openended questions plus one additional question for faculty participants intended to gather more qualitative feedback about user satisfaction with the system Condit Fagan et al 2012 p 90 Additional posttest questions revealed that some participants found EDS overwhelming or confusing and data gathered from administering the SUS supported the data gathered during the posttest process Condit Fagan et al 2012 p 98 The SUS was also utilized as a benchmarking tool to measure usability over time and note improvements from testing done in spring 2010 and testing done in fall 2010

Johnson 2013 also incorporated the SUS into usability testing to compare the Encore discovery tool versus a tabbed layout on the library website at Appalachian State Libraries Participants were asked to complete four tasks on the website using the tabbed layout and using an Encore search box in place of the tabbed layout Tasks included locating a known book finding journal articles related to certain topics and to search for materials on a topic they had recently written about Participants were also asked followup questions after or during each task After completing the tasks on each interface users were asked to complete the SUS The average SUS scores for the website design with the Encore search box was 715 versus 68 for the original tabbed layout The author noted the SUS scores were a way to benchmark how usable the participants rated the two interfaces Johnson 2013 p 65

In an atypical case in the literature Zhang Maron and Charles 2013 document usability testing at Purdue University Libraries for a research repository and collaboration website known as the HumanAnimal Bond Research Initiative Central Research Repository The purpose of testing was to have participants engage in various tasks using the repository such as finding an article in the repository submitting an article to the repository adding bibliographic information of an article in the repository and using interaction features such as user groups Zhang et al 2013 p 58 Following the completion of assigned tasks testing participants were asked a series of openended questions and to complete the System Usability Scale to rate their experience using the system SUS scores were used in conjunction with five other response measures including successfulness of each task whether participants needed help from the researcher during each task number of steps of the navigational path participants went through in each task time to complete each task participants comments during each task in order to gauge overall attitude and experience regarding usage of the tool Zhang et al 2013 p 71 Although researchers were able to identify some usability problems through participant observation such as HABRI Centrals article submission workflow user input design and positions of certain interface elements the SUS provided researchers with data that indicated participants rated the repository highly overall Zhang et al 2013 p 72




Beyond Libraries

There are also numerous studies documented in broader literature that incorporate the SUS for testing a variety of products and tools including websites medical technologies decision aids and print materials A few representative examples from the fields of education and medicine are summarized below 

Tsopra Jais Venot and Duclos 2014 used the SUS when testing clinical decision support systems interfaces The purpose of the study was to have general practitioners interact with two interfaces in order to compare an interface design that focuses on decision processes versus an interface design that focuses on usability principles SUS scores the number of correct responses for ten clinical cases and the confidence level measured with a 4point Likert scale for each interface were assessed and it was determined the interface designed according to usability principles was more usable and inspired more confidence among clinicians Tsopra et al 2014 p e107 The authors state that a separate analysis of the data gathered from SUS questions uncovered that 915 percent of participants didnt feel they would need technical assistance to use the design focusing on usability principles versus 771 percent of participants using the design focusing on decision principles Tsopra et al 2014

Li et al 2013 document usability testing for a webbased patient decision tool for rheumatoid arthritis patients referred to as ANSWER Animated Selfserve Webbased Research tool The purpose of the study was to assess the usability of the ANSWER prototype and identify strengths and limitations of the ANSWER from the patients perspective Li et al 2013 p 131  A group of fifteen participants were asked to use ANSWER and verbalize their thoughts during the process Li et al 2013 p 131 In addition to observing participants and taking field notes the testing was also audiotaped The authors indicate ANSWER scored well on the SUS in earlier testing 8125 and after changes were implemented 81 therefore indicating ANSWER had met the standard of a userfriendly program Li et al 2013 p 138 However data gathered from the thinkaloud sessions illustrated ideas that required further refinement supporting the use of the formative evaluation along with the summative evaluation in usability testing Li et al 2013 p 138

Grudniewicz Bhattacharyya McKibbon and Straus 2015 document the process of updating printed education materials and testing usability via methods including the SUS These materials were redesigned using physician preferences design principles and graphic designer support and physicians were asked to select whether they preferred the redesigned version of the document or the original Grudniewicz et al 2015 p 156 This process was followed by an assessment of usability with the System Usability Scale and a think aloud process Grudniewicz et al 2015 p 156 The purpose of the study was to determine whether or not the redesigned materials better meet the needs of primary care physicians and whether usability and selection are increased when design principles and user preferences are used Grudniewicz et al 2015 p 157 Ease of use was measured using the System Usability Scale and scores for the redesigned materials were significantly higher The wording of the SUS was adjusted slightly in this case to reflect that print materials were being tested rather than a system Grudniewicz et al 2015



Benefits of Using the System Usability Scale SUS 


SUS is a Reliable Tested Tool for Gathering Quantitative Data

There are many valid reasons to consider incorporating the System Usability Scale SUS into library website and system testing Since the SUS has been available for approximately 30 years and a considerable amount of research has indicated that the SUS has excellent reliability it can be used with confidence on both large and small sample sizes Lewis Utesch  Maher 2015 p 497 Test participants can complete the scale quickly making it an easy way to gather quantitative data whether used on its own or in conjunction with other quantitative and qualitative measures Usabilitygov nd As indicated in library and broader literature SUS data can help provide a more complete picture of the attitudes toward a website or system being tested when used in conjunction with usability test measures such as timed tasks and the number of tasks successfully completed Together the results of these measures provide researchers with a clearer understanding of the specific pain points users have identified in a system

The SUS is also free easy to set up and administer to participants online or in print and technology agnostic Usabilitygov nd Because of this researchers can continue to incorporate the SUS as technologies change and develop without having to worry about updating or recreating questionnaires Brooke 2013 Another benefit of using a technology agnostic tool like the SUS is that scores can be compared regardless of the technology and the same set of scores can be used by an organization to benchmark both standard websites and other tools such as catalogs and discovery layers Sauro 2015 p 69




SUS Results are Easy to Share and Understand

In an analysis of the System Usability Scale Bangor Kortum and Miller note the survey provides a single score on a scale that is easily understood by a wide range of people from project managers to computer programmers 2008 p 574 Kortum and Bangor note that subjective usability scores gathered through administering questionnaires like the SUS provide a common language for a number of groups from web designers to managers to describe and discuss the usability attributes of a system 2013 p 68 Measures from other kinds of tests such as the average amount of time to complete a task for example may have little or no meaning to groups like developers without specific detailed knowledge of that task and other comparable tasks Kortum  Bangor 2013 p 68 The simplicity of SUS scores may make sharing data with an organizations administration and stakeholders far less complicated and time consuming than synthesizing and communicating the importance and meaning of other types of data gathered throughout the usability testing process

Tracking SUS scores on the same system over a period of time is also a simple way to communicate to stakeholders how system performance has improved or declined SUS data that indicates scores have improved over time may be useful to researchers needing to justify the time effort and resources expended for the usability testing process to administration As previously noted Condit Fagan et al 2012 used the SUS to benchmark for system improvement when testing the EBSCO Discovery System across semesters p 102  Johnson 2013 also notes the SUS was used to benchmark our students initial reaction to an external Encore discovery tool versus a tabbed layout on the library website p 65 If SUS scores on a particular system have declined over time researchers may be able to use this data to justify the need for more usability testing resources in order to make necessary improvements 

When comparing the usability and functionality of two or more products the SUS also provides a straightforward way to communicate to stakeholders how well a product performed compared to a similar product or products As noted by Johnson 2013 having participants complete the SUS after completing tasks on an existing tabbed layout and on an interface which incorporated the Encore discovery tool indicated the website design with the Encore search box was the preferred choice 




SUS is Customizable

Research indicates that minor modifications can be made to System Usability Scale  without changing the results Bangor Miller and Kortum 2009 conducted testing where an additional adjective scale was added as an eleventh question to the SUS and administered to 964 participants The purpose of this addition was to address the question what is the absolute usability associated with any individual score Bangor et al 2009 p 117  The question asked participants to rate the userfriendliness of a product or website as worst imaginable awful poor OK good excellent or best imaginable Findings indicated that the scale ratings were a close match to SUS scores and the inclusion of an additional scale may be useful for providing a subjective label for an individual studys mean SUS score Bangor et al 2009 p 119

The SUS is also insensitive to minor changes in its wording therefore it can be edited to reflect the type of system or material being tested Lewis et al 2015 p 497 For example the word system which is used in all ten items of the SUS can be changed to website Minor wording changes can also be made to reflect that print materials are being tested rather than a system As previously noted Grudniewicz et al 2015 made minor wording adjustments to reflect that printed education materials were being tested rather than a computer system 



Challenges of Using the System Usability Scale


SUS May Have Limited Value When Used On Its Own

A benefit of the SUS is that it is a technology agnostic tool that can be used to rate a variety of products however this trait may make it a liability when testing library websites and systems because the disadvantage of a technology agnostic instrument is that it can omit important information that is specific to an interface type Sauro 2015 p 69

Using the SUS on its own will provide a source of quantitative data for researchers but it may be difficult to understand why users assigned a website or system a low or high score without additional qualitative and quantitative measures Sauro 2011c SUS scores provide information about how usable a website or system is however they wont tell you much about whats unusable or what to fix or provide insight into which facets of the system are functioning well Sauro 2011c It may be necessary to gather more information on why participants like or dislike the product in order to make informed decisions For example item 2 of the SUS is I found the system unnecessarily complex If a participant rates this question as strongly agree this is useful to researchers because it identifies a possible issue with the system The researchers will not know specifically however which elements of the system caused the user to struggle Openended questions added to the end of the SUS may be useful for identifying specific issues with the system that need to be addressed However a better solution might be to utilize a more diagnostic instrument in addition to or instead of the SUS such as the UMUX UMUXLITE or SUPRQ if more detailed information on specific problems is desired Finstad 2010b Sauro 2015 The questions on the SUPRQ for example address website specific issues such as navigation and look and feel Sauro 2015

There is one specific situation in which administering the SUS alone may be beneficial when evaluating commercial systems that the library has no ability to customize In such situations locating the exact source of problems may be less important than determining whether such problems exist and rating their relative severity The SUS could for example potentially be helpful in evaluating the user interface of commercial library databases and assisting in purchasing decisions




SUS Structure May Be Confusing and Frustrating to Test Participants

Another disadvantage of administering the SUS is the scale structure may be confusing and frustrating to test participants The number 5 on the scale is the highest score for odd numbered questions on the SUS and the number 1 is the highest score on even numbered questions According to Sauro the purpose of this pattern is to reduce acquiescent bias users agreeing to many items and extreme response bias Sauro 2011c Although it is a standard psychometric practice to vary item tone this variation can have negative consequences Lewis et al 2015 p 497 as participants may be used to taking surveys where the highest number on the scale is considered the best score throughout the entire survey and the lowest number on the scale is considered the worst score throughout the entire survey Sauro also notes that if a test participant has strong feelings for or against a website or system they may go through all ten SUS questions and forget to reverse their answers and therefore respond incorrectly by selecting all 1s to indicate a weak product or all 5s to indicate a strong product Sauro 2011c

Research by Finstad 2006 also noted the wording of the SUS may pose issues for some nonnative English speakers This can be problematic if participants do not feel comfortable asking researchers for question clarification in a supervised testing environment or do not have the option to ask for clarification in an unsupervised testing environment Finstad 2006 One issue noted was lack of familiarity with the word cumbersome which is used in item 8 I found the system very cumbersome to use Finstad suggests that changing cumbersome to awkward may help ease confusion in such cases Finstad 2006 p 186 Another issue detected by Finstad was with questions seven eight and nine and the use of the word very to indicate that participants felt the system could be learned very quickly the system was very cumbersome to use and whether or not they felt very confident using the system 2006 p 186 A testing participant noted concern that agreeing to question nine would automatically categorize him as very confident when he was more comfortable agreeing he was simply confident Finstad 2006 p 186

Participants may also experience frustration with the 5point Likert items in the SUS if they feel the available options which include strongly disagree disagree neither agree nor disagree agree and strongly agree dont accurately capture their attitudes and feelings about the website or system being tested Additional research by Finstad 2010a indicates that a 7point Likert scale with the options entirely disagree mostly disagree somewhat disagree neither agree nor disagree somewhat agree mostly agree and entirely agree may be a better option because it is more likely to reflect a respondents true subjective evaluation of a usability questionnaire item than a 5point item scale p 108 



Best Practices for Incorporating the SUS into Usability Testing


Administering the SUS to Users

Typical library website or system testing often involves a series of tasks where researchers observe participants and gather specific data throughout the process such as the number of tasks completed task completion time and comments made by the participants while completing tasks When incorporating a standardized questionnaire such as the SUS along with tasks and other measures into usability testing researchers should carefully consider their administration for the proper management of satisfaction outcomes Borsci Federici Bacci Gnaldi  Bartolucci 2015 p 493 Administering questionnaires at the proper point in testing as well as providing clear and concise instructions to participants are essential for accurately measuring user satisfaction Borsci et al 2015 Since the SUS alternates between positive and negative statements reminding users upfront for instance of the alternative nature of the SUS statements for rating products properly should be kept in mind Muddimer Peres  McLellan 2012 p 63

Ideally the SUS or any standardized questionnaire is administered to the testing participant as soon as they have tested the system and completed all tasks McLellan et al 2012 This helps ensure the participant remembers everything they liked and disliked about the system in order to provide an accurate summation McLellan et al 2012 Brooke also notes that respondents should be asked to record their immediate response to each item rather than thinking about it for a long time 1996 p 8 however he does not make any recommendations for imposing an actual time limit on participants completing the SUS




Randomizing the Order of System Tests

When administering a series of identical tasks to participants to compare two or more products the tasks may become easier for participants to complete as they are repeated This may lead to a higher SUS score for the product being tested last regardless of how usable it is To avoid this researchers should consider alternating the order in which tools are tested from one participant to the next when testing multiple systems or websites




Understanding Users Prior Use

Prior use and experience with a website or system can impact scores on poststudy questionnaires like the SUS which may cause additional challenges for researchers Sauro found that prior experience boosted usability ratings 11 percent for websites and consumer software 2011a Borsci et al noted that when testing systems the overall level of satisfaction will be higher than that among less experienced users 2015 p 494 Researchers may want to recruit testing participants with no or limited experience with the website or system being tested since users may rate a system they are familiar with higher than a system they are unfamiliar with even if the unfamiliar product is more usable Sauro 2011a  



Scoring the SUS


Calculating Scores

The System Usability Scale has a complex grading structure which may increase the likelihood of miscalculating scores Brooke 2013 As previously discussed in the SUS instrument even and odd questions are scored differently Odd questions are scored 04 based on the 15 selection where a selection of 1 equals 0 points a selection of 2 equals 1 point and so on Sauro 2011b Even questions are scored 40 on the 15 selection where a selection of 1 equals 4 points a selection of 2 equals 3 points and so on Scores for all ten questions are added up for a total score between 040 points This total is multiplied by 25 to generate a SUS score between 0100 points As you can see this means calculating the scoring especially doing so manually can be a bit tricky Assigning the wrong point total to a question is very easy especially since the scales are not consistent from question to question and this can throw off the entire final score Survey tools may be helpful in minimizing scoring errors Simple survey tools such as Survey Monkey can be used to administer the SUS and assign the correct number of points based on each selection of the scale This data can be exported into Excel where formulas can be applied to calculate the final scores More advanced survey tools such as Qualtrics can be set up so the correct number of points is automatically assigned to each selection on the scale and final scores are tabulated automatically when the survey is submitted 

Figure 1 shows an example of a graded SUS questionnaire The total score for this example is 26 Multiplying 26  25 gives us a SUS score of 65


Figure 1

Graded SUS questionnaire demonstrating how the score for each of item of the SUS is determined with odd questions scored 04 based on the 15 selection and even questions scored 40 based on the 15 selection


Another challenge of SUS scoring is once the completed score is calculated there is a tendency for scores between 0 and 100 to be perceived as percentages when in fact normalization of the score is required to calculate a percentage Brooke 2013 p 35 




Normalizing Scores

It is important to remember that raw SUS scores are not percentages Sauro 2011b and it is necessary to normalize scores in order to produce a percentile ranking Usabilitygov nd Sauro notes that based on analysis of more than 5000 user scores encompassing almost 500 studies across a variety of application types 2011c the average SUS score is 68 with a standard deviation of 125 Sauro  Lewis 2016 A SUS score of 68 is in the 50th percentile which means the score is higher than 50 percent of all tested systems and applications Sauro 2011c 

SUS scores can also be translated into letter grades which may be helpful for communicating results to stakeholders Since the average SUS score is 68 Sauro  Lewis 2016 note they prefer to grade on a curve in which a SUS score of 68 is at the center of the range for a C p 203 As shown in table 1 the full C range is from 650710 Sauro  Lewis 2016 The scale also indicates a SUS score of 789 or above would constitute an A or above while a SUS score of 516 or below would constitute an F Sauro  Lewis 2016 

Table 1 Curved grading scale interpretation of SUS scores 

	Letter grade	Numerical score range
	A	841100
	A	808840
	A	789807
	B	772788
	B	741771
	B	726740
	C	711725
	C	650710
	C	627649
	D	517626
	F	0516




Other PostStudy Questionnaires

For libraries that want the kind of data the SUS can provide but find its shortcomings too difficult to deal with there are a range of other similar instruments available as possible supplements to or replacements of the SUS Many of these tools are shorter and easier to score than the SUS I include here a brief discussion of four such tools for libraries interested in investigating other options


SingleItem Adjective Rating Scale

For some libraries a singleitem scale may provide a good alternative to the SUS or serve as a good supplement to the SUS when added as an additional item to the scale Bangor et al 2009 Singleitem scales are easy to score and they produce simple transparent big picture data that can easily be shared with administrators and other stakeholders Bangor et al 2009 As previously noted Bangor et al added an adjective rating scale fig 2 to the end of the System Usability Scale questionnaire and found that Likert scale scores correlate extremely well with the SUS 2009 p 114 


Figure 2

The 7point adjective rating scale added as an eleventh question to the SUS and administered to usability participants by Bangor et al 2009


Even though a strong correlation between the SUS and the singleitem rating scale was found Bangor et al 2009 caution against using a singleitem scale on its own and recommend using it in conjunction with objective measures such as task success rates or timeontask measures p 119 so that specific system problems can be identified 




UMUX

Although the SUS is a quick scale practitioners sometimes need to use reliable scales that are even shorter than the SUS to minimize time cost and user effort Borsci et al 2015 p 485 The Usability Metric for User Experience UMUX was developed to provide an alternate metric for perceived usability for situations in which it was critical to reduce the number of items while still getting a reliable and valid measurement of perceived usability Lewis et al 2015 p 498 The UMUX is similar to the SUS in that odd numbered items have a positive tone and even numbered items have a negative tone Lewis et al 2015 The UMUX however has four items instead of ten and has seven rather than five scale steps from 1 strongly disagree to 7 strongly agree Lewis et al 2015 p 498

The four items that comprise the UMUX are as follows

	This systems capabilities meet my requirements
	Using this system is a frustrating experience
	This system is easy to use
	I have to spend too much time correcting things with this system


The UMUX is scored as score  1 for items one and three and 7  score for items two and four Borsci et al 2015 The scores for each item are summed divided by 24 and multiplied by 100 Borsci et al 2015 Borsci et al 2015 note that research incorporating the UMUX has found that the scores have not only correlated with the SUS but also had a similar magnitude p 486 However they recommend that researchers avoid using only the UMUX for their analysis of user satisfaction because it was found it to be too optimistic Borsci et al 2015 p 494 

There are recommendations from researchers on how and when to incorporate the UMUX into usability testing Berkman  Karahoca 2016 note that researchers may benefit from the UMUX and UMUXLITE as lightweight tools to measure the perceived usability of a software system p 107 They also observed the UMUX and UMUXLITE may not be sensitive to differences between the software when comparing very similar systems which may be rated similarly by test participants Berkman  Karahoca 2016 p107 In such studies they suggest using the UMUX in conjunction with another poststudy questionnaire such as the SUS Borsci et al 2015 and Lewis et al 2013 recommend administering both the SUS and the UMUX or UMUXLITE during advanced phases of design Borsci et al note that administering both scales during advanced phases is beneficial as a means to gather more comprehensive data in order to assess user satisfaction with usability 2015 p 494 

Libraries may benefit from using the UMUX as a supplement to the SUS particularly for studies comparing highly similar tools and during advanced phases of design testing The UMUX may also offer a viable alternative as a replacement to the SUS in some circumstances because it consists of only four questions has a high correlation to the SUS consists of questions with seven scale steps rather than five scale steps and has a less complicated grading structure For studies that involve testing only one system or website the UMUX may provide a good alternative to the SUS if utilized in conjunction with usability testing methods which gauge user satisfaction such as task completion and the time it takes to complete a task




UMUXLITE

The UMUXLITE is an even shorter twoitem version of the UMUX It consists only of items one and three the positivetone items from the UMUX instrument Like the UMUX it also utilizes a 7point rating scale Lewis et al 2015 

The two items that comprise the UMUXLITE are

	This systems capabilities meet my requirements
	This system is easy to use


The UMUXLITE is scored as score  1 for both items Lewis 2013 The scores are summed divided by 12 and multiplied by 100 Lewis 2013 In order to create a score that corresponds with the reliability of SUS scores the sum is entered into the regression equation below which produces the final UMUXLITE score Borsci et al 2015 

UMUXLITE  65  Item1 score  Item2 score  210012  229

Borsci et al note that while the UMUX and UMUXLITE are both reliable and valid proxies of the SUS the UMUXLITE with the regression formula appears to have results that are closer in magnitude to the SUS than the UMUX making it the more desirable proxy 2015 p 494 It is worth noting however that the application of the regression formula does add an additional layer of complication when grading the scale 

There are recommendations from researchers on how and when to incorporate the UMUXLITE into usability testing Borsci et al 2015 and Lewis et al 2013 suggest the UMUXLITE may be best used in conjunction with the SUS and not as a replacement Borsci et al 2015 suggest using the UMUXLITE as a preliminary and quick tool to test users reactions to a prototype and then followup with a combination of the SUS and UMUX or UMUXLITE in later testing p 494  

Libraries may benefit from using the UMUXLITE as a supplement to the SUS particularly in more advanced phases of usability testing Although the UMUXLITE has a slightly more complicated grading structure than the UMUX it may still provide libraries with a reliable quick and easy to administer alternative to the SUS for testing websites and systems in very early usability testing phases The two question scale is very quick to administer either online or in print the regression formula produces results which are closer in magnitude to the SUS than the UMUX Borsci et al 2015 and it consists of questions with seven scale steps compared to five scale steps




SUPRQ

The Standardized User Experience Percentile Rank Questionnaire known as the SUPRQ consists of eight items used to measure four website factors usability trust appearance and loyalty Sauro 2015 p 73 The primary advantage the SUPRQ may have over the SUS and UMUX is that it measures more than just a single factor such as usability Sauro 2015 p 84  The SUPRQ was created as the result of a threepart study which spanned a fiveyear period and included over 4000 responses to experiences with over 100 websites Sauro 2015 p 84 This extensive research by Sauro 2015 also found there was evidence of convergent validity with existing questionnaires including the SUS p 84 With the purchase of a SUPRQ full license researchers can administer the questionnaire to an unlimited number of participants paste raw test scores into a calculator to produce normalized scores and percentile ranks and compare results to a database of other websites2  

Seven of the eight questions on the SUPRQ are measured with a 5point scale where 1 equals strongly disagree and 5 equals strongly agree Sauro 2015 p 84 The fifth question asks users how likely they would be to recommend the website using an 11 point scale with 0 being not at all likely and 10 being extremely likely Sauro 2015 p 84 The first two questions on the scale rate usability questions three and four rate trust questions five and six rate loyalty and questions seven and eight rate appearance Sauro 2015 To score the SUPRQ averages are taken for the questions graded on a 5point scale and added to half the score for question five Measuring Usability LLC 2017

The eight items in the SUPRQ are Sauro 2015 p 84 

	The website is easy to use 
	It is easy to navigate within the website 
	I feel comfortable purchasing from the website 
	I feel confident conducting business on the website 
	How likely are you to recommend this website to a friend or colleague 
	I will likely return to the website in the future 
	I find the website to be attractive 
	The website has a clean and simple presentation 


Libraries may benefit from the SUPRQ as a replacement to the SUS for longterm usability projects measuring improvement of different iterations of systems and websites as well as benchmarking how users rate a websites loyalty trust usability and appearance Sauro 2015 p 84 The SUPRQ license features could potentially save libraries a great deal of time with generating scores comparing scores to other websites and reducing the likelihood of scoring errors however it may be difficult for many organizations to justify the license cost 



Conclusion

While using the SUS in library website and system usability testing does present challenges there are also several benefits libraries should consider The SUS offers a quick and easy source of supplemental data for library website and system usability testing in a wide variety of contexts Libraries both large and small can adopt and adapt this tool for the purposes of gaining usability insights and improving the user experience for patrons as long as the specific challenges it presents are known and planned for ahead of time There are a number of other similar tools that can supplement or possibly be used in lieu of the SUS such as the UMUX UMUXLITE or SUPRQ Data from tests such as the SUS can be useful for establishing baselines communicating the impact of changes or aiding in decision making

REFERENCES

	Bangor A Kortum P  Miller J 2008 An empirical evaluation of the System Usability Scale International Journal of HumanComputer Interaction 246 574594 
	Bangor A Miller J  Kortum P 2009 Determining what individual SUS scores mean Adding an adjective rating scale Journal of Usability Studies 43 114123 Retrieved from httpuxpajournalorgdeterminingwhatindividualsusscoresmeanaddinganadjectiveratingscale

	Berkman M I  Karahoca D 2016 Reassessing the Usability Metric for User Experience UMUX scale Journal of Usability Studies 113 89109 Retrieved from httpuxpajournalorgassessingusabilitymetricumuxscale

	Borsci S Federici S Bacci S Gnaldi M  Bartolucci F 2015 Assessing user satisfaction in the era of user experience Comparison of the SUS UMUX and UMUXLITE as a function of product experience International Journal of HumanComputer Interaction 318 484495 
	Brooke J 1996 SUS A quick and dirty usability scale Usability Evaluation in Industry 189194 410 
	Brooke J 2013 SUS A retrospective Journal of Usability Studies 82 2940 Retrieved from httpuxpajournalorgsusaretrospective

	Condit Fagan J Mandernach M Nelson C S Paulo J R  Saunders G 2012 Usability test results for a discovery tool in an academic library Information Technology  Libraries 311 83112 
	Finstad K 2006 The system usability scale and nonnative English speakers Journal of Usability Studies 14 185188 Retrieved from httpuxpajournalorgthesystemusabilityscaleandnonnativeenglishspeakers

	Finstad K 2010a Response interpolation and scale sensitivity Evidence against 5point scales Journal of Usability Studies 53 104110 Retrieved from httpuxpajournalorgresponseinterpolationandscalesensitivityevidenceagainst5pointscales

	Finstad K 2010b The usability metric for user experience Interacting with Computers 225 323327 doi101016jintcom201004004
	Grudniewicz A Bhattacharyya O McKibbon K A  Straus S E 2015 Redesigning printed educational materials for primary care physicians Design improvements increase usability Implementation Science 10 113 doi101186s1301201503395
	Johnson M 2013 Usability test results for Encore in an academic library Information Technology  Libraries 323 5985 
	Kortum P T  Bangor A 2013 Usability ratings for everyday products measured with the system usability scale International Journal of HumanComputer Interaction 292 6776 doi101080104473182012681221
	Lewis J R 2013 Critical review of The usability metric for user experience Interacting with Computers 254 320324 doi 101093iwciwt013
	Lewis J R Utesch B S  Maher D E 2015 Measuring perceived usability The SUS UMUXLITE and AltUsability International Journal of HumanComputer Interaction 318 496505 doi1010801044731820151064654
	Li C L Adam P M Townsend A F Lacaille D Yousefi C Stacey D et al 2013 Usability testing of ANSWER A webbased methotrexate decision aid for patients with rheumatoid arthritis BMC Medical Informatics  Decision Making 131 122 doi1011861472694713131
	Measuring Usability LLC 2017 SUPRQ Standardized UX Percentile Rank Retrieved from httpwwwsuprqcomindexphp

	Muddimer A Peres S C  McLellan S 2012 The effect of experience on System Usability Scale ratings Journal of Usability Studies 72 5667 Retrieved from httpuxpajournalorgtheeffectofexperienceonsystemusabilityscaleratings

	Perrin J M Clark M DeLeon E  Edgar L 2014 Usability testing for greater impact A Primo case study Information Technology  Libraries 334 5766 
	Sauro J 2011a Does prior experience affect perceptions of usability Retrieved from httpwwwmeasuringucomblogpriorexposurephp

	Sauro J 2011b Measuring usability with the System Usability Scale SUS Retrieved from httpwwwmeasuringucomsusphp

	Sauro J 2011c SUStisfied Littleknown System Usability Scale facts User Experience The Magazine of the User Experience Professionals Association 103 Retrieved from httpuxpamagazineorgsustified

	Sauro J 2015 SUPRQ A comprehensive measure of the quality of the website user experience Journal of Usability Studies 102 6886 Retrieved from httpuxpajournalorgsuprqacomprehensivemeasureofthequalityofthewebsiteuserexperience

	Sauro J Lewis J 2016 Quantifying the user experience Practical statistics for user research Amsterdam Waltham MA ElsevierMorgan Kaufmann
	Tsopra R Jais J Venot A  Duclos C 2014 Comparison of two kinds of interface based on guided navigation or usability principles for improving the adoption of computerized decision support systems Application to the prescription of antibiotics Journal of the American Medical Informatics Association 21 e107e116 doi101136amiajnl2013002042
	Usabilitygov nd System Usability Scale SUS Retrieved from httpwwwusabilitygovhowtoandtoolsmethodssystemusabilityscalehtml

	Zhang T Maron D J  Charles C C 2013 Usability evaluation of a research repository and collaboration web site Journal of Web Librarianship 71 5882 doi101080193229092013739041
	




1  Other possible options not discussed in this article include the SUMI Software Usability Measurement Inventory the WAMMI Website Analysis and Measurement Inventory and the Post Study System Usability Questionnaire PSSUQ 

2  More information about the SUPRQ full and limited licenses can be found on Measuring Usability LLC 




Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS






















































A Practical Guide to Improving Web Accessibility


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










A Practical Guide to Improving Web Accessibility




Cynthia Ng

NEW WESTMINSTER PUBLIC LIBRARY



Skip other details including permanent urls DOI citation information
Volume 1 Issue 7 2017



DOI httpdxdoiorg103998weave125356420001701



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	













This paper was refereed by Weaves peer reviewers

Introduction

This article is intended to provide guidance on making library websites and other digital content accessible within the constraints of most organizations technological environments Accessibility can mean different things depending on the context but the focus in this article is on web accessibility which the World Wide Web Consortium W3C defines as enabling people with disabilities to participate equally on the Web W3C 2016 Many existing articles provide an overview of the big picture aspects of accessibility including benefits to the organization see Rowland Mariger Siegel  Whiting 2010 legislation see Fulton 2011 statistics see local census data and general principles see Quesenbery 2014 The focus of this piece will be on specific best practices and guidelines as well as their benefits for content creators who frequently have limited access to edit digital content and cannot always apply recommended solutions that assume full control and access

Benefiting Everyone with Universal Design

Web accessibility is often considered separately from other aspects of web design and development pigeonholing accessibility into a single point on a checklist Quesenbery 2009 instead of being integrated throughout the workflow Unfortunately such practice ignores the fact that accessibility impacts usability findability user experience and other aspects of digital content and affects all users not just those with disabilities Quesenbery 2009 In order to provide a user experience that allows people to achieve their goals accessibility guidelines and best practices need to be integrated into the regular content lifecycle

Understanding accessibility requires us to consider the use of websites and other digital content holistically encompassing

	Hardware including desktop and mobile devices pointing and input devices
	Software including operating system browser assistive software
	Environmental conditions such as lighting Shneiderman  Hochheiser 2001



Figure 1 The user experience honeycomb Source Schofield 2016 used with permission 


Accessibility does not refer only to website design or code creation The vast majority of most library websites are composed of content written and created by contributors outside of the team that maintains a website or digital service or system All aspects of a website or digital services need to be considered when creating or maintaining content see fig 1

Taking so many considerations into account can be difficult but one potential solution is a holistic approach called universal designalso known as universal usability or design for allto enable the widest possible range of users to benefit Shneiderman  Hochheiser 2001 Ensuring that users with disabilities can make use of digital content is vital but most of the recommended guidelines make digital content accessible to a broad range of people not just those with disabilities Thus making content accessible to those with disabilities means it will be more accessible for all users

Making Content Accessible

In many organizations staff are encouraged to create and edit content in a variety of digital systems including content management systems LibGuides and learning management systems In these systems content creators are usually limited to a WYSIWYG What You See Is What You Get editor that offers a very limited range of control over the content and its presentation However it is still possible to make content more accessible by following some content creation best practices


Writing for the Web

While it is easy to focus on the technological aspects of digital content the written text itself also affects accessibility The average person for example can make simple inferences but will have difficulty with lengthy dense text that requires constructing meaning across multiple chunks of text National Center for Education Statistics nd Even without specific accessibility concerns when text is presented in large and long paragraphs users may have more difficulty reading the text and will have to spend more effort referring back and looking for specific pieces of information Well written and spaced text decreases the chances of a reader getting lost thereby improving the likelihood that users find what they want or need and improving user experience

There are many books published on writing for the web but at the core there are three main points to keep in mind when writing content

	Be clear and concise
	Format text to include considerable white space break up longer paragraphs and use bullet points
	Write in simple language with everyday words avoid jargon and acronyms or make sure to explain them


Simple and clear writing improves accessibility particularly for users with reading disabilities and those with difficulty concentrating It is important to have white space so that users can easily scan text and find their spot should they be interrupted Jargon and acronyms can be difficult to mentally parse if they are not part of a users everyday vocabulary and if not properly explained may impede understanding Following these writing guidelines will improve the user experience since users can better understand and interpret the content Kammerer 2009




Headings

A heading is a topical or subject phrase describing the content below it Often headings are treated as a visual element created by changing the size and weight of the text but they are an important semantic element that helps structure and organize the text for all users Headings in digital content are used much like in formal writing or writing done for print The top level heading is heading 1 and typically reserved for the title of a page with headings 2 through 6 used for page content


Example

	Heading 1 Title Making Content Accessible
	Heading 2 Topic Creating Documents
	Heading 3 Subtopic Using Headings
	Heading 2 Topic Creating Media


Using headings properly also makes content more consistent as each level of heading is typically styled by the system such that even if changes are made to the code the change will be applied uniformly to each affected heading As users become familiar with a site they will also become more familiar with what each level of heading looks like making it easier to look for information within the content

Many reading tools and assistive technologies allow users to read the headings first like a table of contents see fig 2 or to skip content by heading so using headings to organize writing greatly increases the navigability of longer content


Figure 2 Weaveuxorg outlined by WAVE an accessibility tool 


Finally using headings not only makes the content easier for people to mentally parse but also makes content more searchable and findable Some search engines use headings to help determine what a page is about so without headings a page may end up lower in search results Purtell 2016






Links

Much like headings many assistive reading tools and software allow users to view all the links on a single page while ignoring the surrounding text or to jump from one link to the next Therefore the textual description of a link needs to signal clearly the purpose of each link Content creators need to particularly avoid uninformative phrases such as read more and info WebAIM 2016b

Consider the following short piece of text where underlined text is a link

If you want to know more about descriptive links click here

In a list of links a user using a links only view would only see or hear the text click here making it difficult to distinguish from other links that have the same text In order for links to be accessible link text should be descriptive ideally explaining what is linked to 

You can learn more about descriptive links from WebAIM

Even if the user only sees the link text it is now clear that the link goes to a WebAIM article about descriptive links Assistive software users frequently show or read links only so using click here does not allow users of such software to distinguish the differences between all the links with the same link text Users of visual browsers also scan links when looking for relevant content so using descriptive link text improves the user experience for all visitors by allowing for an easier understanding of where links go letting users quickly find links and preventing repetitive content




Audio and Visual Content

For all audio and visual content such as images and videos an alternate version of the information should be provided to make the information accessible to users who cannot hear audio andor see images and video Not only is a textual alternative to audiovisual content necessary for deaf and visually impaired users it can be helpful to users whose software cannot load the visual content such as if the link is broken or there is a bad connection Almost onethird of the United States is not on broadband connections Horrigan  Duggan 2015 and many more are on slow connections such as users in rural areas on cheap internet packages or on cellular network connections These users are more likely to have images and video fail to load due to unreliable networks and are more likely to intentionally turn off audiovisual content from loading in their browser to speed up page load times or save on data usage Creators should keep in mind that they often have access to better hardware software and network connections than many if not most of their audience


Images

Images need either alt text alternative text or a caption filled in with a brief description of what the image is trying to convey The alt text is the textual description used in place of the image when the image cannot be loaded or read to the user when accessed using screen readers The caption is text that is kept with the image and typically displayed below it Most WYSIWYG editors provide fields to add text for alt text and caption allowing for both to be filled in see fig 3 They should not repeat each other but can be used to complement one another For example the alt text might describe the image itself and the caption might have commentary or a source note


Figure 3 Screenshot of WordPress image editor with caption field filled in 


In cases of images of charts or datasets it is recommended to provide a summary of the data in the alt text and if possible have an equivalent data table available either on the same page or an easily reached other location

Note that not all images need captions or alt text No text description is needed if the image is purely decorative or if the image is a duplicate of textual explanation For example in a tutorial with stepbystep instructions screenshots or other images to simply show what each step looks like do not necessarily need alt text In figure 4 the flowchart helps people decide when alt text is required


Figure 4 Image alt text decision flowchart Source Alexander 2010 used with permission 


Images of text should be used sparingly if at all as actual text is accessible by default For example an organizations name and contact information should be in text so that anyone can easily copy it for use elsewhere such as a map application Having contact and other basic information in text format is also very important not only for direct accessibility purposes but also to improve search results in search engines




Adding and Creating Other Media

Like images any audiovisual material should have an accessible alternative version For audio the alternate version is a text transcript either presented on the same page or as link to the transcript Video alternatives include

	text transcripts 
	closed or open captions subtitles with description of nonspeech elements and 
	descriptive video video with an audio track describing the visuals


If adding media that is not created inhouse consider asking the person or organization who created the material for a copy of the transcript If that is not possible consider using an automatic transcription program and then editing the transcript There are a number of free and paid software installable and online such as PopUp Archive and VoiceBase Commonly video creators will use the transcript from YouTubes automatic caption service that is generated after a video is uploaded

Since it is time consuming to create or edit transcripts of existing material consider making use of existing services within the organization or hiring a transcription service to provide accessible versions of required material ondemand when requested by users with related disabilities While that can be daunting consider offering transcription services ondemand for users if you have a large backlog of noncaptioned or transcribed media At an academic institution there may be a department with experience in making material accessible who can provide assistance

Transcripts and captions are useful not only for those using assistive software but also for those who are hard of hearing listening in noisy environments and are less familiar with the spoken language Griffin 2015 One study showed that 80 percent of the respondents used captions to watch television even though they did not have a hearing impairment Ofcom 2006




Embedding ThirdParty Media

When adding media from a thirdparty such as YouTube in such a way that it can be played on the web page also add a link to where the original source can be found A link allows users to view the content on the original site which may have more controls accessibility features and other features not available in the embedded version including autogenerated closed captions

Most embeds also include a small set of options the designer of the page can set see fig 5 While often these can be left to the defaults it is worth making sure that the embedded media

	has controls to play and pause at a minimum 
	has keyboard functionality for its controls and 
	does not automatically start playing autoplay



Figure 5 Screenshot of YouTube embed options with Show player controls and Show video title and player actions checked


These guidelines also apply to other interactive features on a website such as carousels or slide shows

Many embedded videos can be set to autoplay when the page is loaded or at some other time as in figure 6 Media that autoplays can be distracting or confusing For those using assistive software autoplay is especially problematic because depending on how the media player is coded the cursor or page focus may move every time the media automatically triggers an action interrupting what the software is reading to the user A user navigating the site by keyboard will constantly find the cursor jumping back to a carousel every time the image changes For these reasons autoplay should be avoided or switched off whenever possible 


Figure 6 Screenshot of carousel from shouldiuseacarouselcom with autoplay enabled as It is changing slides


Controls for media elements should be clearly visible with keyboard functionality enabled Generally media players will either be built into the system or originate from a third party but should be properly tested before use 

Adding links to sources disabling autoplay and providing playback controls ensures a positive user experience by allowing users to decide how they interact with the content In WordPress YouTube embedded videos have controls and do not autoplay by default so that the only other thing needed is a link below to the actual YouTube page with the video Users come to a site for the content but for the best user experience the user should be allowed to decide how to access view and interact with that content






Color Contrast and Text Styles

For text and media color should not convey meaning For example charts and figures are frequently made with different solid colored sections However about 8 percent of men and 1 percent of women Mandal 2014 have a form of colorblindness and may not be able to tell which color reflects which piece of information For example in figure 8 the green at the top and the red to the right of it are difficult to distinguish in the grayscale version being divided only by a very thin line The two yellows on the left may also be difficult to distinguish in both versions





Figures 7  8 Example pie chart using various solid colors with grayscale version for comparison Source Liftarn 2009

While this is particularly relevant to images this guideline applies to text content as well Assistive software will frequently indicate if text is bold or italic but not if it is simply displayed in a different color Some users may need to view a site using monochromatic displays Users may also print information and will appreciate being able to print in black and white or grayscale

Good color contrast also increases visibility in poor lighting conditions For example when viewing a screen in bright light that causes glare on the screen or if the screen is set to a low brightness level to save battery life content is more viewable if it has high contrast These are situations that affect all users not just those with assistive devices




Documents

Document creation Word PDF etc should follow the same general principles as web content Making documents accessible allows users not only to read them with assistive software but also allows all users to annotate and make notes copy and print information Most document creation programs including Word and Acrobat Reader have builtin accessibility checkers Document content is not guaranteed to be viewable in a web browser which may force the user to open the content in a separate application Text that is meant to be read online should not be put into a document but made part of the page 



Assessment and Evaluation

Many excellent strategies for evaluating and assessing websites and digital content are covered in other articles or resources on usability analytics and user experience see usabilitygov for more While a full exploration of this area is out of scope of this article this brief overview should provide a starting point and focuses on assessment and evaluation centered on meeting accessibility guidelines

There are many types of tools that can help determine whether digital content is accessible 

	Documents and other nonweb page content most popular commercial document creation software such as Microsoft Office and Adobe Acrobat have builtin accessibility checking tools Otherwise following the content creation guidelines above should cover most cases see WebAIM 2016a for more
	Emulationsimulation tools These tools provide a different representation of what users see or hear Examples	
WAVE Toolbar can display a web page in different ways such as an outline of headings and a textonly version
	
Colorblind Web Page Filter simulates different common types of colorblindness
	
Fangs a Firefox plugin emulates a screen reader by providing what would be read out loud in text format



	Automated code checkers check whether a web page meets guidelines based solely on the output code Examples	
HTML Codesniffer a bookmarklet which checks whether code conforms to either Section 508 of the Americans with Disabilities Act or Web Content Accessibility Guidelines WCAG
	
WCAG Contrast Checker a Firefox plugin which checks color contrast of all elements



	Assistive technology directly test a websites accessibility usability and overall user experience using screen readers and other assistive technology However many specialized software and devices require training to use


The difficulty with many of these assessment and evaluation tools are that they assume the user will understand and know how to interpret the results and apply the necessary changes to fix any issues Unfortunately many of these tools do not have an easy or basic mode flagging all instances of possible accessibility issues which can be overwhelming

Content creators may also find errors in parts of the website that they have no control over such as the header or the default styles of content Focus on the content pieces that can be easily fixed see W3C 2015 for more information and then if possible speak to the administrators or developers of the website see next section on Talking to Vendors

False positives are common with automated tools so the results they produce need to be carefully scrutinized For example some checkers will flag all instances when an image has no alt text However if the image is decorative then that particular instance of the error can be ignored

Even without automated tools content creators can still do periodic checks of their own or their peers content following the guidelines presented in this article

The most important evaluation method is to get feedback from users Design decisions are frequently made based on assumptions that cannot be validated or invalidated without testing by real users Loranger 2014 Whenever possible find users who use assistive technology to help with testing Make the effort to include such users in any usability testing

Talking to Vendors

Because many content creators or organizations do not have full control of the digital services provided by the library it is important to have a review of thirdparty digital content and services and report any issues to the appropriate vendor

When reporting issues to vendors it is critical to provide as much detail as possible about the problem and how or when it occurs Simply saying the website is broken or that the product needs to be made accessible is uninformative and makes it difficult for the person receiving the comment to assist resulting in very little change However if there are specifics about the issue then it is at least possible for the vendor to fix the issue If there are multiple issues report the issues separately addressing each one as they are found Possible solutions to the problem should be included or a link to such a solution provided If providing a link the page or a section of the page should clearly solve the specific problem preferably with code examples if applicable

Always provide information on the devices operating system browser if applicable vendor software or service where the problem is encountered with version numbers if applicable Try to detail the specific steps that were taken and whether the issue could be replicated in another session Also include an annotated screenshot of the problem if possible

For example a simple request might look something like this


I think this change could improve the accessibility for images added in the system When a user adds an image



	Choose the file to upload
	Fill in the alt text field
	Leave the title field empty



For some reason the alt text always shows up as the title instead

Example httplibrarycomlocation the picture of our main branch has alt and titlelarge red brick building but in the media library its the opposite

Using Library Website v123

Browser Firefox 431

OS Windows 10



Accessibility Statement

After making digital content more usable and accessible an organization can increase transparency and show commitment to providing equivalent access to users by writing and posting an accessibility statement

An accessibility statement can be relatively short but should include some basic information including 

	what has been made accessible
	whether the site conforms to one or more specific sets of guidelines
	what part of the content is not controlled inhouse namely vendor products but it can include a line to say the organization works with vendors
	who can be contacted and how if there are any issues


Some examples of accessibility statements are

	
University of Toronto Accessibility Statement
	
University of Oxford Accessibility Statement and
	
North Carolina State University Accessibility Statement


Conclusion

Many organizations do not have complete control of the online systems used to provide information and services to their users Offtheshelf vendor tools make up a large amount of the digital tools many libraries offer users so often organizations leave it to vendors to make the needed improvements However as this article shows there are things staff likely can do within the constraints of vendor tools and systems to make their content more accessible as well as communicating more effectively with vendors about accessibility issues

Accessibility is not simply a way to meet legislation or avoid litigation but a fundamental aspect of a users experience of the organizations digital space Libraries should integrate accessibility concerns into the larger picture of user experience to benefit all users not just those with assistive devices  

Note For a more technical look at creating accessible websites and applications see the authors recent coauthored article in Code4Lib Journal A Practical Starter Guide on Developing Accessible Websites

References

	Alexander D 2010 Text alternativesa decision tree 4 Syllables Retrieved from http4syllablescomauarticlestextalternativesdecisiontree

	Fulton C 2011 Web accessibility libraries and the law Information Technology  Libraries 301 3443
	Griffin E 2015 Who uses closed captions Not just the deaf or hard of hearing Retrieved from httpwww3playmediacom20150828whousesclosedcaptionsnotjustthedeaforhardofhearing

	Horrigan J B  Duggan M 2015 Home broadband 2015 Pew Research Center Retrieved from httpwwwpewinternetorg20151221homebroadband2015

	Kammerer M 2009 Writing user friendly content UX Booth Retrieved from httpwwwuxboothcomarticleswritinguserfriendlycontent

	Liftarn 2009 Pie chart EP election 2004svg image file Wikipedia The Free Encyclopedia Retrieved from httpsenwikipediaorgwikiFilePiechartEPelection2004svg

	Loranger H 2014 UX without user research is not UX Nielson Norman Group Retrieved from httpswwwnngroupcomarticlesuxwithoutuserresearch

	Mandal A 2014 Color blindness prevalence News Medical Retrieved from httpwwwnewsmedicalnethealthColorBlindnessPrevalenceaspx

	National Center for Education Statistics nd PIAAC 20122014 results summary Retrieved from httpsncesedgovsurveyspiaacresultssummaryaspx

	Ofcom 2006 Television access services Retrieved from httpswwwofcomorgukconsultationsandstatementscategory1accessservssummary

	Purtell M 2016 In 2016 how important is an H1 tag for SEO Search Engine Journal Retrieved from httpswwwsearchenginejournalcomin2014howimportantisanh1tagforseo

	Quesenbery W 2009 Usable accessibility Making web sites work well for people with disabilities Retrieved from httpwwwuxmatterscommtarchives200902usableaccessibilitymakingwebsitesworkwellforpeoplewithdisabilitiesphp

	Quesenbery W 2014 January 21 A web for everyone Accessibility as a design challenge webcast Hosted by OReilly Retrieved from httporeillynetcompube2992immmid0b6284cmpemnawebcastinfowebcast20140120

	Robson N 2013 Horizontal scrolling and user experience best practices Usability Geek Retrieved from httpusabilitygeekcomhorizontalscrollinguserexperiencebestpractices

	Rowland C Mariger H Siegel P M  Whiting J 2010 Universal design for the digital environment Transforming the institution EDUCAUSE Review 456 Retrieved from httpwwweducauseedueroarticleuniversaldesigndigitalenvironmenttransforminginstitution

	Schofield M 2016 How to talk about user experience LibUX Retrieved from httplibuxcohowtotalkaboutuserexperience

	Shneiderman B  Hochheiser H 2001 Universal usability as a stimulus to advanced interface design Behaviour  Information Technology 205 367376 doi10108001449290110083602
	W3C 2015 Evaluating websites for accessibility Overview Retrieved from httpswwww3orgWAIevalOverviewhtml

	W3C 2016 Accessibility Retrieved from httpswwww3orgstandardswebdesignaccessibility

	WebAIM 2016a Articles Retrieved from httpwebaimorgarticles

	WebAIM 2016b Links and Hypertext Retrieved from httpwebaimorgtechniqueshypertextlinktext






Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS




























































What We Talk About When We Talk About Digital Libraries UX Approaches to Labeling Online Special Collections


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










What We Talk About When We Talk About Digital Libraries UX Approaches to Labeling Online Special Collections 




Dylan Burns Alex Sundt Darcy Pumphrey and Becky Thoms

UTAH STATE UNIVERSITY



Skip other details including permanent urls DOI citation information
Volume 2 Issue 1 2019



DOI httpdxdoiorg103998weave125356420002102



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	














Abstract



Digital libraries digital collections digital archivesjust a few of the common terms used to describe the output of largescale digitization efforts While the term digital library is commonly used by librarians the term itself reflects the specific disciplinary and technical environments in which the concept for a digital library was first imagined Terminology has been wellexplored in academic libraries but questions remain regarding how meaningful digital library and related terms are to the users of digitized archival collections In 2016 a reverse category test was conducted with target users of Utah State University Libraries digital collections to determine what labels users associate with different types of library materials More than just an issue of semantics this article explores the critical role that naming plays in how users understand these collections while offering insight into how to make digitized materials more findable and usable in online environments



This paper was refereed by Weaves peer reviewers


Introduction

Communicating the scope and value of library collections is a perennial problem that has only come into sharper focus as more and more libraries adopt a usercentered approach to design and outreach One key element of a usercentered library is creating effective labels for library collections and services that make sense to users and reflect their natural language For digitized materials particularly in the areas of special collections and archives labeling can be an especially difficult problem Special collections are by nature esoteric and often require mediation by archival specialists to access and use When digitized and placed online these unique materials are likely to attract a new and wider audience who may have little or no experience navigating special collections Adding to this potential confusion a diverse range of terminology exists for describing digitized archival collections on the websites of Association of Research Libraries member libraries Table 1 Although the term digital collections appears to be increasingly popular the use of digital library digital archives and similar variations continue to persist and are still quite popular Additionally disparate terms sometimes occur together appearing at different points in website navigation and in the case of state libraries and historical societies may be supplanted altogether by branded names that may or may not be meaningful to users This creates an overall confusing environment for online users who without the benefit of mediation by archival specialists are left to form their own interpretations for the vast range of vocabulary they may encounter In this article we will explore how users perceive different labels and associate them with different types of digital materials shedding light on this problem and pointing towards a potential solution for digital library designers 

Table 1 Sample of terms used by ARL libraries to label digitized cultural heritage collections n25

	
Term

	
Number of Occurrences


	
Digital Collections

	
17


	
Digital Library

	
6


	
Digital Repository

	
1


	
Digital Archives

	
1


	
eArchives

	
1


	
Digitized Collections

	
2


	
Special Collections Online

	
1




Different terms often occurred across the same website

The History of the Term Digital Libraries 

Part of the problem with the term digital library stems from the history of digital library development and the conflicting definitions that emerged from different disciplines working in the field of digital libraries The term digital library was first used in the library literature to describe a system combining the conventional archive of current or historically important information and knowledge along with ephemeral material such as drafts notes memoranda and files of ongoing activity Kahn  Cerf 1988 p 3 However the inspiration for such a system can be traced back to the proliferation of scientific research and publications in the postwar United States Questions of how libraries could store and make available a growing number of volumes and how scholars would make sense of it all prompted many to consider technological solutions to this information surplus Calhoun 2014 Bushs 1945 As We May Think imagined a memex device capable of storing ones entire library of books and personal documents and allowing for new ways of discovery through associative indexing Many researchers such as Calhoun 2014 Fox and Marchionini 1998 and Harter 1997 also point to Lickliders 1965 Libraries of the Future which predicted many features common to todays online information environments p 2 p 36 

In 1993 the influential Research in Digital Library Initiative was launched as a joint initiative of the Defense Advanced Research Projects Agency the National Science Foundation and the National Aeronautics and Space Administration Designed to spur innovation in largescale information storage and retrieval the program initially provided grants to projects in computer and information science Later after the program was extended to include the National Endowment for the Humanities the Library of Congress and the National Library of Medicine more emphasis was placed on projects focused in the arts and humanities These disparate communitiescomputer and information science library science arts and humanitieseach provided their own specialized definition of the term Borgman 1999 p 228 Although libraries were involved in early projects to digitize cultural and other artifacts and create digital libraries the field was largely characterized by the work of computer scientists and the need to develop technical infrastructure and definitions that emerged reflected this tension Pomerantz Choemprayong  Eakin 2008 For example Kahn and Wilensky 1995 proposed the concept of digital objects organized within a networkaccessible repository which Cleveland extends into a collection of disparate resources and disparate systems catering to specific communities and user groups 1988 p 3 

For many librarians however the term digital library was inherently problematic While more evocative than electronic database the term reduced libraries to content repositories discounting the broader sense of communityoriented service organizations Borgman 1999 pp 230231 Battin 1998 rejected the terms reliance on familiar metaphors of the physical library which might be limiting in the emerging digital information landscape Definitions from the library and information science community reflected uncertainty about the shape digital libraries would take and how well they would be merged with traditional library practices Harter 1997 described a continuum of forms that digital libraries could evolve into including something similar to the web with control zones for authoritative content and narrower selfcontained systems with features very similar to todays digital libraries Schwartz 2000 noted the muddled line between digital libraries and the growth of hybrid libraries reflecting an increasing mix of print and electronic collections Each of these approaches attempted to get at what made digital libraries distinct from their nondigital counterparts and how these two units within the library would use terminology and structures to define difference 

While some scholars saw the digital library as a distinct form others positioned digital libraries as an evolution of the conventional library organization For example Lynch 1997 described digital libraries as having many of the same structural elements of traditional librarianship with content only stored and accessed in a digital form Reflecting this focus on a structured institutional approach the Digital Library Federation proposed the following definition


Digital libraries are organizations that provide the resources including the specialized staff to select structure offer intellectual access to interpret distribute preserve the integrity of and ensure the persistence over time of collections of digital works so that they are readily and economically available for use by a defined community or set of communities Waters 1998



In this sense a digital library is not a container for digital objects but a communityenabling organization that provides access and valueadded services for user communities Similarly Lynch 2002 distinguishes between digital collections as raw content and digital libraries as the systems that make digital collections come alive make them usefully accessible that make them useful for accomplishing work and that connect them with communities Even without a common definition or a shared understanding of what digital library meant usage of the term became widespread as a result of the Digital Library Initiative program grants Fox Akscyn Furuta  Leggett 1995 p 24 

Over the last half century we have seen many meanings for the term digital libraries used to the point where users often do not know what they will find when they enter the digital library While the usage of the term digital library has shifted over the years from the memex device to digitized special collections the incorporation of electronic resources and ebooks have thrown a wrench into an agreed upon usage of the term As we will show by considering our users assumptions we can find an easier and more usable path for our digitized special collections materials to meet the needs and expectations of our community

The Usability of Contemporary Digital Libraries

If defined as communityservice organizations the success and sustainability of a digital library should be closely tied to understanding and catering to the needs of its user communities Although digital libraries are no longer a novel concept how to relate these collections to users with coherent usercentered branding and terminology remains an open question Borgman 1999 noted that a digital library could be thought of as a standalone branch within a library system p 237 While this provides a helpful model for understanding the relationship between digital libraries and their sponsoring institutions unlike physical libraries it is much more difficult to define the user community of a digital library Because so much usage occurs virtually and often originates from locations beyond the local library community Lynch 2002 cautioned against making assumptions about the motivations and end goals of the users of digital libraries

Although much research has been conducted regarding users perceptions and usability issues related to digital libraries the problem of what to call digital libraries so that users can make sense of them has not been well explored Kelly 2014 provided a comprehensive overview of user research within the broadlydefined area of digital libraries Usability studies of digital libraries have mostly involved case studies while a few explored specific interface problems Dickson 2008 Xie 2007 or issues like multilingual support Smith 2006 and content accessibility Southwell  Slater 2012 Xie Babu Joo  Fuller 2015 Surveys of users perceptions and acceptance of digital libraries are more relevant but provide limited insight into the problem of collection branding Thong Weiyin and Kar Yan 2004 pointed to factors like clear relatable terminology in digital library interfaces and previous exposure as important factors in user acceptance of a digital library Although the authors did not discuss the specific term digital library their findings suggest overlap between usability terminology and the marketability of digital libraries Xie 2008 pointed to lack of cohesiveness across digital library collections noting that digital libraries broadly were difficult for users to search and use and suggesting that developers consider branding separate digital libraries by the scope or theme of collections

Research Questions

While this terminology for digital libraries is acceptable and perhaps necessary for researchers in particular fields and library professionals what about the endusers of digital libraries Fox et al note the phrase digital library evokes a different impression in each reader 1995 p 24 What does this label evoke for the users of special collections What about the typical undergraduate student user of an academic library Is it clear to these and other users what a digital library may contain and importantly what parts of the larger academic library are not included Longstanding usability research indicates that people do not read websites in detail Instead they scan for keywords headings and links that seem related to their information need Nielsen 1997 Nielsen Norman Group 2014 Users hunt for links that have a high information scent based on the presence of descriptive link text that suggests a high probability of finding the needed content Nielsen 2003 With this in mind how usable is the label digital library as an access point for digitized archival materials What keyword terms might have a stronger information scent for users and how can those terms be incorporated into access points for our digital materials More than just an issue of semantics the branding and labeling we employ in digital library interfaces plays a critical role in helping users find utilize and understand archival and special collections in the online environment 

To address this issue we designed and administered a surveybased test to answer the following questions

	What terms are library users most likely to associate with different materials commonly found in digital libraries
	What terms are potentially confusing or likely to be misunderstood by users In particular does the term digital library get confused for other general material types such as ebooks


For purposes of clarity and accuracy it is important to distinguish between terminology user interface labels and branding While each is important for how we communicate to users they impact the user experience in different ways Here we refer to terminology as a general usage of a word to describe an object in a technical sense Even though terminology may be useful and accepted by a community of practitioners this does not mean a given term is understandable to end users On the other hand it is essential that labels for links and other user interface controls are understandable to end users and free of jargon Similarly a brand still needs to be relatable and communicate value to the user but can take more creative liberties in how it represents a service or collection Generally jargon and brand names are problematic when used as labels in library websites Kupersmith 2012 For the purposes of this study we use digital library and similar terms to refer to mainly online collections of digitized cultural heritage objects and other materials As we will show this term is clearly jargon poorly defined within the library community and problematic both for the labeling and branding of digitized cultural heritage materials 

Methods

Over the past three years Utah State University Libraries engaged in a significant overhaul of its main library website employing a usercentered approach that entailed user testing and iterative design Prior to this project all digitized materials from our Special Collections  Archives as well as the institutional repository were accessible through a link labeled digital library In developing a new information architecture for the website including more userfriendly navigation the lack of consensus in the community on campus or inside the library itself over what digital library represented was obvious This was confirmed in usability testing of the library homepage While doing this usability testing it became clear that users tasked with finding a historic photograph of the campus struggled to locate the link to the digital library and expressed confusion with the terminology This project sought to address this problem by refining the terminology to be more usercentered 

Throughout the spring and summer of 2016 we developed and administered a Qualtrics survey with two sections The first section presented participants with a reverse category test a method that is commonly used in testing library navigation labels Hennig 2001 Whang 2008 For our test participants were given five taskbased questions that asked them to choose the label they would be most likely to click on to find different material types commonly found in digital libraries In addition a sixth task asking participants which label they would choose for a science ebook was included to test whether any labels might be associated with a more traditional nonarchival item Label options were selected to represent the range of terms found in our analysis of ARL member websites The term digital was selected because it was more common than other synonyms such as e or online and was included for each option in order to remove it as a factor in participants decisionmaking Instead we wanted to test users perceptions of more semantically distinct variations on the term library such as archives and collections Along with Digital Collections the variant Digital History Collections was also included to test whether the modifier history might impact participants label choices for different items This approach was advantageous for testing the usability of opaque terms like Digital Library As opposed to a category test in which users simply list what they expect to find for different labels the inclusion of taskbased scenarios helped to contextualize the label choices as a whole eliminating the need to explain the nature of our digital collections to users in order for them to understand the purpose of the test This reduced the potential for bias and increased the chances that participants would model realworld behavior based on accomplishing a task rather than considering what to call our broad set of collections

Text of Survey 


The Library is trying to improve the labels we use for links on the library website We need your help to make sure the labels we choose are appropriate and make sense to you The row at the top includes potential labels for links on the website For each question on the left please select the label you would most likely click on to find that item Dont worry about where things are on the current website There are no right or wrong answerswe want to know which one you think makes the most sense




Taskbased questions



	Where would you click to find online photographs of USU from the 1930s
	Where would you click to find an ebook on particle physics
	Where would you click to read online diaries of Mormon pioneers
	Where would you click to find newspapers from the 1950s
	Where would you click to find old USU yearbooks that you can read online
	Where would you click to find recorded interviews with Latino immigrants to Cache Valley Utah 



Label options



	Digital History Collections
	Digital Library
	Digital Archives
	Digital Collections


Participants were not given a none of the above option but were not required to select an option for each task Instead the second section provided an openended question that asked What terms would you suggest for a link to the Librarys database of digitized photographs newspapers regional history and folklore items 

We recruited survey participants from several user groups considered part of the target audience of USUs Special Collections  Archives undergraduate students enrolled in a history class undergraduate students from our general student population student employees in the library and community members primarily retirees enrolled in a continuing education program Although virtual access outside of the local campus community makes up a significant percentage of overall use of the digital collections we felt these local groups could serve as a reasonable standin for virtual users Archives staff have also observed that these groups will often seek inperson assistance with locating materials that are available through online collections making them an important source of information for improving the findability and overall user experience of digital collections We administered surveys inperson to these groups either by recruiting participants from around the library building by visiting classrooms or by attending outreach events In addition the survey was distributed electronically to university and local public library staff Because users often have a limited understanding of the full scope of library collections we felt it was important that results from library patrons were qualified by the experience and expertise of librarians and other library staff This would allow for comparisons between the perceptions of end users and how library staff conceptualize these collections both from their own personal experience and based on their knowledge of users in a reference environment

Results

In total we received fifty responses from target end users and thirtyone responses from library staff members in area libraries Table 2 Tables 38 show responses for each reverse category question Despite USU Libraries original choice of digital library for special collections materials overwhelmingly participants identified digital library as the label they would select to find ebooks The remaining items were associated with a broader range of labels Newer materials or materials associated with the contemporary community or University were spread amongst the labels Digital Collections and Digital Archives It is not surprising that history was a favorable term for respondents based on several of the surveys scenarios Many participants selected the label Digital History Collections for scenarios related to materials that were clearly historical For example in response to the question about Mormon pioneer diaries 61 percent favored Digital History Collections over 17 percent for Digital Collection and for photographs from the 1930s 43 percent chose Digital History Collections over 16 percent for Digital Collections Curiously the interviews with Cache Valley immigrant families described as oral histories by scholars were not associated as often with historic collections with only 15 percent of participants placing it in Digital History Collections and 53 percent placing it in Digital Collections 

Table 2 Survey Participants by Group

	
Population

	
Number of Participants


	
Library Undergraduate Student Workers 

	
6


	
General Undergraduate Students 

	
16


	
Undergraduate Students in History Class 

	
9


	
Community Members 

	
19


	
USU Library Staff 

	
20


	
Local Public Librarians 

	
11


	
Total

	
81




These preliminary results suggest some level of discomfort with items which are temporally new ie created in the past decade identified as historical along with other older special collections materials Participants can be partially forgiven for this because of the welltread scholarly tension between what is history and what is not Carr 1961 Hobsbawm  Ranger 1983 A potential solution would be to have two collections one historical and one contemporary and yet this does not seem to make much sense in terms of usability and only complicates our issues

 

Results were consistent across the various age groups with very little difference except for community members suggesting different terms in response to the openended question than the student or library staff groups Overall Digital History Collections was the most popular label The label Digital Archives popular in some library circles was picked as the classification for many of the University archival materials like yearbooks newspapers and photographs but less often for historical objects like the diaries or interviews

Table 3 Where would you click to find online photographs of USU from the 1930s

	
Population

	
Digital Library

	
Digital Collections

	
Digital Archives

	
Digital History Collections


	
Library Undergraduate Student Workers n6

	
0

	
2 

	
1 

	
3 


	
General Undergraduate Students n16

	
1 

	
2 

	
6 

	
7 


	
Undergraduate Students in History Class n9

	
1 

	
2 

	
2 

	
4 


	
Community Members n19

	
1 

	
0

	
8 

	
10 


	
USU Library Staff n20

	
1

	
5

	
6

	
8


	
Local Public Librarians n11

	
1

	
2

	
5

	
3


	
Total n81

	
5

	
13

	
28

	
35 43




Table 4 Where would you click to find an ebook on particle physics

	
Population

	
Digital Library

	
Digital Collections

	
Digital Archives

	
Digital History Collections


	
Library Undergraduate Student Workers n6

	
6

	
0

	
0

	
0


	
General Undergraduate Students n16

	
12

	
4

	
0

	
0


	
Undergraduate Students in History Class n9

	
9

	
0

	
0

	
0


	
Community Members n19

	
14

	
3

	
2

	
0


	
USU Library Staff n20

	
16

	
4

	
0

	
0


	
Local Public Librarians n11

	
11

	
0

	
0

	
0


	
Total n81

	
68 84

	
11

	
2

	
0




Table 5 Where would you click to read online diaries of Mormon pioneers

	
Population

	
Digital Library

	
Digital Collections

	
Digital Archives

	
Digital History Collections


	
Library Undergraduate Student Workers n6

	
1

	
2

	
1

	
2


	
General Undergraduate Students n16

	
1

	
2

	
2

	
11


	
Undergraduate Students in History Class n9

	
0

	
0

	
1

	
8


	
Community Members n19

	
1

	
4

	
1

	
13


	
USU Library Staff n20

	
1

	
4

	
5

	
10


	
Local Public Librarians n11

	
1

	
2

	
3

	
5


	
Total n81

	
5

	
14

	
13

	
49 61




Table 6 Where would you click to find newspapers from the 1950s that you can view online

	
Population

	
Digital Library

	
Digital Collections

	
Digital Archives

	
Digital History Collections


	
Library Undergraduate Student Workers n6

	
0

	
0

	
3

	
3


	
General Undergraduate Students n16

	
1

	
1

	
10

	
4


	
Undergraduate Students in History Class n9

	
0

	
1

	
3

	
5


	
Community Members n19

	
2

	
2

	
8

	
7


	
USU Library Staff n19

	
2

	
5

	
7

	
5


	
Local Public Librarians n11

	
1

	
2

	
5

	
3


	
Total n80

	
6

	
11

	
36 44

	
27




Indicates that not all participants selected an answer for this question

Table 7 Where would you click to find old USU yearbooks that you can read online

	
Population

	
Digital Library

	
Digital Collections

	
Digital Archives

	
Digital History Collections


	
Library Undergraduate Student Workers n6

	
0

	
0

	
2

	
4


	
General Undergraduate Students n16

	
0

	
5

	
5

	
6


	
Undergraduate Students in History Class n9

	
2

	
1

	
4

	
2


	
Community Members n19

	
1

	
6

	
8

	
4


	
USU Library Staff n20

	
3

	
4

	
7

	
6


	
Local Public Librarians n11

	
2

	
2

	
4

	
3


	
Total n81

	
8

	
18

	
30 37

	
25




Table 8 Where would you click to find recorded interviews with Latino immigrants to Cache valley from 2012

	
Population

	
Digital Library

	
Digital Collections

	
Digital Archives

	
Digital History Collections


	
Library Undergraduate Student Workers n5

	
1

	
1

	
3

	
0


	
General Undergraduate Students n16

	
1

	
10

	
3

	
2


	
Undergraduate Students in History Class n9

	
1

	
6

	
1

	
1


	
Community Members n18

	
4

	
8

	
1

	
5


	
USU Library Staff n20

	
5

	
12

	
2

	
1


	
Local Public Librarians n11

	
2

	
5

	
1

	
3


	
Total n79

	
14

	
42 53

	
11

	
12




Indicates that not all participants selected an answer for this question

In response to the openended question participants suggested many novel combinations of archives digital and history but most responses used one or more of the label choices from our previous question Table 9 The most popular response was Digital Archives followed by more traditional terms like archives or collections indicating little consensus among participants Some participants also dropped the term digital entirely favoring terms like archives or historical archives As an example the preference for historical and archives over digital library for older materials were different than how we labeled our collections since digital library was the term for all this material On the other hand ebooks have never been associated with the title digital library within our system yet respondents overwhelmingly chose that term for those materials 

Table 9 What terms would you suggest for a link to the Librarys database of digitized photographs newspapers regional history and folklore items

	
Population

	
Suggested Terms


	
Library Undergraduate Student Workers n1

		Digital Special Collections


	
General Undergraduate Students n7

		Historical Database
	Digital archives
	Digital archives with subcategories for different types
	Digital media collection
	Digital Library
	Historical archives with sub sections


	
Undergraduate Students in History Class n2

		Regional collections
	For photosdigital images


	
Community Members n6

		Pre  Digital Data  Historical
	Digital archives
	Microfish sic

	Digital History Database
	Archives
	Archives


	
USU Library Staff n4

		Either Digital Library or Digital Archives
	Digital Archives or Digital History Collections
	Digital Historical Media
	USU related  archives General materials not specific to USU  library fewer choices less confusion


	
Local Public Librarians n5

		Digitital sic library
	Digital Collections  I think that the resulting page would benefit from having a menu of options hierarchy of sorts that use words like ebooks digital history collections USU history or other categories represented in the Digital Collections that people could choose 
	Digital Collections seems best Digital Archives sounds more academic to me so it may depend on the audience that youre catering to
	Digital Archives
	All in one database If so then digital collections digital library second choice




Discussion

Our findings demonstrate that our survey participants struggle to interpret many popular terms used to label digital library collections Despite many attempts at a formal definition as our ARL survey above shows conflicting uses persist in the library literature ranging from collections of digitized archival materials to subscription databases to broad information access points like library web sites Comeaux 2008 p 461 Additionally significant variation continues to exist in how libraries and other cultural heritage institutions label their digital collections Confusing jargonheavy labels and brand names are a welldocumented usability problem Kupersmith 2012 and while librarians have debated the merits of different terms there has been little to no discussion of what labels like digital library digital archive and digital collection actually mean to users In particular the term digital library is not only illdefined in the library community but based on our findings seems to be poorly understood by library users 

Interestingly several participants seemed to recognize the limitations of using a single term to describe such broad collections and use cases from our scenarios Instead of just a single link label some participants suggested a secondary level of navigation based around material type with one participant suggesting categorization based around whether it was a USUrelated collection or nonUSU collection Together these findings suggest that there are inherent problems not only with the specific label digital library but with the concept of digital libraries as distinct entities that can be fully understood without understanding their constituent parts 

Several participants suggested labels that did not include the term digital which raises the question of how popular a formatneutral label might have been if included as a survey option It is worth considering whether users now expect libraries to be hybrid with some resources available online and others located in a physical collection If this is the case it would indicate a need to fundamentally shift how we have been branding and integrating special collections into the larger increasingly digital library environment When items from special collections are digitized do the scanned objects become something different and something no longer in special collections Should the inverse be used with special collections that are not available digitally being separated and branded differently from those that are easily available online From a usercentered perspective this dichotomy may no longer be necessary let alone desirable This was clear in the differences amongst the suggestions from the community members many of which were retirees versus younger participants more familiar with digital objects The retirees suggested we continue to use terms like archives and microfiche even if the objects were digital which illuminates a comfort with one format or in the case of microfiche another transformation than with the newer digitized format For items housed in USUs Special Collections  Archives the connection with the physical object is important however all objects from the collection will not be digitized and therefore a separate online portal with a descriptive label will be necessary for those interested in the full weight of the collection 

The explosion of digitization efforts coupled with a finditnow attitude of scholars and students means the online distribution of special collections materials is not showing signs of slowing down Overholt 2013 identified distribution as the key to the future of special collections in uncertain and challenging times


it hardly needs to be said that digitization and the ability to share digitized materials widely is enacting a wholesale transformation yet frustratingly there is still far too much friction in the process of matching users with the materials they need p 15



Overholt identifies several potential stumbling blocks for access for patrons including institutional silos and lack of openness While this addresses the larger searchability issues amongst many digitized collections it does not settle the user experience issues within the individual institutional collections This will continue to be an ongoing problem and more research is needed With the confusion surrounding the naming of our digital collections how do we cater to the user that searches specifically in our institutions collections For institutions with a range of collections and services how does this and other confusing jargon weigh down the overall user experience not just for special collections materials but online catalogs ebooks and other electronic materials that could all be reasonably considered part of a digital library from the perspective of end users 

As a result of this survey we settled on the term digital collections as a catchall for digitized and borndigital material from USUs Special Collections  Archives with Digital History Collections serving as the specific branding or label for our Digital Asset Management System portal The word digital tells users the format of the objects while collections signifies to users that the items are from our special collections because this term reflects the physical location In an assessment of library jargon Hutcherson 2004 found that nearly 60 percent of undergraduate students could identify what librarians meant when they used collection which put it on par with citation and catalog and well above more obscure terms like controlled vocabulary or Boolean p 352 While not the most popular of the options in the survey it was preferred enough over digital library to justify the change We anticipate that this name change will not solve all the search issues and labeling confusion but it is a step in the right direction Further outreach and marketing will be necessary to highlight the collections and connect users to the materials 

It is necessary to balance the needs of users with different backgrounds and levels of expertise in navigating library environments As a naming device the word digital does not describe the item or the collections even in the case of borndigital materials rather it describes the format of the item or the collection Within our discussions both with users and with our colleagues it is clear there is a distinct tension surrounding the word digital Internet savvy special collections consumers wish that all items be accessible online but on the other hand less technologicallyinclined users do not want real objects superseded by the digital nor in most cases would archivists

In user experience circles a tension exists between experts and novices one where novices may be confused by arcane structures and naming systems while experts may be frustrated by a more guided and easytouse approach Hassenzahl 2004 p 34 To extend this example to libraries and archives an expert scholar wellversed in library jargon and collection structures would be frustrated by a design built to guide and teach new patrons A classic example is catalog a term that endures from analog libraries and may be very relatable to more expert library users and yet can be easily confusing for newer patrons Both the branding of our services and how we label our websites and user interfaces need to account for all levels of user knowledge and experience while considering how these factors impact the accessibility of our collections This becomes difficult in the case of digital libraries which while comparable to commercial search engines or websites like Flickr exhibit many of the same complexities as physical archives In our survey results users choices were telling in terms of how we as librarians view special collections and what our patrons expect but also demonstrate the limitations of universal labels 

An additional layer of complexity stems from the fact that many digitized collections are created as surrogates for the physical collections within the archives or library and connect with a real object in the archives Thus the digital form is just an expression of an object and not as is central to our naming struggles a defining feature of the object itself Despite fears to the contrary archival materials are not in danger of being lost to the digital On this transformation towards digital libraries Battin 1998 reminds us that books and paper will not disappear and digital capacities continue to be addons rather than simple replacements p 273 Digitization is a supplement to the rich materials housed in USUs Special Collections  Archives This results in the term digital being added to labels for these materials to note their difference from the real object

Conclusion

Digitization as Prochaska 2009 suggests has opened collections to broader audiences and become the center of attention within the library As the drive for digital surrogates of cultural heritage objects increases the need to create online collections that are meaningful and useful to our communities must be at the forefront of these discussions As popular culture becomes increasingly tied to the web and online media digital becomes less a signifier of uniqueness and more an expectation among users For library collections to remain relevant we need to consider whether digital library and similar terms are still useful for communicating the value of an institutions unique online materials and their relationship with wider library collections both print and electronic

Good labeling is a key factor for making usable websites In the case of library websites our goal of connecting users with information resources and presenting those resources accurately is further complicated by what we know about user behavior including how users read or dont read on the web confusion over library and research jargon and continued problems with library technology and systems integration With increasing focus placed on library user experience how should we confront these problems in order to highlight library materials rather than hiding or hindering their use while also supporting users desire for speed and simplicity In some cases separate branding and distinct labeling may be necessary but for many libraries it may be time to consider repositioning their digital collections as part of the wider library ecosystem Is a distinct branded portal for digital collections necessary for end users who already expect nearly everything to be online For users seeking to fulfill an information need this may be a case where the whole is not greater than the sum of its parts Instead more usable digital libraries may be those that favor bringing objects to the surface rather than expecting users to navigate selfcontained curated collections With this in mind perhaps attention needs to shift toward providing closer integration with webscale discovery services and other starting points for user research like commercial search engines 

Problems with library jargon are unlikely to go away Even as older terms are replaced with more accessible usercentric language new library services and changes in technology promise a continuous supply of obscure vocabulary terms Even still as librarians we should make it our mission to elucidate these terms and clarify the nature of our collections both through user research and usercentered information design as well as support strategies like library instruction As more users discover our unique materials librarians will need to bridge the gap between their expertise as collection creators and managers and the goal of making online environments that are accessible for a broad range of audiences While seemingly minor labeling our collections in ways that are meaningful to our users is an important first step towards realizing such environments 

References

	Battin P 1998 Leadership in a transformational age In B L Hawkins  P Battin Eds
	
The mirage of continuity Reconfiguring academic information resources for the 21st century pp 260270 Washington DC Council on Library and Information Resources and the Association of American Universities
	Borgman C L 1999 What are digital libraries Competing visions Information Processing  Management 353 227243 httpsdoiorg101016S0306457398000594
	Bush V 1945 As we may think Atlantic Magazine Retrieved from httpswwwtheatlanticcommagazinearchive194507aswemaythink303881
	Calhoun K 2014 Emergence and definitions of digital libraries In Exploring digital libraries Foundations practice prospects pp 126 London Facet Publishing Chicago ALA NealSchuman 
	Carr E H 1961 What is history Cambridge University of Cambridge Press 
	Cleveland G 1998 Digital libraries Definitions issues and challenges UDT occasional paper 8 Retrieved from httpsarchiveiflaorgVI5opudtop8udtop8pdf
	Comeaux D 2008 Usability studies and usercentered design in digital libraries Journal of Web Librarianship 223 457475 httpdoiorg10108019322900802190696
	Dickson M 2008 CONTENTdm digital collection management software and enduser efficacy Journal of Web Librarianship 223 339379 httpdoiorg10108019322900802190852
	Fox E A Akscyn R M Furuta R K  Leggett J J 1995 Digital libraries Communications of the ACM 384 2228 httpsdoiorg101145205323205325
	Fox E A  Marchionini G 1998 Toward a worldwide digital library Communications of the ACM 414 2932 httpsdoiorg101145273035273043
	Harter S P 1997 Scholarly communication and the digital library Problems and issues Texas Digital Library 11 Retrieved from httpsjournalstdlorgjodiindexphpjodiarticleview44
	Hassenzahl M 2004 The thing and I Understanding the relationship between user and product In MA Blythe K Overbeeke A F Monk  P C Wright Eds Funology From usability to enjoyment pp 3142 httpdoiorg1010071402029675

	Hennig N 2001 Card sorting usability tests of the MIT Libraries web site categories from the users point of view In N EdUsability assessment of libraryrelated web sites Methods and case studies pp 8899 Chicago LITA American Library Association
	Hobsbawm E  Ranger T Eds 1983 The invention of tradition Cambridge Cambridge University Press 
	Hutcherson N B 2004 Library jargon Student recognition of terms and concepts commonly used by librarians in the classroom College  Research Libraries 654 349354 httpsdoiorg105860crl654349

	Kahn R E  Cerf V G 1988 The Digital Library Project Vol 1 The world of knowbots An open architecture for a digital library system and a plan for its development DRAFT Corporation for National Research Initiatives Retrieved from httphdlhandlenet42635372091

	Kahn R  Wilensky R 1995 A framework for distributed digital object services DLib Magazine Retrieved from httpwwwcnrirestonvaushomecstrarchkwhtml
	Kelly E J 2014 Assessment of digitized library and archives materials A literature review Journal of Web Librarianship 84 384403 httpdoiorg101080193229092014954740
	Kupersmith J 2012 Library terms that users understand Berkeley CA UC Berkeley Library Retrieved from httpescholarshiporgucitem3qq499w7

	Licklider J C R 1965 Libraries of the future Cambridge MA MIT Press
	Lynch C 1997 Searching the Internet Scientific American 2763 5256 httpdoiorg101038scientificamerican039752

	Lynch C 2002 Digital collections digital libraries and the digitization of cultural heritage information First Monday 75 httpdoiorg105210fmv7i5949

	Nielsen J 1997 How users read on the web Retrieved from httpswwwnngroupcomarticleshowusersreadontheweb

	Nielsen J 2003 Information foraging Why Google makes people leave your site faster Retrieved from httpswwwnngroupcomarticlesinformationscent

	Nielsen Norman Group 2014 Writing hyperlinks Salient descriptive start with keyword Retrieved from httpswwwnngroupcomarticleswritinglinks  
	Overholt J H 2013 Five theses on the future of special collections RBM A Journal of Rare Books Manuscripts and Cultural Heritage 141 1520 Retrieved from httpnrsharvardeduurn3HULInstRepos10601790

	Pomerantz J Choemprayong S  Eakin L 2008 The development and impact of digital library funding in the United States In D A Nitecki  E G Abels Eds Influence of funding on advances in librarianship Vol 31 pp 3792 Retrieved from httpwwwemeraldinsightcomdoipdfplus101016S00652830280829310022

	Prochaska A 2009 Digital special collections The big picture RBM A Journal of Rare Books Manuscripts and Cultural Heritage 101 1324
	Schwartz C 2000 Digital libraries An overview The Journal of Academic Librarianship 266 385393
	Smith C 2006 Multiple cultures multiple intelligences Applying cognitive theory to usability of digital libraries Libri International Journal of Libraries and Information Studies 564 227238 httpsdoiorg101515LIBR2006227
	Southwell K L  Slater J 2012 Accessibility of digital special collections using screen readers Library Hi Tech 303 457471 httpsdoiorg10110807378831211266609

	Thong J Y Weiyin H  Kar Yan T 2004 What leads to user acceptance of digital libraries Communications of The ACM 4711 7983
	Waters DJ 1998 What are digital libraries CLIR Issues 4 Retrieved from httpswwwclirorg199807clirissuesnumber4
	Whang M 2008 Cardsorting usability tests of the WMU Libraries web site Journal of Web Librarianship 223 205218
	Xie H I 2007 Help features in digital libraries Types formats presentation styles and problems Online Information Review 316 861880 httpsdoiorg10110814684520710841810

	Xie H I 2008 Users evaluation of digital libraries DLs Their uses their criteria and their assessment Information Processing  Management 443 13461373 httpsdoiorg101016jipm200710003

	Xie I Babu R Joo S  Fuller P 2015 Using digital libraries nonvisually Understanding the helpseeking situations of blind users Information Research 202 123 Retrieved from httpwwwinformationrnetir202paper673html






Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS




































































Collection Development and User Experience Symposia


	Skip to main content
	Skip to quick search
	Skip to global navigation






Journal of Library User Experience

Weave is an openaccess peerreviewed journal for Library User Experience professionals published by Michigan Publishing




Quick search






	Current Issue Vol 2 Issue 1
	Archive
	Download EPUBs
	Submit to Weave










Collection Development and User Experience Symposia





Skip other details including permanent urls DOI citation information
Volume 1 Issue 8 2018



DOI httpdxdoiorg103998weave125356420001804



Creative Commons 30 Attribution License




Permissions This work is licensed under a Creative Commons Attribution 30 License Please contact mpubhelpumichedu to use this work in a way not covered by the license

For more information read Michigan Publishings access and usage policy






	Print
	
Share	Twitter
            	
	Facebook
            	
	Reddit
            	
	Mendeley
            	














In September 2017 Weave reached out to a number of academic and public librarians with the hope of instigating and documenting the conversation they might have with one another about the user experience issues facing collection development and eresources librarians


The conversation below unfolded over email between Monday September 11 and Friday September 15 2017 It has been lightly edited for clarity


Our participants

	Michelle BoisvenueFox Director of Innovation and User Experience Kent District Library
	Galadriel Chilton Director of Collections Initiatives Ivy Plus Libraries 
	Daniel Dollar Associate University Librarian for Collections Preservation and Digital Scholarship Yale University Library
	Mihoko Hosoi Assistant Director for Systemwide Licensing California Digital Library
	Alison Kuchta Collection Development Librarian Kent District Library
	Daniel Matsumoto eResources Librarian San Francisco Public Library


Moderated by

	Cody Hanson University of Minnesota Libraries Weave Board
	Matthew Reidsma Web Services Librarian Grand Valley State University Libraries Weave Editor



Matthew Reidsma

What are the biggest challenges your users face in using electronic resources How do you address those challenges in the collection development process




Alison Kuchta Kent District Library

I order ebooks and eaudiobooks for Kent District Library Were a public library system in the suburbs and outlying areas surrounding Grand Rapids Michigan We have a service population of 395000 In 2016 we circulated 1215187 digital items 7045551 physical items and had 3537857 website visits Heres the KDL 2016 Annual Report with more fun facts

Some of the biggest challenges our users face using electronic resources are the digital divide lack of awareness of resources certain items not being available to us for purchase and long wait times for popular materials


Digital Divide

In some of our communities a digital divide still exists Individuals may not have their own computers and in some cases reliable and affordable internet access is not available To combat this we provide computers at our branches tablets for checkout classes and WiFi hotspots Demand for our WiFi hotspots has been extremely high 




Device Issues

To address device issues our staff has access to various popular digital devices and goes through training with them iPads have also been purchased for each of our frontline staff members We also have a group of individuals called Tech Trainers who create handouts to help patrons and staff with troubleshooting common issues These FAQs and Tips and Tricks for our various digital platforms are available in our branches and on our website This group presents to staff throughout the year gives classes keeps handouts current and provides outreach and Speak to a Geek services to several senior centers in our service area We also have a Patron Services department that answers questions by phone for all of our 18 branches Some of our service providers provide tech support resources to our staff and patrons






Michelle BoisvenueFox Kent District Library

We looked at putting a digital kiosk at the airport but when we tested the kiosk it required a library card to access the free stuff We ditched the idea because we didnt want to cause frustration for travelers or those without a library card




Alison


 Lack of Awareness of Resources

To combat lack of awareness our Communications staff promotes our electronic resources by highlighting them in our newsletters social media posts events and on our website Our staff also creates many booklists that link to our catalog where discovery of many of these digital materials is also possible




Items Not Being Available to Purchase

 Lack of availability of ebooks and eaudiobooks to libraries is getting to be less and less a problem these days However occasionally there are still materials I receive requests for that are not available to us In some of these cases Im able to communicate the request to our providers Sometimes they are able to get us these materials depending on the publisher Patrons are able to recommend materials to us through staff in our branches our Recommend a Purchase form on our website and directly from our main ebook platform




High Wait Times for Popular Items

 High wait times for popular digital materials is an inconvenience for our patrons at this time We have experienced 12 percent yearoveryear growth in digital circulation and wait times are now averaging almost 40 days We do our best to keep our holds ratio at a reasonable level however higher demand high prices of ebooks and eaudiobooks and budget constraints do not always allow for this To help our patrons find something while they are waiting we promote many alternative items through booklists on our main ebook site and in our branches We also provide access to an additional ebook platform that has items that are available for simultaneous use and we are always on the lookout for new products and services that will help us save money and meet user expectations and needs






Michelle

Some additional training tips we are looking to share with patrons is how to return digital items We find many people cant see how to do this and it may help our holds ratios Another tip we are looking to share is how to search for items that are available as well as building a wish list




Daniel Dollar Yale University Libraries

Alison I am impressed by how well you know your community and your ease in citing key statistics At the Yale University Library we have been working to build a culture of assessment over the past few years which includes having a better handle on our usage data Still I am speculating when it comes to the biggest challenges our users face in using electronic resources 


Patron Preferences for Formats

For starters our users want what they want We purchase an eversion of a book but then get a request for a print copy or vice versa We cannot duplicate content at scale although the trends are clear as we see physical circulations decline and eresource downloads continue to climb I understand you cannot do a straight comparison of circulations and downloadswe are talking apples and oranges Its the orders of magnitude that stands out when you have millions of downloadscall them orangesand few hundred thousand circulationsor apples 




Lack of Awareness of Resources

Another challenge which was also noted by Alison is the lack of awareness of resources My library provides a resource rich environment and its a challenge informing our user community about all that is available Outreach and instruction is a focus of our librarians They invest significant time in Libguides offer classes hold oneonones and communicate through various channels It is also essential for eresources to be easily discoverable We have invested significant resources into our Blacklight discovery platform which we have branded as QuickSearch and prominently placed on our homepage  




Support

 We strive to be very responsive when users report problems or ask questions about eresources We have a very capable eresources troubleshooting team that is run by my colleagues in technical services Recurring issues we try to flag through FAQs see examples for FAQs about offcampus access and accessing a specific newspaper And while it may not always factor into license negotiations we regularly raise UX issues with publishers and vendors For example we are in discussions with a publisher whos default setting on their publication platform is to show all their content regardless of whether Yale has subscribed to it Our expectation is for subscribed content to be limited to what we license 




Partnerships

 Finally we are not in this alone We work closely with other academic institutions through consortia such as NorthEast Research Libraries NERL and partnerships like the Ivy Plus Libraries We have been in recent conversations through NERL and led by colleagues at Columbia University about institutional branding of and advertisements on publishervendor content platforms   






Alison

We also find many of our users are open to using different formats and will take whatever is available first However in some cases our digital users have to be reminded about the physical collection and more and more Im finding people who just want the eaudio We duplicate a lot of our materials and this is becoming less and less sustainable especially when costly eaudiobooks are added into the mix




Matthew

Alison I was really interested in your last point on hold times Its not often that we in the UX community think about licensing agreements as a user experience issue but it really is Do the discussions with vendors around licensing ever move into discussions of user satisfaction usability or easeofuse 




Alison

Our vendors are aware of our user experience issues As far as our wait times OverDrive has suggested we might use simultaneous use plans on specific targeted items with high holds that are available in this model1 However this wouldnt make a dent in our wait times at this point They also offer us many themed booklists that we rotate regularly on our ebook landing page They have an interest in making sure our patrons are happy and become return users Just like us they dont want anyone to leave empty handed The CostperCirculation model will be an option on some titles in the near future with them too We meet monthly and make development requests with our patrons in mind Some examples of development requests make foreign language materials more obvious be able to customize the message our patrons receive when they recommend an item and be able to customize the message for when our patrons reach their limit of recommendations




Galadriel Chilton Ivy Plus Libraries

The biggest challenges that I see users in academic communities facing when it comes to electronic resources are


Impediments to Use Clunky Interfaces and a Maze of Steps to Access

Online content available through libraries does not offer users the same sleek functionality or brand recognition of online content marketed directly to end users especially for ebooks For example using Kindle ebooks Audiblecom audio books Netflix or Hulu streaming and Google images all have user interfaces where the user accesses content quickly and intuitively with little questioning of how to get content 

By contrast library resources such as Overdrive for audio or ebooks Ebrary for ebooks multiple interfaces for streaming content and image sources like Artstor are not as well known to users and have user interfaces that are complicated enough that as Daniel and Alison noted libraries spend significant amounts of time marketing and creating guides for how users can access the rich content available to them

 For example if I want to access a Kindle book on a device other than my computer I download the Kindle app and login with my same Amazon credentials and the option to send it to my smartphone or tablet is available with one click on the checkout screen By contrast to download an Ebrary ebook requires a user to download Adobe Digital Editions for use on their computer To read the book on a device users must download a separate app and then create a separate Adobe ID first httpproquestlibguidescomebookcentraldownload

 When I worked at a large state university users seeking help accessing an ebook would hear all the steps required before they could access a DRMencased ebook via Ebrary or EBSCO and they would choose to buy the Kindle edition of a book instead While this might work for those with the means to do so there are many users on the other side of the digital and economic divide who do not have the device or the funds to buy the content they need




Different Formats Different Content Different Uses

Print and electronic formats of supposedly the same content are different an ebook may not have the images charts and tables of its print counterpart and while a print book can be acquired for a user via interlibrary loan most ebooks cannot Like Daniel noted users seek access to books in print and online This seems to be because they are using print to read at length and online for quick access as well as to skim and search content yet libraries do not have the human or fiscal resources to buy duplicate content




So Many Choices

Between what is available on the open web and what is available online through libraries users have an overwhelming amount of access entry points to choose from and then information available to them which could lead to analysis paralysis So many choices likely lead users to seek out the path of least resistance in terms of access familiar access points like Google intuitive and familiar interfaces like Netflix

 Libraries canare address these challenges in multiple ways




 Selection  Negotiation

Whenever possible libraries select content not just for the content itself but also based on the usability and intuitive interface For example ebooks available on some platforms such as ProjectMUSE and JSTOR offer users access to ebook chapters as downloadable PDFs analogous to how users access journal articles By not buying content because of a poor interface libraries can over time change the market but this can be challenging when users seek content and online options are limited

 Libraries can strive to select content that includes the same content as the print content andor aspire to negotiate with vendors for online content that stipulates that content includes all components of the print edition For instances when the online content is different due to copyright limitations negotiate with the vendor that their interface must include a clearly visible note of what content is missing

 When it comes to working with information providers to improve the information landscape for users libraries have a long history of working cooperatively library consortia and partnerships are consistently looking into ways that resource selection resource sharing and negotiation can both provide users with the information they need and improve access and usability




 Ease Access Impediments  User Support

Work with vendors to push access authentication out to where users are For example if a user lands on a content access page from Google search results page users should be able to select their library and authenticate immediately eg httpswwwjstororglogon without having to reaccess the content providers user interface through the librarys website Libraries can also continue their longstanding efforts to be a bridge between users and information by continuing efforts that Alison and Daniel describe around communication and discovery

 Although developing new models of eresource acquisition and access is slow and very timeconsuming it is important to acknowledge celebrate and continuously evaluate the effectiveness of small changes so that library resources are both relevant and accessible With the multitude of platforms interfaces and devices that are now part of the information access equation it is fundamentally unacceptable for libraries to provide relevant information to their academic communities without also making sure that the user experience accessing those collections meets or exceeds the users expectations because library collections become irrelevant if users cannot easily access them






Daniel Matsumoto San Francisco Public Library

Its great to be part of the conversation and to read about parallel issues and challenges in both academic and public library environments

 To provide some background San Francisco Public Library serves appropriately 860000 San Francisco residents of which 49 percent are card holders and the greater Bay Area of 7 million people Additionally any California resident can get an SFPL card so we have some exclusively remote users The Main Library is located in Civic Center Plaza and is accessible by all transit lines We have more than 900 employees in 28 locations throughout the city


Keeping Up

 The greatest challenge for our staff and patrons has been keeping up the constant updates and changes to the platform apps It is particularly challenging for our patrons who do not upgrade their devices or operating systems on a regular basis We offer access to three major ebook platforms OverDrive Axis360 and Hoopla and a handful of secondary platforms Enki UDN United Daily News  Chinese ebooks Safari Books and Books24x7 With requirements and variations to each platform it can be a tricky delivering consistent information and instruction   

 To better serve our patrons and increase staff awareness of these electronic resources we have

	Required threehour ebook training for all new staff members
	Created three go to brochures that describe stepbystep how to get started with library ebooks
	Populated our LibAnswers FAQ with relevant ebook information
	Invited struggling patrons to attend our Digital Device Drop In and Book a Librarian sessions for oneonone assistance


 Of these activities we have found the dedicated staff training and oneonone assistance to be most effective at least anecdotally

 As others have mentioned we invested a lot of time and effort in marketing these resources which has paid off Check out of ebooks and other digital content has kept our yearoveryear circulation in the plus column for many years at an average increase of 5 percent per year Print circulation continues to decline at a rate of 4 percent per year

 While we have strong relationships with each of our vendors we have conceded that there is only so much that they can do to provide an optimal user experience though OverDrive has produced some favorable results with their new streamlined Libby app

 Lately we have been encouraged by the work of the New York Public Librarys SimplyE app and the Digital Public Library of Americas Exchange who have been working hard to deliver digital content that leverages the power of libraries We have been monitoring their work

 We recently created the Research Strategy and Analytics Unit which will coordinate the librarys performance measures statistical data tracking and reporting and customer intelligence activities Our Collection Development will work closely with this new department to better understand who are patrons are and how they are accessing our resources






Mihoko Hosoi California Digital Library

Its interesting to see that we have similar and different challenges

 I work at the California Digital Library CDL and serve mostly University of California UC faculty students and staff My primary role involves UC systemwide licensing contracts for 10 UC campuses and I dont get to interact with end users very much In fact I work in an office building not on campus and rely heavily on my UC campus colleagues input in understanding the needs of our faculty and students In my previous roles at other academic institutions I worked more directly with faculty and students My responses will be based on my observation as the licensing manager in my current role

 In terms of the biggest challenges in using electronic resources the first thing that came to my mind was our users desire to use our licensed content for computational analysis They seem to be thinking of our collections as data not ejournals or ebooks We recently updated the CDL Model License to support UC researchers and authors research needs For example we updated the Text and Data Mining TDM section of our model license to clarify that authorized users may not only engage in text andor data mining activities for academic research purposes but also share the results with others so long as the purpose is not to create a product for use by third parties that would substitute for the licensed materials We started using the new language late last year and have been negotiating with vendors for each new license Some vendors are more flexible than others We are pleased that we are making some progress At the same time having appropriate licenses is one thing and providing the service is another It takes much communication with vendors campus librarians and end users to support our users needs 

 We are also committed to support the needs of our users with disabilities and list our accessibility requirements under the Warranties section of our model license Vendors are sometimes surprised that we do not sign our licenses without them We advocate for our users so that they can make full use of the licensed content

 We sometimes get questions on clickthrough licenses and see that they create confusion for our users To prevent any potential issues our model license states that if there is any conflict between the clickthrough or online terms and the CDL signed license the terms of the CDL license prevail We also negotiate with vendors and try to get such online terms removed as much as possible

 Additionally we make sure that watermarks if any will not reduce readability of content and will not degrade image quality and that digital rights management DRM technology is not implemented by licensors in such a way as to limit the usage rights of our users I havent directly received any complaints on these matters but we address them at the licensing stage to prevent any issues

 Unlike print materials usage rights of electronic licensed content are complicated To clarify whats been negotiated we indicate terms of use via our ERMS Portal so that our users and librarians will know whats permitted eg interlibrary loan course reserves scholarly sharing perpetual access etc

 We negotiate UC systemwide licenses as much as possible to obtain favorable discounts and terms when resources are needed at all campuses We promote our resources in different ways so that they get utilized For example we publish articles through CDLINFO News describing key features and contents and promote them through Resource Liaison Program where campus librarians serve as Resource Liaisons and work closely with vendors on interface changesdevelopment and technical issues and provide training to other librarians and users It sometimes takes time and coordination to work in a big system like UC but I feel fortunate to be able to collaborate with talented and skilled colleagues




Cody Hanson Weave

I found Mihokos account of electronic resource usability challenges from CDLs perspective fascinating and it raised a couple of questions for me

First prompted by Mihokos mention of computational analysis of electronic resources it would seem that we cant always anticipate the uses to which our resources will be put Do any of you attempt any proactive assessment of how users interact with licensed resources Or do you primarily rely on users raising issues

Second Mihokos discussion of various aspects of the license agreements CDL signs made me wonder if theres work that could be done in the library UX community to attempt to define standards for usability that would be appropriate for inclusion in licenses Aside from the examples Mihoko mentioned TDM Accessibility Warranties watermarks DRM are any of you aware of license language that addresses usability




Mihoko

Some of my CDL and UC Santa Cruz colleagues recently conducted a user survey on print and ebook usage behaviors at UC Santa Cruz They found that participants especially in social science arts and humanities preferred print books over ebooks and that ebook access restrictions watermarks limited number of pages that can be downloaded limited number of simultaneous users etc and usability challenges can make ebooks frustrating to use The summary of the study webinar recording and other usability reports by CDL staff are available on our website My team handles mostly licensed content such as ebooks ejournals and subscription databases CDL has a separate UX design team that addresses overall UX issues

In terms of the standards for usability we consulted our CDL and UC colleagues in updating our Model License Some of them have UX design background and their input was helpful The University of California also came up with UC libraries EBook Value Statement in 2013 and we observe the guidelines as much as possible when we license ebooks At the same time ebook interlibrary loan in a manner analogous to the loan of physical books has been challenging We are curious to see what happens with the Capital Records LLC v ReDigi Inc case which involves the doctrine of digital first sale and might affect the way we handle interlibrary loan with digital licensed content Other items in the UC EBook Value Statement such as the ability to navigate content through table of contents print copy save annotate and to export bibliographic information to citation management software all seem like reasonable expectations We use the UC EBook Value Statement to inform staff faculty and students but also to communicate our expectations with publishers CDL also publishes various technical guidelines for vendors and update them regularly Our internal document refers to the US Department of Health  Human Services Usability Guidelines which seem helpful for web design and broader digital communication issues Well need more specific usability standards for ebooks though




Daniel Dollar

It is interesting to note the similarities between public and academic libraries in providing access to electronic resources Cody you raise an intriguing question about being more proactive or reactive in assessing UX for eresources Experience is critical The development of a digital humanities program at the Yale Library helped drive our discussions around text and data mining TDM It went from an abstract concept to one where we had an actual use case with a request to mine the Vogue Archive It was an excellent learning experience for both the library and vendor Like CDL we have a TDM clause in our model license and have had several extensive mostly successful discussions with vendors regarding computational analysis of their licensed eresources and how such use is in accordance of copyright ie the right to read is the right to mine Accessibility which Mihoko mentioned is another key clause we push for inclusion in our licenses  

You need to build an assessment program before you can start to take more proactive steps A few years ago some of my colleagues conducted an ethnographic study of the research practices of humanities doctoral students The research did not change collection development practices but it did inform outreach efforts such as the creation of a Libguide for students traveling outside the country to do research for the firsttime Following on CDL we created an ebooks value statement and went on to form an ebooks advisory group The advisory group last year created an internal document to aid subject librarians purchasing oneoff and small ebook packages by noting several key factors which were No DRM Digital Rights Management Unlimited Users PDF DownloadsChapterSections PDF DownloadsBook EPUB Downloads EReservesStable Links ILL Index in Articles our SUMMON discovery app AccessibilityW3C WCAG 20 We then ranked our top ebook platform vendors in three tiers Excellent Acceptable and Problem use as last resort 

We continue to purchase ebook content from problem vendors UX is important but it is not a showstopper as is the case with key licensing terms such as indemnification or foreign legal jurisdiction I get the Purdue librarians perspective about content considerations prevailing over the container it comes in However as our conversation has highlighted we are moving toward more holistic understandings about eresources and working to better leverage the large amounts of data we have or can collect about them and our user communities interaction with them Of course this brings up privacy considerations which is deserves its own conversation







	Since this discussion KDL has transferred our digital collection over to Bibliothecas cloudLibrary Their cloudLink and Pay Per Use PPU services are features that make cloudLibrary a practical platform We are working to stretch our budget reduce wait times and increase selection for our patrons CloudLinking acts like a digital consortia but only allows us and our partners to borrow availableon shelf materials The PPU service offers a wide range titles our patrons can borrow simultaneously at a fraction of the cost of purchasing While our partnership with Bibliotheca is new and there are many factors involved we have seen some encouraging results Wait times have gone from roughly 40 days to 20 days






Top of page










Hosted by Michigan Publishing a division of the University of Michigan Library

ISSN 23333316

	About
	Editorial Board
	Editorial Philosophy
	Contact
	Log in


	Follow us
	Twitter
	Email
	RSS









